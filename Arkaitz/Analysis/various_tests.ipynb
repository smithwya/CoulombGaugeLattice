{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iminuit version: 2.28.0\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# basic setup of the notebook\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "from numba import njit, prange\n",
    "from numba.experimental import jitclass\n",
    "import pickle\n",
    "\n",
    "from mpmath import *\n",
    "mp.dps = 200;mp.pretty = True\n",
    "import tomllib\n",
    "from pip._vendor import tomli\n",
    "import sys, os\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocess as mp\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import scipy as sp\n",
    "from scipy import *\n",
    "import faulthandler\n",
    "faulthandler.enable()\n",
    "sys.path.append('./code')\n",
    "from fit_drivers import *\n",
    "from minimizer import *\n",
    "from fit_functions import *\n",
    "from output_functions import *\n",
    "from general_stats import *\n",
    "from jpac_colors import *\n",
    "import fit_drivers, minimizer, fit_functions, output_functions, general_stats  \n",
    "\n",
    "import math as mp\n",
    "import timeit\n",
    "import time\n",
    "\n",
    "# everything in iminuit is done through the Minuit object, so we import it\n",
    "from iminuit import Minuit\n",
    "from iminuit import minimize\n",
    "import time\n",
    "from iminuit.util import describe\n",
    "from typing import Annotated\n",
    "\n",
    "# we also need a cost function to fit and import the LeastSquares function\n",
    "from iminuit.cost import LeastSquares\n",
    "\n",
    "# display iminuit version\n",
    "import iminuit\n",
    "print(\"iminuit version:\", iminuit.__version__)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Importing fixed params for analysis\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "with open('ini_files/S_analysis_L16_pole.toml', \"rb\") as f:\n",
    "    params = tomli.load(f)\n",
    "\n",
    "with open('ini_files/basic_setup_pole.toml', \"rb\") as f2:\n",
    "    params2 = tomli.load(f2)\n",
    "\n",
    "for i in params:\n",
    "     params['{}'.format(i)].update(params2['{}'.format(i)])\n",
    "\n",
    "\n",
    "who            = params['creator']['who']\n",
    "  \n",
    "  \n",
    "path           = params['paths_to_files']['base_path']\n",
    "mainpath       = '{}{}'.format(path,params['paths_to_files']['mainpath'])\n",
    "resultspath    = '{}{}'.format(path,params['paths_to_files']['resultspath'])\n",
    "resultsdir     = '{}{}'.format(path,params['paths_to_files']['resultsdir'])\n",
    "plotsdir       = '{}{}'.format(path,params['paths_to_files']['plotsdir'])\n",
    "Gcplotsdir     = '{}{}'.format(path,params['paths_to_files']['Gcplotsdir'])\n",
    "sizelabel      = params['paths_to_files']['sizelabel']      \n",
    "  \n",
    "  \n",
    "corrtype       = params['correlators']['corrtype']  \n",
    "xi             = params['correlators']['xi']\n",
    "beta           = params['correlators']['beta']\n",
    "betanorm       = params['correlators']['betanorm']\n",
    "Lextent        = params['correlators']['Lextent']\n",
    "Textent        = params['correlators']['Textent']\n",
    "size           = params['correlators']['size']\n",
    "Ncfgs          = params['correlators']['Ncfgs']\n",
    "\n",
    "als            = params['correlators']['als']\n",
    "  \n",
    "dini_Gc        = params['minimization_parameters']['dini_Gc']\n",
    "dstop_Gc       = params['minimization_parameters']['dstop_Gc']\n",
    "dmindata_Gc    = params['minimization_parameters']['dmindata_Gc']\n",
    "dini_Vr        = params['minimization_parameters']['dini_Vr']\n",
    "dstop_Vr       = params['minimization_parameters']['dstop_Vr']\n",
    "dmindata_Vr    = params['minimization_parameters']['dmindata_Vr']\n",
    "dfin_Gc        = params['minimization_parameters']['dfin_Gc']\n",
    "dfin_Vr        = params['minimization_parameters']['dfin_Vr']\n",
    "reuse          = params['minimization_parameters']['reuse']\n",
    "inv_first      = params['minimization_parameters']['inv_first']\n",
    "mcalls         = params['minimization_parameters']['mcalls']\n",
    "mtol           = params['minimization_parameters']['mtol']\n",
    "inipars_Gc     = params['minimization_parameters']['inipars_GC']\n",
    "variants_Gc    = params['minimization_parameters']['variants_GC']\n",
    "jackkl         = params['minimization_parameters']['jackkl']\n",
    "xiini          = params['minimization_parameters']['xiini']\n",
    "xifin          = params['minimization_parameters']['xifin']   \n",
    "fileini        = params['minimization_parameters']['fileini']                         \n",
    "filefin        = params['minimization_parameters']['filefin']\n",
    "datatype_Gc    = params['minimization_parameters']['datatype_Gc']\n",
    "model_Gc       = params['minimization_parameters']['model_Gc']\n",
    "model_Vr       = params['minimization_parameters']['model_Vr']\n",
    "datatype_Vr    = params['minimization_parameters']['datatype_Vr']\n",
    "inipars_Vr     = params['minimization_parameters']['inipars_Vr']\n",
    "variants_Vr    = params['minimization_parameters']['variants_Vr']\n",
    "multiprocess   = params['minimization_parameters']['multiprocess']\n",
    "cov_freeze     = params['minimization_parameters']['cov_freeze']\n",
    "improve        = params['minimization_parameters']['improve']\n",
    "multistart     = params['minimization_parameters']['multistart']\n",
    "  \n",
    "\n",
    "clean          = params['extra']['clean']\n",
    "cutoff_ma      = params['extra']['cutoff_ma']\n",
    "norm           = params['extra']['norm']\n",
    "no_corrs       = params['extra']['no_corrs']\n",
    "no_valid_check = params['extra']['no_valid_check']\n",
    "\n",
    "\n",
    "gev_m1_tofm=5.068\n",
    "als=np.array(als)/gev_m1_tofm\n",
    "als_orig=np.array(als)*gev_m1_tofm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "1985\n",
      "1992\n",
      "1927\n",
      "2000\n",
      "2000\n",
      "1995\n",
      "1994\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "1985\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "1917\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "1946\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "1917 2000\n",
      "[225, 230, 235, 240, 245, 250, 255, 260]\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#This is the only part that varies between Sebastian's and Wyatt's Lattices, the paths/readings\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create results folders if they do not exist\n",
    "if os.path.exists(resultsdir)==False:\n",
    "    os.mkdir(resultsdir)\n",
    "if os.path.exists(plotsdir)==False:\n",
    "    os.mkdir(plotsdir)\n",
    "if os.path.exists(Gcplotsdir)==False:\n",
    "    os.mkdir(Gcplotsdir)    \n",
    "\n",
    "\n",
    "# Clean results folder?\n",
    "if clean == 1:\n",
    "    os.system('rm -rf {}/*'.format(plotsdir))\n",
    "    os.system('rm -rf {}/*'.format(resultsdir))  \n",
    "    os.system('rm -rf {}/*'.format(Gcplotsdir)) \n",
    "\n",
    "\n",
    "for k in range(len(xi)):\n",
    "    if os.path.exists('{}{}'.format(resultspath,xi[k]))==False:\n",
    "        os.mkdir('{}{}'.format(resultspath,xi[k]))\n",
    "    if os.path.exists('{}/xi={}'.format(Gcplotsdir,xi[k]))==False:\n",
    "        os.mkdir('{}/xi={}'.format(Gcplotsdir,xi[k]))\n",
    "\n",
    "        \n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Read raw data and prepare accordingly\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "         \n",
    "\n",
    "# Data used in the analysis\n",
    "datam=[]\n",
    "for k in range(len(xi)):\n",
    "    dataint=[]\n",
    "    for j in range(len(beta)):\n",
    "        dataint.append(np.genfromtxt('{}{}/L{}_b{}_xi{}_{}.dat'.format(mainpath,xi[k],int(sizelabel),beta[j],xi[k],corrtype)))\n",
    "    datam.append(dataint)\n",
    "    \n",
    "# Collect completed configurations from raw data    \n",
    "data=[]\n",
    "for k in range(len(xi)):\n",
    "    dataint=[]\n",
    "    for j in range(len(datam[k])):\n",
    "        if (len(np.array(collect_configs(datam[k][j],Lextent,Textent).trans_S()))==0):\n",
    "            dataint.append(np.array(collect_configs(datam[k][j],Lextent,Textent).trans_W()))\n",
    "        else:\n",
    "            dataint.append(np.array(collect_configs(datam[k][j],Lextent,Textent).trans_S()))\n",
    "    data.append(dataint)\n",
    "\n",
    "      \n",
    "\n",
    "nconfigs=[]\n",
    "for k in range(len(xi)):\n",
    "    nint=[]\n",
    "    for j in range(len(beta)):\n",
    "        nint.append(int(len(data[k][j])/size[k]))\n",
    "        print(int(len(data[k][j])/size[k]))\n",
    "        nconfigs.append(int(len(data[k][j])/size[k]))  \n",
    "\n",
    "print(min(nconfigs),max(nconfigs))  \n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1278b86b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x127d85730>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 7.5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x127d13380>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x124d5fcb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 7.5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x127d16450>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x127d13710>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 7.5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1267a72f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x127d17710>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 7.5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x127d3f5f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x127d3cc20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 7.5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x127d3cad0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x127d11af0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 7.5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x127d3a360>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x127d3aa50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 7.5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x127d3b0b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x127d3b020>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 7.5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x127d3bf80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x127d38050>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 7.5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x127d85370>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x127d3bc50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 7.5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=0\n",
    "k=3\n",
    "r=0\n",
    "pos=0\n",
    "\n",
    "jackkl=100000\n",
    "jump_configs=1\n",
    "\n",
    "mcalls=10000\n",
    "mtol=0.00001\n",
    "\n",
    "totaltraj=int(len(data[x][k])/size[k])\n",
    "Nt=Textent\n",
    "\n",
    "Gc=np.zeros((int(totaltraj/jump_configs),Nt))\n",
    "Gc2=np.zeros((int(totaltraj/jump_configs),Nt))\n",
    "for i in range(int(totaltraj/jump_configs)):\n",
    "    index=jump_configs*i\n",
    "    Gc[[i]]=data[x][k][range(index*Nt,(index+1)*Nt),[r]]\n",
    "    Gc2[[i]]=data[x][k+1][range(index*Nt,(index+1)*Nt),[r]]\n",
    "\n",
    "for time in range(len(Gc[0])):\n",
    "    shift=0.1\n",
    "    data_t = np.ones(len(Gc[:,time]))*time+1\n",
    "    plt.scatter(data_t,Gc[:,time],color=jpac_blue)\n",
    "    plt.scatter(data_t+shift,Gc2[:,time],color=jpac_red)\n",
    "    plt.xlim(0,7.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.25139636, 0.87052982, 0.61546284, 0.43870142, 0.31429297,\n",
       "       0.22588335, 0.16277069, 0.1175101 , 0.08493955, 0.06146263])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 2765.21938808,  5368.8128157 ,  9113.25823357, 14175.09791814,\n",
       "       20796.23214703, 28816.88786356, 37053.66959364, 37907.16717419,\n",
       "       46475.0256049 , 52896.5891635 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th colspan=\"2\" style=\"text-align:center\" title=\"Minimizer\"> Migrad </th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align:left\" title=\"Minimum value of function\"> FCN = 0.678 (χ²/ndof = 0.3) </td>\n",
       "        <td style=\"text-align:center\" title=\"Total number of function and (optional) gradient evaluations\"> Nfcn = 4028 </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align:left\" title=\"Estimated distance to minimum and goal\"> EDM = 2.84e-09 (Goal: 2e-08) </td>\n",
       "        <td style=\"text-align:center\" title=\"Total run time of algorithms\">  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align:center;background-color:#92CCA6;color:black\"> Valid Minimum </td>\n",
       "        <td style=\"text-align:center;background-color:#92CCA6;color:black\"> Below EDM threshold (goal x 10) </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align:center;background-color:#92CCA6;color:black\"> No parameters at limit </td>\n",
       "        <td style=\"text-align:center;background-color:#92CCA6;color:black\"> Below call limit </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align:center;background-color:#92CCA6;color:black\"> Hesse ok </td>\n",
       "        <td style=\"text-align:center;background-color:#92CCA6;color:black\"> Covariance accurate </td>\n",
       "    </tr>\n",
       "</table><table>\n",
       "    <tr>\n",
       "        <td></td>\n",
       "        <th title=\"Variable name\"> Name </th>\n",
       "        <th title=\"Value of parameter\"> Value </th>\n",
       "        <th title=\"Hesse error\"> Hesse Error </th>\n",
       "        <th title=\"Minos lower error\"> Minos Error- </th>\n",
       "        <th title=\"Minos upper error\"> Minos Error+ </th>\n",
       "        <th title=\"Lower limit of the parameter\"> Limit- </th>\n",
       "        <th title=\"Upper limit of the parameter\"> Limit+ </th>\n",
       "        <th title=\"Is the parameter fixed in the fit\"> Fixed </th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> 0 </th>\n",
       "        <td> x0 </td>\n",
       "        <td> 0.000 </td>\n",
       "        <td> 0.002 </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> 1 </th>\n",
       "        <td> x1 </td>\n",
       "        <td> 1.50 </td>\n",
       "        <td> 0.05 </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> 2 </th>\n",
       "        <td> x2 </td>\n",
       "        <td> 0.3204 </td>\n",
       "        <td> 0.0023 </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> 3 </th>\n",
       "        <td> x3 </td>\n",
       "        <td> 0.255 </td>\n",
       "        <td> 0.016 </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> 4 </th>\n",
       "        <td> x4 </td>\n",
       "        <td> -0.29 </td>\n",
       "        <td> 0.09 </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> 5 </th>\n",
       "        <td> x5 </td>\n",
       "        <td> 0.114 </td>\n",
       "        <td> 0.029 </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> 6 </th>\n",
       "        <td> x6 </td>\n",
       "        <td> 0.93 </td>\n",
       "        <td> 0.32 </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "    </tr>\n",
       "</table><table>\n",
       "    <tr>\n",
       "        <td></td>\n",
       "        <th> x0 </th>\n",
       "        <th> x1 </th>\n",
       "        <th> x2 </th>\n",
       "        <th> x3 </th>\n",
       "        <th> x4 </th>\n",
       "        <th> x5 </th>\n",
       "        <th> x6 </th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> x0 </th>\n",
       "        <td> 3.88e-06 </td>\n",
       "        <td style=\"background-color:rgb(246,246,250);color:black\"> -3e-6 <strong>(-0.032)</strong> </td>\n",
       "        <td style=\"background-color:rgb(247,247,250);color:black\"> -0e-6 <strong>(-0.026)</strong> </td>\n",
       "        <td style=\"background-color:rgb(232,232,250);color:black\"> -4e-6 <strong>(-0.137)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,245,245);color:black\"> 6e-6 <strong>(0.034)</strong> </td>\n",
       "        <td style=\"background-color:rgb(220,220,250);color:black\"> -13e-6 <strong>(-0.230)</strong> </td>\n",
       "        <td style=\"background-color:rgb(238,238,250);color:black\"> -57e-6 <strong>(-0.089)</strong> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> x1 </th>\n",
       "        <td style=\"background-color:rgb(246,246,250);color:black\"> -3e-6 <strong>(-0.032)</strong> </td>\n",
       "        <td> 0.00221 </td>\n",
       "        <td style=\"background-color:rgb(250,101,101);color:black\"> 108e-6 <strong>(0.993)</strong> </td>\n",
       "        <td style=\"background-color:rgb(187,187,250);color:black\"> -0.37e-3 <strong>(-0.481)</strong> </td>\n",
       "        <td style=\"background-color:rgb(122,122,250);color:black\"> -0.0042 <strong>(-0.985)</strong> </td>\n",
       "        <td style=\"background-color:rgb(130,130,250);color:black\"> -1.3e-3 <strong>(-0.924)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,128,128);color:black\"> 0.0124 <strong>(0.816)</strong> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> x2 </th>\n",
       "        <td style=\"background-color:rgb(247,247,250);color:black\"> -0e-6 <strong>(-0.026)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,101,101);color:black\"> 108e-6 <strong>(0.993)</strong> </td>\n",
       "        <td> 5.36e-06 </td>\n",
       "        <td style=\"background-color:rgb(182,182,250);color:black\"> -20e-6 <strong>(-0.524)</strong> </td>\n",
       "        <td style=\"background-color:rgb(124,124,250);color:black\"> -203e-6 <strong>(-0.971)</strong> </td>\n",
       "        <td style=\"background-color:rgb(132,132,250);color:black\"> -61e-6 <strong>(-0.907)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,132,132);color:black\"> 590e-6 <strong>(0.788)</strong> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> x3 </th>\n",
       "        <td style=\"background-color:rgb(232,232,250);color:black\"> -4e-6 <strong>(-0.137)</strong> </td>\n",
       "        <td style=\"background-color:rgb(187,187,250);color:black\"> -0.37e-3 <strong>(-0.481)</strong> </td>\n",
       "        <td style=\"background-color:rgb(182,182,250);color:black\"> -20e-6 <strong>(-0.524)</strong> </td>\n",
       "        <td> 0.000267 </td>\n",
       "        <td style=\"background-color:rgb(250,200,200);color:black\"> 0.50e-3 <strong>(0.336)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,202,202);color:black\"> 0.15e-3 <strong>(0.321)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,238,238);color:black\"> 0.43e-3 <strong>(0.082)</strong> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> x4 </th>\n",
       "        <td style=\"background-color:rgb(250,245,245);color:black\"> 6e-6 <strong>(0.034)</strong> </td>\n",
       "        <td style=\"background-color:rgb(122,122,250);color:black\"> -0.0042 <strong>(-0.985)</strong> </td>\n",
       "        <td style=\"background-color:rgb(124,124,250);color:black\"> -203e-6 <strong>(-0.971)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,200,200);color:black\"> 0.50e-3 <strong>(0.336)</strong> </td>\n",
       "        <td> 0.00817 </td>\n",
       "        <td style=\"background-color:rgb(250,108,108);color:black\"> 2.5e-3 <strong>(0.945)</strong> </td>\n",
       "        <td style=\"background-color:rgb(135,135,250);color:black\"> -0.026 <strong>(-0.886)</strong> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> x5 </th>\n",
       "        <td style=\"background-color:rgb(220,220,250);color:black\"> -13e-6 <strong>(-0.230)</strong> </td>\n",
       "        <td style=\"background-color:rgb(130,130,250);color:black\"> -1.3e-3 <strong>(-0.924)</strong> </td>\n",
       "        <td style=\"background-color:rgb(132,132,250);color:black\"> -61e-6 <strong>(-0.907)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,202,202);color:black\"> 0.15e-3 <strong>(0.321)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,108,108);color:black\"> 2.5e-3 <strong>(0.945)</strong> </td>\n",
       "        <td> 0.00085 </td>\n",
       "        <td style=\"background-color:rgb(146,146,250);color:black\"> -7.6e-3 <strong>(-0.802)</strong> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> x6 </th>\n",
       "        <td style=\"background-color:rgb(238,238,250);color:black\"> -57e-6 <strong>(-0.089)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,128,128);color:black\"> 0.0124 <strong>(0.816)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,132,132);color:black\"> 590e-6 <strong>(0.788)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,238,238);color:black\"> 0.43e-3 <strong>(0.082)</strong> </td>\n",
       "        <td style=\"background-color:rgb(135,135,250);color:black\"> -0.026 <strong>(-0.886)</strong> </td>\n",
       "        <td style=\"background-color:rgb(146,146,250);color:black\"> -7.6e-3 <strong>(-0.802)</strong> </td>\n",
       "        <td> 0.105 </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "┌─────────────────────────────────────────────────────────────────────────┐\n",
       "│                                Migrad                                   │\n",
       "├──────────────────────────────────┬──────────────────────────────────────┤\n",
       "│ FCN = 0.678 (χ²/ndof = 0.3)      │             Nfcn = 4028              │\n",
       "│ EDM = 2.84e-09 (Goal: 2e-08)     │                                      │\n",
       "├──────────────────────────────────┼──────────────────────────────────────┤\n",
       "│          Valid Minimum           │   Below EDM threshold (goal x 10)    │\n",
       "├──────────────────────────────────┼──────────────────────────────────────┤\n",
       "│      No parameters at limit      │           Below call limit           │\n",
       "├──────────────────────────────────┼──────────────────────────────────────┤\n",
       "│             Hesse ok             │         Covariance accurate          │\n",
       "└──────────────────────────────────┴──────────────────────────────────────┘\n",
       "┌───┬──────┬───────────┬───────────┬────────────┬────────────┬─────────┬─────────┬───────┐\n",
       "│   │ Name │   Value   │ Hesse Err │ Minos Err- │ Minos Err+ │ Limit-  │ Limit+  │ Fixed │\n",
       "├───┼──────┼───────────┼───────────┼────────────┼────────────┼─────────┼─────────┼───────┤\n",
       "│ 0 │ x0   │   0.000   │   0.002   │            │            │         │         │       │\n",
       "│ 1 │ x1   │   1.50    │   0.05    │            │            │         │         │       │\n",
       "│ 2 │ x2   │  0.3204   │  0.0023   │            │            │         │         │       │\n",
       "│ 3 │ x3   │   0.255   │   0.016   │            │            │         │         │       │\n",
       "│ 4 │ x4   │   -0.29   │   0.09    │            │            │         │         │       │\n",
       "│ 5 │ x5   │   0.114   │   0.029   │            │            │         │         │       │\n",
       "│ 6 │ x6   │   0.93    │   0.32    │            │            │         │         │       │\n",
       "└───┴──────┴───────────┴───────────┴────────────┴────────────┴─────────┴─────────┴───────┘\n",
       "┌────┬────────────────────────────────────────────────────────────────┐\n",
       "│    │       x0       x1       x2       x3       x4       x5       x6 │\n",
       "├────┼────────────────────────────────────────────────────────────────┤\n",
       "│ x0 │ 3.88e-06    -3e-6    -0e-6    -4e-6     6e-6   -13e-6   -57e-6 │\n",
       "│ x1 │    -3e-6  0.00221   108e-6 -0.37e-3  -0.0042  -1.3e-3   0.0124 │\n",
       "│ x2 │    -0e-6   108e-6 5.36e-06   -20e-6  -203e-6   -61e-6   590e-6 │\n",
       "│ x3 │    -4e-6 -0.37e-3   -20e-6 0.000267  0.50e-3  0.15e-3  0.43e-3 │\n",
       "│ x4 │     6e-6  -0.0042  -203e-6  0.50e-3  0.00817   2.5e-3   -0.026 │\n",
       "│ x5 │   -13e-6  -1.3e-3   -61e-6  0.15e-3   2.5e-3  0.00085  -7.6e-3 │\n",
       "│ x6 │   -57e-6   0.0124   590e-6  0.43e-3   -0.026  -7.6e-3    0.105 │\n",
       "└────┴────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 2.56303878e-11,  1.49954153e+00,  3.20375473e-01,  2.54581540e-01,\n",
       "       -2.89858544e-01,  1.14348073e-01,  9.25085900e-01])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<ErrorbarContainer object of 3 artists>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1347e5010>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.88, 0.8, '$\\\\chi^2/ndof=0.3$')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.88, 0.7, '$E_0=0.320\\\\pm 0.002$')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.88, 0.65, '$dlog(0)=0.434\\\\pm 0.022$')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '$T$ ')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$G(R,T)$')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=1\n",
    "k=6\n",
    "r=3\n",
    "pos=0\n",
    "\n",
    "jackkl=100000\n",
    "jump_configs=1\n",
    "\n",
    "mcalls=10000\n",
    "mtol=0.00001\n",
    "\n",
    "totaltraj=int(len(data[x][k])/size[k])\n",
    "Nt=Textent\n",
    "\n",
    "Gc=np.zeros((int(totaltraj/jump_configs),Nt))\n",
    "for i in range(int(totaltraj/jump_configs)):\n",
    "    index=jump_configs*i\n",
    "    Gc[[i]]=data[x][k][range(index*Nt,(index+1)*Nt),[r]]\n",
    "    \n",
    "#logG=np.log(ratio(trim_negative(Gc).trimmed()).val())\n",
    "\n",
    "\n",
    "# Get average over all data, we will then replicate for every Jackknife sample to get errors\n",
    "\n",
    "gdata=jackknife(Gc,jackkl).sample()\n",
    "lt=len(Gc[0])\n",
    "dfin=min(lt,100)\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_2t  = np.linspace(1, 2*lt-1, 2*lt-1)\n",
    "if pos==0:\n",
    "    data_y   = ensemble_stat(gdata).mean()\n",
    "else:\n",
    "    data_y   = gdata[pos]\n",
    "data_cov = ensemble_stat(jackknife(gdata,jackkl).up()).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(jackknife(gdata,jackkl).up()).rcov()))\n",
    "\n",
    "data_y\n",
    "np.sort(np.sqrt(np.diag(improved_inverse_covariance(data_cov))))\n",
    "\n",
    "data_covf = np.identity(lt)\n",
    "for i in range(len(np.sqrt(np.diag(data_cov)))):\n",
    "    for j in range(len(np.sqrt(np.diag(data_cov)))):\n",
    "        data_covf[i][j]*=np.sqrt(np.diag(data_cov))[i]*np.sqrt(np.diag(data_cov))[j]\n",
    "\n",
    "tini=1\n",
    "tfin=9\n",
    "\n",
    "funfit='nb_exp_np_pole'\n",
    "inipars=[0.0,1.,1.,0.1,1.0,0.1,1.0]\n",
    "#funfit='nb_exp_np'\n",
    "#inipars=[-0.46355412, -2.793052 ]\n",
    " \n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, tini, tfin, inipars, funfit , mcalls, mtol,0,1,0,0,10,10)\n",
    "\n",
    "fit=m.minimize()\n",
    "fit\n",
    "np.array(fit.values)\n",
    "\n",
    "if (len(inipars)%2==0):\n",
    "    mass  = np.abs(np.array(fit.values)[1])\n",
    "    emass = np.array(fit.errors)[1]\n",
    "else:\n",
    "    mass  = np.abs(np.array(fit.values)[2])\n",
    "    emass = np.array(fit.errors)[2]   \n",
    "\n",
    "\n",
    "dlog=loglimG(0,*np.array(fit.values)[1:])\n",
    "edlog=prop_err(0,'loglimG',np.array(fit.values)[1:],np.array(fit.errors)[1:],np.array(fit.covariance.correlation())[1:,1:])[0]\n",
    "\n",
    "data_t_plot=np.linspace(data_t[0],data_t[-1],1000)\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t_plot, eval(funfit)(data_t_plot, *fit.values), label=\"fit\")\n",
    "\n",
    "#plt.yscale('log')\n",
    "\n",
    "plt.figtext(0.88, 0.8, \n",
    "                '$\\\\chi^2/ndof={:.1f}$'.format(fit.fval/fit.ndof), \n",
    "                horizontalalignment =\"right\",  \n",
    "                verticalalignment =\"center\",  \n",
    "                wrap = True, fontsize = 12,  \n",
    "                color =\"black\")\n",
    "plt.figtext(0.88, 0.7, \n",
    "                '$E_0={:.3f}\\\\pm {:.3f}$'.format(mass,emass), \n",
    "                horizontalalignment =\"right\",  \n",
    "                verticalalignment =\"center\",  \n",
    "                wrap = True, fontsize = 12,  \n",
    "                color =\"black\")\n",
    "plt.figtext(0.88, 0.65, \n",
    "                '$dlog(0)={:.3f}\\\\pm {:.3f}$'.format(dlog,edlog), \n",
    "                horizontalalignment =\"right\",  \n",
    "                verticalalignment =\"center\",  \n",
    "                wrap = True, fontsize = 12,  \n",
    "                color =\"black\")\n",
    "plt.xlabel(\"$T$ \",fontsize=12)\n",
    "plt.ylabel(\"$G(R,T)$\",fontsize=12, rotation=90, loc='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.21117458, 1.28138604, 1.17533155, ..., 1.25877697, 1.24069075,\n",
       "       1.28731942])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(1.2513963643009975)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(1.418929864005)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gc[:,0]\n",
    "np.mean(Gc[:,0])\n",
    "np.max(Gc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.25141655, 1.25138132, 1.25143453, ..., 1.25139266, 1.25140174,\n",
       "       1.25137834])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(1.2514917829298533)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdata=jackknife(Gc,jackkl).sample()[:,0]\n",
    "gdata\n",
    "np.max(gdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.21117458, 1.28138604, 1.17533155, ..., 1.25877697, 1.24069075,\n",
       "       1.28731942])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(1.418929864005098)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jackknife(gdata,jackkl).up()\n",
    "np.max(jackknife(gdata,jackkl).up())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../S_correlators_L32/Gc_plots/xi=1/3_nb_exp_np_pole_exp_AIC_list_ti1_0_tfin16_tmin12_beta=225_R=1_nocorrs=0_g\", \"rb\") as fp:   # Unpickling\n",
    "   b = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00010075])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00010075])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00010071])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00010071])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5142635155172564)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5142635155172567)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00010122])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00010075])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.0001007])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.0001007])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdata1=b.ordered()[0][4][:,1]\n",
    "gdata2=b.ordered()[6][4][:,1]\n",
    "\n",
    "Gdata1=jackknife(gdata1,jackkl).pup()\n",
    "Gdata2=jackknife(gdata2,jackkl).pup()\n",
    "weights=[0.9,0.1]\n",
    "\n",
    "(jackknife(gdata1**2).fmean()-jackknife(gdata1).fmean()**2)*(len(gdata1)-1)\n",
    "jackknife(Gdata1**2).fmean()-jackknife(Gdata1).fmean()**2\n",
    "\n",
    "\n",
    "(jackknife(gdata2**2).fmean()-jackknife(gdata2).fmean()**2)*(len(gdata2)-1)\n",
    "jackknife(Gdata2**2).fmean()-jackknife(Gdata2).fmean()**2\n",
    "\n",
    "\n",
    "gdata=gdata1*weights[0]+gdata2*weights[1]\n",
    "gdatasq=gdata1**2*weights[0]+gdata2**2*weights[1]\n",
    "Gdata=Gdata1*weights[0]+Gdata2*weights[1]\n",
    "Gdatasq=Gdata1**2*weights[0]+Gdata2**2*weights[1]\n",
    "\n",
    "gdata.mean()\n",
    "Gdata.mean()\n",
    "\n",
    "len(gdata)\n",
    "(jackknife(gdatasq).fmean()-jackknife(gdata).fmean()**2)*(len(gdata)-1)\n",
    "jackknife(Gdatasq).fmean()-jackknife(Gdata).fmean()**2\n",
    "(jackknife(gdata**2).fmean()-jackknife(gdata).fmean()**2)*(len(gdata)-1)\n",
    "jackknife(Gdata**2).fmean()-jackknife(Gdata).fmean()**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26457516])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.26457516])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jackknife(gdata1).upcov()+jackknife(gdata1).fmean()**2\n",
    "jackknife(Gdata1**2).fmean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.33397993e-06, 1.12768105e-07],\n",
       "       [1.12768105e-07, 2.31189511e-08]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.64213682],\n",
       "       [0.64213682, 1.        ]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.27380228e-08, -2.61242528e-11],\n",
       "       [-2.61242528e-11,  1.05894645e-08]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.28327604e-07, -9.22688373e-10],\n",
       "       [-9.22688373e-10,  9.59603365e-09]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gc=np.zeros((int(totaltraj/jump_configs),Nt))\n",
    "for i in range(int(totaltraj/jump_configs)):\n",
    "    index=jump_configs*i\n",
    "    Gc[[i]]=data[x][k][range(index*Nt,(index+1)*Nt),[r]]\n",
    "    \n",
    "#logG=np.log(ratio(trim_negative(Gc).trimmed()).val())\n",
    "\n",
    "\n",
    "# Get average over all data, we will then replicate for every Jackknife sample to get errors\n",
    "\n",
    "gdata1=jackknife(jackknife(Gc,jackkl).sample()[:,0]).pup()\n",
    "gdata2=jackknife(jackknife(Gc,jackkl).sample()[:,9]).pup()\n",
    "\n",
    "np.cov(gdata1,gdata2)\n",
    "np.corrcoef(gdata1,gdata2)\n",
    "\n",
    "\n",
    "np.cov(add_gaussian_noise(gdata1,1e-7),add_gaussian_noise(gdata2,1e-8))-np.cov(gdata1,gdata2)\n",
    "np.cov(add_gaussian_noise2(gdata1,1e-7),add_gaussian_noise2(gdata2,1e-8))-np.cov(gdata1,gdata2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00010083])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.10071575])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val=Gdata1.mean()*weights[0]+Gdata2.mean()*weights[1]\n",
    "eval=(jackknife(Gdata1**2).fmean()*weights[0]+jackknife(Gdata2**2).fmean()*weights[1])\n",
    "\n",
    "val2=gdata1.mean()*weights[0]+gdata2.mean()*weights[1]\n",
    "eval2=((jackknife(gdata1).upcov()+jackknife(gdata1).fmean()**2)*weights[0]+(jackknife(gdata2).upcov()+jackknife(gdata2).fmean()**2)*weights[1])\n",
    "\n",
    "\n",
    "eval-val**2\n",
    "eval2-val2**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.37933672e-05, 4.35990770e-08, 3.11586735e-09, 1.01556374e-09,\n",
       "       4.73928161e-10, 3.33576786e-10, 2.49249539e-10, 1.83717921e-10,\n",
       "       8.16209918e-22, 6.04466121e-22])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative eig found== -8.183877357811934e-22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.37933672e-05, 4.35990770e-08, 3.11586735e-09, 1.01556374e-09,\n",
       "       4.73928161e-10, 3.33576854e-10, 2.49249489e-10, 1.83717921e-10,\n",
       "       8.15941334e-22, 1.29402036e-22])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_near_psd(A):   # As explained in N.J. Higham, \"Computing a nearest symmetric positive semidefinite matrix\" (1988): https://doi.org/10.1016/0024-3795(88)90223-6\n",
    "    if (len(np.shape(A))<2):\n",
    "        result=A\n",
    "    else:\n",
    "        C=(A + np.transpose(A))/2\n",
    "        eigval, eigvec = np.linalg.eig(C)\n",
    "        if (np.min(eigval)<0):\n",
    "            print('Negative eig found==',np.min(eigval))\n",
    "        eigval[eigval < 0] = 0\n",
    "        result=np.transpose(eigvec).dot(np.diag(eigval)).dot(eigvec)\n",
    "        #result=(result+np.transpose(result))/2\n",
    "    return result\n",
    "\n",
    "try_matrix=data_cov_R\n",
    "\n",
    "np.linalg.svd(try_matrix)[1]\n",
    "np.linalg.svd(get_near_psd(try_matrix))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.440892098500626e-16)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(5.24173948860076e-16)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1.24867594e+02, 6.54523399e-14])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 8.00848298e-03, -1.58443683e+01])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-1.58443683e+01,  1.52782926e+13])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 8.00848298e-03, -1.58443683e+01])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 8.00848298e-03, -1.58443683e+01])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def improved_inverse_covariance2(A):    # It computes the Moore-Penrose pseudo-inverse. It produces a SVD decomp and inverse, which resets small singular values via a condition related to machine precision. If no small singular values are found, it provides with the actual SVD method inversion\n",
    "    rtol=len(A)*np.finfo(np.float64).eps\n",
    "    svd=sp.linalg.svd(A)\n",
    "    eig_sign=np.round(np.real(sp.linalg.eig(A)[0])/np.abs(np.real(sp.linalg.eig(A)[0])))\n",
    "    singular_value=svd[1][-1]/svd[1][0]\n",
    "    #print(singular_value,rtol)\n",
    "    if (singular_value>rtol):\n",
    "        UT=np.transpose(svd[0])\n",
    "        inv_list=1/svd[1]*eig_sign\n",
    "        inv_list[inv_list < 0]=0\n",
    "        S_inv=np.diag(inv_list)\n",
    "        V=np.transpose(svd[2])\n",
    "        inv_A=np.dot(np.dot(V,S_inv),UT)\n",
    "    else:\n",
    "        inv_A=sp.linalg.pinvh(A)\n",
    "    return inv_A\n",
    "\n",
    "\n",
    "def improved_inverse_covariance_near_psd(A):\n",
    "    lA=len(A)\n",
    "    I=np.diag(np.ones(lA))\n",
    "    if (np.min(sp.linalg.eig(A)[0])>0):\n",
    "        result=sp.linalg.svd(A, lapack_driver='gesvd')\n",
    "        UT=np.transpose(result[0])\n",
    "        S_inv=np.diag(1./result[1])\n",
    "        V=np.transpose(result[2])\n",
    "        UT=np.transpose(V).copy()\n",
    "        inv_A=np.dot(np.dot(V,S_inv),UT)\n",
    "    else:\n",
    "        inv_A=sp.linalg.pinv(A)\n",
    "    return inv_A\n",
    "\n",
    "\n",
    "def improved_inverse_covariance(A):    # It computes the Moore-Penrose pseudo-inverse. It produces a SVD decomp and inverse, which resets small singular values via a condition related to machine precision. If no small singular values are found, it provides with the actual SVD method inversion\n",
    "    inv_A=sp.linalg.pinvh(A)\n",
    "    return inv_A\n",
    "\n",
    "try_matrix=[[1.24867594065e2,0.000000000129494060556078701111],[0.000000000129494060556078701111,6.545234e-14]]\n",
    "#try_matrix=data_cov_R\n",
    "2*np.finfo(np.float64).eps\n",
    "np.linalg.svd(try_matrix)[1][-1]/np.linalg.svd(try_matrix)[1][0]\n",
    "\n",
    "np.linalg.eig(try_matrix)[0]\n",
    "\n",
    "np.allclose(improved_inverse_covariance(try_matrix),np.transpose(improved_inverse_covariance(try_matrix)))\n",
    "np.allclose(improved_inverse_covariance2(try_matrix),np.transpose(improved_inverse_covariance2(try_matrix)))\n",
    "np.allclose(improved_inverse_covariance_no_near_psd(try_matrix),np.transpose(improved_inverse_covariance_no_near_psd(try_matrix)))\n",
    "np.allclose(np.linalg.inv(try_matrix),np.transpose(np.linalg.inv(try_matrix)))\n",
    "\n",
    "improved_inverse_covariance(try_matrix)[0]\n",
    "improved_inverse_covariance(try_matrix)[1]\n",
    "improved_inverse_covariance2(try_matrix)[0]\n",
    "improved_inverse_covariance_no_near_psd(try_matrix)[0]\n",
    "\n",
    "np.allclose(improved_inverse_covariance(try_matrix),improved_inverse_covariance2(try_matrix))\n",
    "np.max(np.abs(improved_inverse_covariance2(try_matrix)-improved_inverse_covariance_no_near_psd(try_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.2005662759242832e-100)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(-5.704278066648301e-72)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(2.6848588206907085e-61)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(-5.854123423105823e-90)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0909481305157181e-17 2.220446049250313e-15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(-4.057230209971613e-92)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0909481305157181e-17 2.220446049250313e-15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(5.664896358398598e-92)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(-1.2635288365754236e-94)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(-4.470566973604055e-93)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(5.839573907996314e-122)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(6.720390456912959e-122)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=0\n",
    "k=1\n",
    "T=1\n",
    "lt=len(Gc[0])\n",
    "totaltraj=int(len(data[x][k])/size[k])\n",
    "G_in_R=np.zeros((int(totaltraj/jump_configs),Nt))\n",
    "for i in range(int(totaltraj/jump_configs)):\n",
    "    for r in range(lt):\n",
    "        index=jump_configs*i\n",
    "        G_in_R[i][r]=data[x][k][range(index*Nt,(index+1)*Nt),[r]][T]\n",
    "\n",
    "data_cov_R=ensemble_stat(G_in_R).rcov()\n",
    "\n",
    "np.linalg.det(np.dot(sp.linalg.inv(try_matrix),try_matrix)-np.diag(np.ones(lt)))\n",
    "np.linalg.det(np.dot(try_matrix,sp.linalg.inv(try_matrix))-np.diag(np.ones(lt)))\n",
    "np.linalg.det(np.dot(np.linalg.inv(try_matrix),try_matrix)-np.diag(np.ones(lt)))\n",
    "np.linalg.det(np.dot(try_matrix,np.linalg.inv(try_matrix))-np.diag(np.ones(lt)))\n",
    "np.linalg.det(np.dot(improved_inverse_covariance2(try_matrix),try_matrix)-np.diag(np.ones(lt)))\n",
    "np.linalg.det(np.dot(try_matrix,improved_inverse_covariance2(try_matrix))-np.diag(np.ones(lt)))\n",
    "np.linalg.det(np.dot(improved_inverse_covariance_no_near_psd(try_matrix),try_matrix)-np.diag(np.ones(lt)))\n",
    "np.linalg.det(np.dot(try_matrix,improved_inverse_covariance_no_near_psd(try_matrix))-np.diag(np.ones(lt)))\n",
    "np.linalg.det(np.dot(improved_inverse_covariance(try_matrix),try_matrix)-np.diag(np.ones(lt)))\n",
    "np.linalg.det(np.dot(try_matrix,improved_inverse_covariance(try_matrix))-np.diag(np.ones(lt)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_check=[[1.e6,0],[0,-1.e-2]]\n",
    "matrix_check=get_near_psd(matrix_check)\n",
    "\n",
    "sp.linalg.eig(matrix_check)[0]\n",
    "#inv1=sp.linalg.inv(matrix_check)\n",
    "result=sp.linalg.svd(matrix_check)\n",
    "UT=np.transpose(result[0])\n",
    "S_inv=np.diag(1./result[1])\n",
    "V=np.transpose(result[2])\n",
    "result[1]\n",
    "inv2=np.dot(np.dot(V,S_inv),UT)\n",
    "sp.linalg.pinv(matrix_check, return_rank=True)[1]\n",
    "inv3=sp.linalg.pinv(matrix_check, return_rank=True)[0]\n",
    "\n",
    "inv1\n",
    "inv2\n",
    "inv3\n",
    "\n",
    "sp.linalg.det(np.dot(matrix_check,inv1)-np.diag(np.ones(2)))\n",
    "sp.linalg.det(np.dot(inv1,matrix_check)-np.diag(np.ones(2)))\n",
    "sp.linalg.det(np.dot(matrix_check,inv2)-np.diag(np.ones(2)))\n",
    "sp.linalg.det(np.dot(inv2,matrix_check)-np.diag(np.ones(2)))\n",
    "sp.linalg.det(np.dot(matrix_check,inv3)-np.diag(np.ones(2)))\n",
    "sp.linalg.det(np.dot(inv3,matrix_check)-np.diag(np.ones(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=0\n",
    "k=7\n",
    "r=8\n",
    "pos=0\n",
    "\n",
    "tini=1\n",
    "tfin=12\n",
    "\n",
    "jackkl=1000\n",
    "jump_configs=1\n",
    "\n",
    "mcalls=10000\n",
    "mtol=0.00001\n",
    "\n",
    "totaltraj=int(len(data[x][k])/size[k])\n",
    "Nt=Textent\n",
    "\n",
    "Gc=np.zeros((int(totaltraj/jump_configs),Nt))\n",
    "for i in range(int(totaltraj/jump_configs)):\n",
    "    index=jump_configs*i\n",
    "    Gc[[i]]=data[x][k][range(index*Nt,(index+1)*Nt),[r]]\n",
    "    \n",
    "#logG=np.log(ratio(trim_negative(Gc).trimmed()).val())\n",
    "\n",
    "\n",
    "# Get average over all data, we will then replicate for every Jackknife sample to get errors\n",
    "\n",
    "gdata=jackknife(Gc,jackkl).sample()\n",
    "lt=len(Gc[0])\n",
    "dfin=min(lt,100)\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_2t  = np.linspace(1, 2*lt-1, 2*lt-1)\n",
    "if pos==0:\n",
    "    data_y   = ensemble_stat(gdata).mean()\n",
    "else:\n",
    "    data_y   = gdata[pos]\n",
    "data_cov = ensemble_stat(jackknife(gdata,jackkl).up()).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(jackknife(gdata,jackkl).up()).rcov()))\n",
    "\n",
    "\n",
    "data_covf = np.identity(lt)\n",
    "for i in range(len(np.sqrt(np.diag(data_cov)))):\n",
    "    for j in range(len(np.sqrt(np.diag(data_cov)))):\n",
    "        data_covf[i][j]*=np.sqrt(np.diag(data_cov))[i]*np.sqrt(np.diag(data_cov))[j]\n",
    "\n",
    "\n",
    "funfit='nb_exp_np_pole'\n",
    "inipars=[0.,2.,1.,0.1,1.0,0.1,1.0]\n",
    "#funfit='nb_exp_np'\n",
    "#inipars=[-0.46355412, -2.793052 ]\n",
    " \n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, tini, tfin, inipars, funfit , mcalls, mtol,0,1,0,0,10,1000)\n",
    "\n",
    "m.minimize()\n",
    "\n",
    "fit=m.minimize()\n",
    "\n",
    "E_val=np.array(fit.values)[2]\n",
    "E_err=np.array(fit.errors)[2]\n",
    "\n",
    "dlog=loglimG(0,*np.array(fit.values)[1:])\n",
    "edlog=prop_err(0,'loglimG',np.array(fit.values)[1:],np.array(fit.errors)[1:],np.array(fit.covariance.correlation())[1:,1:])[0]\n",
    "chi2= m.minimize().fval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ini_jackk_pars=np.array(fit.values)\n",
    "\n",
    "dlog_jackk = []\n",
    "E_jackk    = []\n",
    "chi2_jackk = []\n",
    "for jackk in range(min(totaltraj,jackkl)):\n",
    "    pos=jackk\n",
    "    data_y=gdata[pos]\n",
    "    m=RepeatSingleFit(data_t, data_y, data_cov, tini, tfin, ini_jackk_pars, funfit , mcalls, mtol,0,1,0,0,10,0)\n",
    "    if (m.minimize().valid==False):\n",
    "        print('Trying fix',jackk)\n",
    "        ntries=50\n",
    "        for k in range(ntries):\n",
    "            s = np.random.normal(0, 0.01, len(ini_jackk_pars))\n",
    "            inipars_list=(1+s)*ini_jackk_pars\n",
    "            m2=RepeatSingleFit(data_t, data_y, data_cov, tini, tfin, inipars_list, funfit , mcalls, mtol,0,1,0,0,10,0)\n",
    "            if (m2.minimize().valid):\n",
    "                m=m2\n",
    "                break\n",
    "\n",
    "    if (m.minimize().valid==False):\n",
    "        print('Not valid',jackk)\n",
    "\n",
    "    fit=m.minimize()\n",
    "    dlog_jackk.append(loglimG(0,*np.array(fit.values)[1:]))\n",
    "    E_jackk.append(np.array(fit.values)[2])\n",
    "    chi2_jackk.append(fit.fval)\n",
    "\n",
    "\n",
    "print(dlog,edlog)\n",
    "print(ensemble_stat(dlog_jackk).mean(),np.sqrt(ensemble_stat(jackknife(dlog_jackk).up()).rcov()))\n",
    "print(E_val,E_err)\n",
    "print(ensemble_stat(E_jackk).mean(),np.sqrt(ensemble_stat(jackknife(E_jackk).up()).rcov()))\n",
    "chi2_f_jackk=np.mean(chi2_jackk)-((tfin-tini+1)-len(inipars))/(len(chi2_jackk)-1)\n",
    "print(chi2,chi2_f_jackk,np.abs(chi2_f_jackk-chi2)/chi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocess=10\n",
    "filefin=0\n",
    "multistart=100\n",
    "\n",
    "mcalls=10000\n",
    "mtol=0.00001\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Select data files to be fitted\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "datarun=[]\n",
    "dataint  = data[xiini:xifin+1]\n",
    "for i in range(len(dataint)):\n",
    "    datarun.append(dataint[i][fileini:filefin+1])\n",
    "\n",
    "sizerun  = size[fileini:filefin+1]\n",
    "betarun  = beta[fileini:filefin+1]\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#Prepare options for fitting\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "if (dini_Gc==0):\n",
    "    diini  = 0\n",
    "    distop = 0\n",
    "else:\n",
    "    diini   = dini_Gc\n",
    "    distop = dini_Gc+dstop_Gc\n",
    "    \n",
    "x=0\n",
    "k=0\n",
    "r=5\n",
    "\n",
    "totaltraj=int(len(data[x][k])/size[k])\n",
    "Nt=Textent\n",
    "\n",
    "Gc=np.zeros((totaltraj,Nt))\n",
    "for i in range(totaltraj):\n",
    "    Gc[[i]]=data[x][k][range(i*Nt,(i+1)*Nt),[r]]\n",
    "    \n",
    "logG=np.log(ratio(trim_negative(Gc).trimmed()).val())\n",
    "\n",
    "\n",
    "# Get average over all data, we will then replicate for every Jackknife sample to get errors\n",
    "jackkl=10000\n",
    "\n",
    "#datatype_Gc='exp'\n",
    "\n",
    "\n",
    "if (datatype_Gc==\"dlog\"):\n",
    "    gdata=np.log(ratio(trim_negative(jackknife(Gc,jackkl).sample()).trimmed()).val())\n",
    "elif (datatype_Gc==\"log\" or datatype_Gc==\"log_pole\"):\n",
    "    gdata=np.log(trim_negative(jackknife(Gc,jackkl).sample()).trimmed())\n",
    "    #gdata=np.log(trim_negative(Gc).trimmed())\n",
    "elif (datatype_Gc==\"exp\" or datatype_Gc==\"exp_WL\" or datatype_Gc==\"exp_line\"):\n",
    "    gdata=jackknife(Gc,jackkl).sample()\n",
    "\n",
    "gdata=jackknife(gdata,jackkl).up()\n",
    "\n",
    "\n",
    "lt=len(gdata[0])\n",
    "dfin=min(lt,100)\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = jackknife(gdata,jackkl).sample()\n",
    "data_cov = jackknife(gdata,jackkl).scov()\n",
    "\n",
    "\n",
    "model_Gc='nb_exp_np_pole'\n",
    "inipars_Gc  = [[0.0,2.0,1.0],[0.0,2.0,1.0,0.1,1.0],[0.0,2.0,1.0,0.1,1.0,0.1,1.0]]                                                                                        # Input pars to fit with\n",
    "variants_Gc = ['single','double','triple']  \n",
    "#dmindata_Gc=5\n",
    "\n",
    "m=Modelsmin(data_t, data_y, data_cov, dini_Gc, dstop_Gc, dmindata_Gc, dfin_Gc, inipars_Gc, model_Gc, variants_Gc, datatype_Gc, mcalls, mtol, reuse, inv_first, multiprocess,cov_freeze,improve,multistart,no_corrs,no_valid_check)\n",
    "mf=m.jackk_minimize()\n",
    "AIC_list=Jackknife_AIClist(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC_list.ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC_list.avgval0(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=1\n",
    "\n",
    "betarun  = beta[0:11]\n",
    "xirun    = xi\n",
    "diini    = 1\n",
    "variants_Gc=[1,2]\n",
    "\n",
    "Vdat=[]\n",
    "for i in range(len(betarun)):\n",
    "    print('{}{}/{}_{}_{}_VR_rescaled_ti{}_{}_tfin{}_tmin{}_cut{}_beta={}_nocorrs={}_{}.dat'.format(resultspath,xi[0],len(variants_Gc),model_Gc,datatype_Gc,diini,dstop_Gc,dfin_Gc,dmindata_Gc,cutoff_ma,betarun[i],no_corrs,corrtype))\n",
    "    Vdat_int=np.loadtxt('{}{}/{}_{}_{}_VR_rescaled_ti{}_{}_tfin{}_tmin{}_cut{}_beta={}_nocorrs={}_{}.dat'.format(resultspath,xi[0],len(variants_Gc),model_Gc,datatype_Gc,diini,dstop_Gc,dfin_Gc,dmindata_Gc,cutoff_ma,betarun[i],no_corrs,corrtype))\n",
    "    Vdat.append(Vdat_int)\n",
    "\n",
    "lt       = len(Vdat[0][0])\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_tf  = np.linspace(1, lt, 100*lt)\n",
    "data_y   = ensemble_stat(Vdat[k]).mean()\n",
    "data_cov = ensemble_stat(Vdat[k]).rcov()     # Do not use these non-diagonal elements, they come from a rescaled sample, they are not correct\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(Vdat[k]).rcov()))\n",
    "\n",
    "data_y\n",
    "data_err\n",
    "\n",
    "pos=0\n",
    "\n",
    "jackkl=100000\n",
    "jump_configs=1\n",
    "\n",
    "mcalls=10000\n",
    "mtol=0.00001\n",
    "\n",
    "\n",
    "rini=1\n",
    "rfin=12\n",
    "\n",
    "funfit='nb_VR_line'\n",
    "inipars=[0.0,2.,1.]\n",
    " \n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, rini, rfin, inipars, funfit , mcalls, mtol,0,1,0,0,10,10)\n",
    "\n",
    "fit=m.minimize()\n",
    "fit\n",
    "np.array(fit.values)\n",
    "\n",
    "\n",
    "sigma  = np.abs(np.array(fit.values)[2])/als[0][k]**2/0.44**2/gev_m1_tofm**2\n",
    "esigma = np.array(fit.errors)[2]/als[0][k]**2/0.44**2/gev_m1_tofm**2\n",
    "\n",
    "\n",
    "data_t_plot=np.linspace(data_t[0],data_t[-1],1000)\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t_plot, eval(funfit)(data_t_plot, *fit.values), label=\"fit\")\n",
    "\n",
    "#plt.yscale('log')\n",
    "\n",
    "plt.figtext(0.35, 0.8, \n",
    "                '$\\\\chi^2/ndof={:.1f}$'.format(fit.fval/fit.ndof), \n",
    "                horizontalalignment =\"right\",  \n",
    "                verticalalignment =\"center\",  \n",
    "                wrap = True, fontsize = 12,  \n",
    "                color =\"black\")\n",
    "plt.figtext(0.35, 0.7, \n",
    "                '$\\\\sigma={:.2f}\\\\pm {:.2f}$'.format(sigma,esigma), \n",
    "                horizontalalignment =\"right\",  \n",
    "                verticalalignment =\"center\",  \n",
    "                wrap = True, fontsize = 12,  \n",
    "                color =\"black\")\n",
    "plt.xlabel(\"$R$ \",fontsize=12)\n",
    "plt.ylabel(\"$V(R)$\",fontsize=12, rotation=90, loc='center')\n",
    "plt.ylim(0,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../S_correlators_L32/Gc_plots/xi=4/2_nb_exp_np_pole_exp_AIC_list_ti1_0_tfin16_tmin12_beta=225_R=1_nocorrs=0_g\", \"rb\") as fp:   # Unpickling\n",
    "   b = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing autocorrelations, based on page 94 from Gattringer and Lang's and page 184 of Degrand and Detar\n",
    "\n",
    "def auto_func(t,a,b):\n",
    "    return a*np.exp(-t/b)\n",
    "\n",
    "def autocorr(list,dt):\n",
    "    mean=np.mean(list)\n",
    "    mean1=0\n",
    "    mean2=0\n",
    "    Ncfgs=len(list)\n",
    "    corr1=0\n",
    "    corr2=0\n",
    "    for i in range(Ncfgs-dt):\n",
    "        corr1+=(list[i]*list[i+dt])/(Ncfgs-dt)\n",
    "        corr2+=(list[i]-mean)*(list[i+dt]-mean)/(Ncfgs-dt)\n",
    "        mean1+=list[i]/(Ncfgs-dt)\n",
    "        mean2+=list[i+dt]/(Ncfgs-dt)\n",
    "    \n",
    "    corr1-=mean1*mean2\n",
    "    return corr2\n",
    "\n",
    "xi_range=1\n",
    "r_range=10\n",
    "r_ini=1\n",
    "tval=10\n",
    "t_ini=1\n",
    "ergodic_T=100\n",
    "\n",
    "for beta_label in range(len(beta)):\n",
    "\n",
    "    fig = plt.figure(figsize=(16,9))\n",
    "    plt.legend(fontsize=12,frameon=False,loc=0)\n",
    "\n",
    "    for x in range(xi_range):\n",
    "        corr_ergodic_final=[]\n",
    "\n",
    "        jump_configs=1\n",
    "        #print(len(data[x][beta_label]))\n",
    "        totaltraj=int(len(data[x][beta_label])/size[beta_label])\n",
    "        Nt=Textent\n",
    "        Gc=np.zeros((int(totaltraj/jump_configs),Nt))\n",
    "\n",
    "        for r in range(r_ini,r_ini+r_range):\n",
    "            for i in range(int(totaltraj/jump_configs)):\n",
    "                index=jump_configs*i\n",
    "                Gc[[i]]=data[x][beta_label][range(index*Nt,(index+1)*Nt),[r]]\n",
    "\n",
    "            data_ergodic   = np.linspace(0, ergodic_T, ergodic_T+1)\n",
    "            corr_ergodic=[]\n",
    "            for i in data_ergodic:\n",
    "                inter=0\n",
    "                for k in range(t_ini,t_ini+tval):\n",
    "                     inter+=autocorr(Gc[:,k],int(i))/autocorr(Gc[:,k],0)/tval\n",
    "\n",
    "                corr_ergodic.append(inter)\n",
    "\n",
    "            corr_ergodic_final.append(corr_ergodic)\n",
    "\n",
    "        final_autocor=np.mean(corr_ergodic_final,axis=0)\n",
    "        fit_autocor=sp.optimize.curve_fit(auto_func,data_ergodic,final_autocor)\n",
    "        time_autoco=fit_autocor[0][1]\n",
    "\n",
    "        plt.plot(data_ergodic, final_autocor, label='$\\\\xi={},\\\\tau={:10.2f}$'.format(x+1,time_autoco),color=jpac_color_around[x])\n",
    "        plt.legend(fontsize=12,frameon=False,loc=1)\n",
    "        #plt.plot(data_ergodic, auto_func(data_ergodic,fit_autocor[0][0],fit_autocor[0][1]), label=\"fit\",color=\"blue\")\n",
    "\n",
    "    plt.figtext(0.4, 0.8, \n",
    "                '$L={},\\, \\\\beta={}$'.format(sizelabel,beta[beta_label]/betanorm), \n",
    "                horizontalalignment =\"center\",  \n",
    "                verticalalignment =\"center\",  \n",
    "                wrap = True, fontsize = 20,  \n",
    "                color =\"black\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi_range=2\n",
    "r_range=1\n",
    "r_ini=15\n",
    "tval=1\n",
    "t_ini=1\n",
    "ergodic_T=100\n",
    "\n",
    "for beta_label in range(1,2+0*len(beta)):\n",
    "\n",
    "    fig = plt.figure(figsize=(16,9))\n",
    "    plt.legend(fontsize=12,frameon=False,loc=0)\n",
    "\n",
    "    for x in range(xi_range):\n",
    "        jump_configs=1\n",
    "        #print(len(data[x][beta_label]))\n",
    "        totaltraj=int(len(data[x][beta_label])/size[beta_label])\n",
    "        Nt=Textent\n",
    "        Gc=np.zeros((totaltraj,Nt))\n",
    "        Gc_avg=np.zeros(totaltraj)\n",
    "\n",
    "        for i in range(totaltraj):\n",
    "            for r in range(r_ini,r_ini+r_range):\n",
    "                index=jump_configs*i\n",
    "                Gc[[i]]+=data[x][beta_label][range(index*Nt,(index+1)*Nt),[r]]/r_range\n",
    "\n",
    "            for k in range(t_ini,t_ini+tval):\n",
    "                Gc_avg[[i]]+=Gc[i,k]/tval\n",
    "                \n",
    "\n",
    "        data_ergodic   = np.linspace(0, ergodic_T, ergodic_T+1)\n",
    "        corr_ergodic=[]\n",
    "        corr_ergodic_final=[]\n",
    "        for i in data_ergodic:\n",
    "            inter=autocorr(Gc_avg,int(i))/autocorr(Gc_avg,0)\n",
    "            corr_ergodic.append(inter)\n",
    "        corr_ergodic_final.append(corr_ergodic)\n",
    "\n",
    "        final_autocor=np.mean(corr_ergodic_final,axis=0)\n",
    "        fit_autocor=sp.optimize.curve_fit(auto_func,data_ergodic,final_autocor)\n",
    "        time_autoco=fit_autocor[0][1]\n",
    "\n",
    "        plt.plot(data_ergodic, final_autocor, label='$\\\\xi={},\\\\tau={:10.2f},Ncfgs={}$'.format(x+1,time_autoco,totaltraj),color=jpac_color_around[x])\n",
    "        plt.legend(fontsize=12,frameon=False,loc=1)\n",
    "        #plt.plot(data_ergodic, auto_func(data_ergodic,fit_autocor[0][0],fit_autocor[0][1]), label=\"fit\",color=\"blue\")\n",
    "\n",
    "    plt.figtext(0.4, 0.8, \n",
    "                '$L={},\\, \\\\beta={}$'.format(sizelabel,beta[beta_label]/betanorm), \n",
    "                horizontalalignment =\"center\",  \n",
    "                verticalalignment =\"center\",  \n",
    "                wrap = True, fontsize = 20,  \n",
    "                color =\"black\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_s=20\n",
    "repeat=100\n",
    "data_to_repeat=np.genfromtxt('../tests/Arkaitz-2.75.dat')\n",
    "data_test=np.zeros(repeat*len_s)\n",
    "\n",
    "for k in range(repeat):\n",
    "    for i in range(len_s):\n",
    "        data_test[[i+k*len_s]]=data_to_repeat[i+k][1]\n",
    "\n",
    "data_test   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test=np.genfromtxt('../tests/Arkaitz-2.75.dat')[:20\n",
    "\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "plt.legend(fontsize=12,frameon=False,loc=0)\n",
    "\n",
    "ergodic_T=80\n",
    "data_ergodic   = np.linspace(0, ergodic_T, ergodic_T+1)\n",
    "corr_ergodic=[]\n",
    "corr_ergodic_final=[]\n",
    "for i in data_ergodic:\n",
    "    inter=autocorr(data_test[:],int(i))/autocorr(data_test[:],0)\n",
    "    corr_ergodic.append(inter)\n",
    "\n",
    "corr_ergodic_final.append(corr_ergodic)\n",
    "\n",
    "final_autocor=corr_ergodic_final[0]\n",
    "fit_autocor=sp.optimize.curve_fit(auto_func,data_ergodic,final_autocor)\n",
    "time_autoco=fit_autocor[0][1]\n",
    "plt.scatter(data_ergodic, final_autocor, label='$\\\\beta=2.75,\\\\tau={:10.2f}$'.format(time_autoco),color=jpac_color_around[x])\n",
    "plt.legend(fontsize=12,frameon=False,loc=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if Jackknife is correct, we will test central values and errors\n",
    "\n",
    "x=0\n",
    "k=0\n",
    "r=0\n",
    "\n",
    "totaltraj=int(len(data[x][k])/size[k])\n",
    "Nt=Textent\n",
    "\n",
    "Gc=np.zeros((totaltraj,Nt))\n",
    "for i in range(totaltraj):\n",
    "    Gc[[i]]=data[x][k][range(i*Nt,(i+1)*Nt),[r]]\n",
    "    \n",
    "data_y   = ensemble_stat(Gc).mean()\n",
    "\n",
    "data_y\n",
    "\n",
    "np.mean(jackknife(Gc).sample(),axis=0) \n",
    "jackknife(jackknife(Gc).sample()).up() \n",
    "\n",
    "# These two are identical to one another\n",
    "ensemble_stat(Gc).rcov()[0]\n",
    "jackknife(Gc).fcov()[0]\n",
    "jackknife(jackknife(Gc).sample()).upcov()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing minimizer's precision/accuracy\n",
    "factor=10\n",
    "ntrials=100\n",
    "mcalls=5000\n",
    "mtol=0.0001\n",
    "hack=0\n",
    "\n",
    "\n",
    "data_incov=improved_inverse_covariance(data_cov)\n",
    "def least_squares_scipy(par):  # we must accept a variable number of model parameters\n",
    "    ym = exp_np(data_t, *par)\n",
    "    return np.dot(np.dot((data_y - ym), data_incov),(data_y - ym))\n",
    "\n",
    "count1=0\n",
    "count2=0\n",
    "count3=0\n",
    "count4=0\n",
    "count5=0\n",
    "\n",
    "m1list=[]\n",
    "m1chilist=[]\n",
    "m2list=[]\n",
    "m2chilist=[]\n",
    "m3list=[]\n",
    "m3chilist=[]\n",
    "m4list=[]\n",
    "m4chilist=[]\n",
    "m5list=[]\n",
    "m5chilist=[]\n",
    "m6list=[]\n",
    "\n",
    "\n",
    "for i in range(ntrials):\n",
    "    inipars=np.array([0.0756601070458546,1.8388443700832076,0.2397704868012228,0.081132649591307,0.3404256622175537])\n",
    "    einipars=factor*inipars\n",
    "    s = np.random.normal(0, 1, len(inipars))\n",
    "    inipars=inipars+s*einipars\n",
    "    least_squares_np = EvenBetterLeastSquares(eval('nb_exp_np_pole'), data_t, data_y, data_incov)\n",
    "    m=Minuit(least_squares_np,*inipars)   # pass starting values as a sequence\n",
    "    m.strategy=1\n",
    "    m.tol=mtol\n",
    "    result1=m.migrad(mcalls)\n",
    "    m2=Minuit(least_squares_np,*inipars)   # pass starting values as a sequence\n",
    "    m2.strategy=2\n",
    "    m2.tol=mtol\n",
    "    result2=m2.scipy('COBYLA',mcalls).simplex(mcalls).scipy('CG',mcalls).migrad(mcalls).migrad(mcalls).migrad(mcalls)\n",
    "    m3=Minuit(least_squares_np,*inipars)   # pass starting values as a sequence\n",
    "    m3.strategy=2\n",
    "    m3.tol=mtol\n",
    "    result3=m3.scipy('CG',mcalls).scipy('L-BFGS-B',mcalls).migrad(mcalls).migrad(mcalls)\n",
    "    m4=Minuit(least_squares_np,*inipars)   # pass starting values as a sequence\n",
    "    m4.strategy=2\n",
    "    m4.tol=mtol\n",
    "    result4=m4.simplex(mcalls).simplex(mcalls).scipy('CG',mcalls).scipy('L-BFGS-B',mcalls).migrad(mcalls).migrad(mcalls).migrad(mcalls)\n",
    "\n",
    "\n",
    "    np.set_printoptions(precision=16)\n",
    "    \n",
    "\n",
    "    if result1.valid:\n",
    "        count1+=1\n",
    "    if result1.valid or hack==1:\n",
    "        m1list.append(np.abs(np.array(result1.values)))\n",
    "        m1chilist.append(result1.fval/result1.ndof)\n",
    "\n",
    "    if result2.valid:\n",
    "        count2+=1\n",
    "    if result2.valid or hack==1:\n",
    "        m2list.append(np.abs(np.array(result2.values)))\n",
    "        m2chilist.append(result2.fval/result2.ndof)\n",
    "\n",
    "    if result3.valid:\n",
    "        count3+=1\n",
    "    if result3.valid or hack==1:\n",
    "        m3list.append(np.abs(np.array(result3.values)))\n",
    "        m3chilist.append(result3.fval/result3.ndof)\n",
    "\n",
    "    if result4.valid:\n",
    "        count4+=1\n",
    "    if result4.valid or hack==1:\n",
    "        m4list.append(np.abs(np.array(result4.values)))\n",
    "        m4chilist.append(result4.fval/result4.ndof)\n",
    "\n",
    "\n",
    "    bounds=[]\n",
    "    for i in inipars:   \n",
    "        bounds.append((0,factor*abs(i)))\n",
    "\n",
    "    #res1=sp.optimize.basinhopping(least_squares_scipy,inipars,niter=10)\n",
    "    #m5list.append(np.abs(res1.x))\n",
    "    #m5chilist.append(res1.fun/result4.ndof)\n",
    "    #inipars5=np.array(res1.x)\n",
    "    m5=Minuit(least_squares_np,*inipars)\n",
    "    m5.tol=mtol\n",
    "    m5.strategy=2\n",
    "    res1=m5.scipy('Nelder-Mead',mcalls).scipy('CG',mcalls).scipy('Nelder-Mead',mcalls).scipy('L-BFGS-B',mcalls).migrad(mcalls).migrad(mcalls).migrad(mcalls)\n",
    "\n",
    "    if res1.valid:\n",
    "        count5+=1\n",
    "    if res1.valid or hack==1:\n",
    "        m5list.append(np.abs(np.array(res1.values)))\n",
    "        m5chilist.append(res1.fval/res1.ndof)\n",
    "\n",
    "\n",
    "m1list=np.array(m1list)\n",
    "m1chilist=np.array(m1chilist)\n",
    "m2list=np.array(m2list)\n",
    "m2chilist=np.array(m2chilist)\n",
    "m3list=np.array(m3list)\n",
    "m3chilist=np.array(m3chilist)\n",
    "m4list=np.array(m4list)\n",
    "m4chilist=np.array(m4chilist)\n",
    "m5list=np.array(m5list)\n",
    "m5chilist=np.array(m5chilist)\n",
    "\n",
    "\n",
    "#np.mean(m1list,axis=0)\n",
    "#np.mean(m2list,axis=0)\n",
    "#np.mean(m3list,axis=0)\n",
    "#np.mean(m4list,axis=0)\n",
    "#np.mean(m5list,axis=0)\n",
    "\n",
    "count1\n",
    "count2\n",
    "count3\n",
    "count4\n",
    "count5\n",
    "\n",
    "np.mean(m1chilist,axis=0)\n",
    "np.mean(m2chilist,axis=0)\n",
    "np.mean(m3chilist,axis=0)\n",
    "np.mean(m4chilist,axis=0)\n",
    "np.mean(m5chilist,axis=0)\n",
    "\n",
    "np.sqrt(np.var(m1list,axis=0))\n",
    "np.sqrt(np.var(m2list,axis=0))\n",
    "np.sqrt(np.var(m3list,axis=0))\n",
    "np.sqrt(np.var(m4list,axis=0))\n",
    "np.sqrt(np.var(m5list,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-start procedure for \"global minimization\"\n",
    "# This works by providing the maximum amount of points you want to start sampling with. It produces a \n",
    "\n",
    "x=0\n",
    "k=10\n",
    "r=11\n",
    "\n",
    "jackkl=20000\n",
    "jump_configs=1\n",
    "\n",
    "mcalls=5000\n",
    "mtol=0.0001\n",
    "factor=1\n",
    "nsamples=1000\n",
    "strategy=2\n",
    "\n",
    "totaltraj=int(len(data[x][k])/size[k])\n",
    "Nt=Textent\n",
    "\n",
    "Gc=np.zeros((int(totaltraj/jump_configs),Nt))\n",
    "for i in range(int(totaltraj/jump_configs)):\n",
    "    index=jump_configs*i\n",
    "    Gc[[i]]=data[x][k][range(index*Nt,(index+1)*Nt),[r]]\n",
    "    \n",
    "#logG=np.log(ratio(trim_negative(Gc).trimmed()).val())\n",
    "\n",
    "\n",
    "# Get average over all data, we will then replicate for every Jackknife sample to get errors\n",
    "\n",
    "gdata=jackknife(Gc,jackkl).sample()\n",
    "gdata=jackknife(gdata,jackkl).up()\n",
    "lt=len(Gc[0])\n",
    "dfin=min(lt,100)\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_2t  = np.linspace(1, 2*lt-1, 2*lt-1)\n",
    "data_y   = ensemble_stat(gdata).mean()\n",
    "data_cov = ensemble_stat(gdata).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(gdata).rcov()))\n",
    "data_incov=improved_inverse_covariance(data_cov)\n",
    "\n",
    "data_covf = np.identity(lt)\n",
    "for i in range(len(np.sqrt(np.diag(data_cov)))):\n",
    "    for j in range(len(np.sqrt(np.diag(data_cov)))):\n",
    "        data_covf[i][j]*=np.sqrt(np.diag(data_cov))[i]*np.sqrt(np.diag(data_cov))[j]\n",
    "\n",
    "\n",
    "\n",
    "pars_best=[-0.0756601021475849,1.838844370954277,0.2397704868229662,0.0811326516777515,0.3404256638585156]\n",
    "fit_best=1.6972963589305958\n",
    "\n",
    "inipars=np.array([0.0,2.0,1.0,0.1,1.0])\n",
    "einipars=inipars.copy()\n",
    "for j in range(len(einipars)):\n",
    "    einipars[j]=max(0.01,einipars[j])\n",
    "einipars*=factor\n",
    "\n",
    "least_squares_np = EvenBetterLeastSquares(eval('nb_exp_np_pole'), data_t, data_y, data_incov)\n",
    "\n",
    "inipars_list=[]\n",
    "for i in range(nsamples):\n",
    "    s = np.random.normal(0, 1, len(inipars))\n",
    "    inipars_list.append(inipars+s*einipars)\n",
    "\n",
    "fit_results=[]\n",
    "minimized=0\n",
    "par_results=[]\n",
    "for i in range(len(inipars_list)):\n",
    "    m=Minuit(least_squares_np,*inipars_list[i])\n",
    "    m.tol=mtol\n",
    "    m.strategy=strategy\n",
    "    result_fit=m.simplex(mcalls).scipy('L-BFGS-B',mcalls).migrad(mcalls).migrad(mcalls)\n",
    "    #result_fit=m.simplex(mcalls).scipy('CG',mcalls).simplex(mcalls).scipy('L-BFGS-B',mcalls).migrad(mcalls).migrad(mcalls)\n",
    "    if (result_fit.valid):\n",
    "        minimized+=1\n",
    "        par_results.append(np.array(result_fit.values))\n",
    "\n",
    "    fit_results.append(result_fit.fval/result_fit.ndof)\n",
    "\n",
    "correct=0\n",
    "for i in range(nsamples):\n",
    "    if (np.abs(fit_results[i]-1)<100):\n",
    "        correct+=1\n",
    "\n",
    "minimized\n",
    "correct\n",
    "\n",
    "np.mean(np.sqrt(np.var(par_results,axis=0)))   # Mean of variation on parameter results over fits\n",
    "\n",
    "np.min(fit_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./'\n",
    "list_data_tpa=[];list_data_effm_f=[];list_data_effm_err_f=[];list_data_tp=[];list_data_effmp=[];list_data_effm_errp=[];list_data_tf=[];list_fitall=[];list_efitall=[];list_data_tpf=[];list_fit=[];list_efit=[]\n",
    "data_tpa, data_effm_f, data_effm_err_f, data_tp, data_effmp, data_effm_errp, data_tf, fitall, efitall, data_tpf, fit, efit=plotGc(data_t, data_y, data_cov, AIC_list, datatype_Gc, model_Gc, mcalls, mtol, reuse, inv_first, xi[0], path,0,0.05).prepare()  \n",
    "list_data_tpa.append(data_tpa);list_data_effm_f.append(data_effm_f);list_data_effm_err_f.append(data_effm_err_f);list_data_tp.append(data_tp);list_data_effmp.append(data_effmp);list_data_effm_errp.append(data_effm_errp);list_data_tf.append(data_tf);list_fitall.append(fitall);list_efitall.append(efitall);list_data_tpf.append(data_tpf);list_fit.append(fit);list_efit.append(efit)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "plt.fill_between(data_tf, fitall+efitall, fitall-efitall,color=jpac_blue,alpha=0.1)\n",
    "plt.fill_between(data_tpf, fit+efit, fit-efit,color=jpac_blue,alpha=0.7)\n",
    "if (len(data_tp)>=1):\n",
    "    plt.errorbar(data_tpa, data_effm_f, data_effm_err_f, fmt=\"ok\", alpha=0.3)\n",
    "    plt.errorbar(data_tp, data_effmp, data_effm_errp, fmt=\"ok\")\n",
    "plt.xlabel(\"$t/a_t$\",fontsize=24)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.legend(fontsize=16,frameon=False)\n",
    "plt.show(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compact_eff_m(list_data_tpa, list_data_effm_f, list_data_effm_err_f, list_data_tp, list_data_effmp, list_data_effm_errp, list_data_tf, list_fitall, list_efitall, list_data_tpf, list_fit, list_efit, path, beta, y_lim):   \n",
    "    fig = plt.figure(figsize=(16,9))\n",
    "    for i in range(len(list_data_tpa)):\n",
    "        alphamult=1\n",
    "        data_tf=list_data_tf[i];data_tpf=list_data_tpf[i];fitall=list_fitall[i];efitall=list_efitall[i];fit=list_fit[i];efit=list_efit[i];data_tpa=list_data_tpa[i];\n",
    "        data_tp=list_data_tp[i];data_effm_f=list_data_effm_f[i];data_effmp=list_data_effmp[i];data_effm_err_f=list_data_effm_err_f[i];data_effm_errp=list_data_effm_errp[i]\n",
    "        if (fitall[-1]>y_lim):\n",
    "            alphamult=0\n",
    "        plt.fill_between(data_tf, fitall+efitall, fitall-efitall,color=jpac_color_around[i],alpha=alphamult*0.1)\n",
    "        plt.fill_between(data_tpf, fit+efit, fit-efit,color=jpac_color_around[i],alpha=alphamult*0.7)\n",
    "        if (len(data_tp)>=1):\n",
    "            plt.errorbar(data_tpa, data_effm_f, data_effm_err_f,color=jpac_color_around[i], fmt=\"ok\", alpha=alphamult*0.3)\n",
    "            plt.errorbar(data_tp, data_effmp, data_effm_errp,color=jpac_color_around[i], fmt=\"ok\",alpha=alphamult*1)\n",
    "    plt.xlabel(\"$t/a_t$\",fontsize=24)\n",
    "    plt.ylabel(\"$\\\\beta={}$\".format(beta),fontsize=24, rotation=0, loc='top')\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.ylim(None,y_lim)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.legend(fontsize=16,frameon=False)\n",
    "    #plt.show()\n",
    "    plt.savefig('{}_compact.pdf'.format(path), format=\"pdf\", bbox_inches='tight', pad_inches=0.2)\n",
    "    plt.close(fig)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compact_eff_m(list_data_tpa,list_data_effm_f,list_data_effm_err_f,list_data_tp,list_data_effmp,list_data_effm_errp,list_data_tf,list_fitall,list_efitall,list_data_tpf,list_fit,list_efit,'/',2.25,1.)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileini=filefin=2\n",
    "datarun=[]\n",
    "dataint  = data[xiini:xifin+1]\n",
    "xirun    = xi[xiini:xifin+1]\n",
    "for i in range(len(dataint)):\n",
    "    datarun.append(dataint[i][fileini:filefin+1])\n",
    "\n",
    "\n",
    "sizerun  = size[fileini:filefin+1]\n",
    "betarun  = beta[fileini:filefin+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multistart=10\n",
    "jackkl=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gcplotsdircompact='{}_compact'.format(Gcplotsdir)\n",
    "AIC_list_final=[]\n",
    "for k in range(len(datarun)):\n",
    "    print('Attempting fits to xi={}'.format(xirun[k]))\n",
    "    path=['{}/xi={}'.format(Gcplotsdir,xirun[k]),'{}/xi={}'.format(Gcplotsdircompact,xirun[k])]\n",
    "    result=fitter(datarun[k], sizerun, dini_Gc, dstop_Gc, dmindata_Gc, dfin_Gc, datatype_Gc, model_Gc, inipars_Gc, variants_Gc, mcalls, mtol, reuse, inv_first, multiprocess, cutoff_ma, xirun[k], betarun, path, corrtype, norm, cov_freeze, improve, multistart, no_corrs, no_valid_check)\n",
    "    Vrlistavg, Vrlistavg_rescaled, Vrlistsel, worstsel, listfinal , datayf=result.jackk_fit(jackkl)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC_list_final.append(listfinal)\n",
    "#Store the V(R) data Jackknife results\n",
    "Vrf=[]\n",
    "for i in range(len(datarun[k])):\n",
    "    Vrf.append(jackknife(Vrlistavg[i]).up())\n",
    "    np.savetxt('{}{}/{}_{}_{}_VR_ti{}_{}_tfin{}_tmin{}_cut{}_beta={}_nocorrs={}_{}.dat'.format(resultspath,xirun[k],len(variants_Gc),model_Gc,datatype_Gc,dini_Gc,dstop_Gc,dfin_Gc,dmindata_Gc,cutoff_ma,betarun[i],no_corrs,corrtype), jackknife(Vrlistavg[i]).up())\n",
    "    np.savetxt('{}{}/{}_{}_{}_VR_rescaled_ti{}_{}_tfin{}_tmin{}_cut{}_beta={}_nocorrs={}_{}.dat'.format(resultspath,xirun[k],len(variants_Gc),model_Gc,datatype_Gc,dini_Gc,dstop_Gc,dfin_Gc,dmindata_Gc,cutoff_ma,betarun[i],no_corrs,corrtype), jackknife(Vrlistavg_rescaled[i]).up())\n",
    "    np.savetxt('{}{}/{}_{}_{}_worstsel_ti{}_{}_tfin{}_tmin{}_cut{}_beta={}_nocorrs={}_{}.dat'.format(resultspath,xirun[k],len(variants_Gc),model_Gc,datatype_Gc,dini_Gc,dstop_Gc,dfin_Gc,dmindata_Gc,cutoff_ma,betarun[i],no_corrs,corrtype), [worstsel[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cov[5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cov_rescaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagn=6\n",
    "jackknife(Vdat,jackkl).scov()[0][diagn][diagn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jackknife(jackknife(Vdat_rescaled,jackkl).sample()).upcov()[diagn][diagn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multistart = 10\n",
    "improve    = 0\n",
    "\n",
    "datarun=[]\n",
    "dataint  = data[xiini:xifin+1]\n",
    "xirun    = xi[xiini:xifin+1]\n",
    "for i in range(len(dataint)):\n",
    "    datarun.append(dataint[i][fileini:filefin+1])\n",
    "\n",
    "sizerun  = size[fileini:filefin+1]\n",
    "betarun  = beta\n",
    "\n",
    "VRchisq2dof = []\n",
    "worstsel=[]\n",
    "\n",
    "variants_Gc=['single','double']\n",
    "diini=1\n",
    "distop=0\n",
    "model_Gc='nb_exp_np_pole'\n",
    "\n",
    "dini_Vr=1 \n",
    "dstop_Vr=1 \n",
    "dmindata_Vr=8\n",
    "dfin_Vr=10\n",
    "\n",
    "for k in range(1+0*len(datarun)):\n",
    "    for i in range(2,3+0*len(betarun)): \n",
    "        print (\"xi={}, beta={}\".format(xirun[k],betarun[i]))\n",
    "        worstsel.append(np.loadtxt('{}{}/{}_{}_{}_worstsel_ti{}_{}_tfin{}_tmin{}_cut{}_beta={}_nocorrs={}_{}.dat'.format(resultspath,xirun[k],len(variants_Gc),model_Gc,datatype_Gc,diini,dstop_Gc,dfin_Gc,dmindata_Gc,cutoff_ma,betarun[i],no_corrs,corrtype)))\n",
    "        Vdat=np.loadtxt('{}{}/{}_{}_{}_VR_ti{}_{}_tfin{}_tmin{}_cut{}_beta={}_nocorrs={}_{}.dat'.format(resultspath,xirun[k],len(variants_Gc),model_Gc,datatype_Gc,diini,dstop_Gc,dfin_Gc,dmindata_Gc,cutoff_ma,betarun[i],no_corrs,corrtype))\n",
    "        Vdat_rescaled=np.loadtxt('{}{}/{}_{}_{}_VR_rescaled_ti{}_{}_tfin{}_tmin{}_cut{}_beta={}_nocorrs={}_{}.dat'.format(resultspath,xirun[k],len(variants_Gc),model_Gc,datatype_Gc,diini,dstop_Gc,dfin_Gc,dmindata_Gc,cutoff_ma,betarun[i],no_corrs,corrtype))\n",
    "        jackkl=len(Vdat)\n",
    "        lt=len(Vdat[i])\n",
    "\n",
    "        data_t     = np.linspace(1, lt, lt)\n",
    "        data_y     = jackknife(Vdat,jackkl).sample()\n",
    "        data_cov   = jackknife(Vdat,jackkl).scov()\n",
    "        data_cov_rescaled = jackknife(jackknife(Vdat_rescaled,jackkl).sample()).upcov()\n",
    "\n",
    "        m=Modelsmin( data_t, data_y, data_cov, dini_Vr, dstop_Vr, dmindata_Vr, dfin_Vr, inipars_Vr, model_Vr, variants_Vr, datatype_Vr, mcalls, mtol, reuse, inv_first, multiprocess, cov_freeze, improve, multistart, no_corrs, no_valid_check, data_cov_rescaled)\n",
    "        mf=m.jackk_minimize()\n",
    "        AIC_list=Jackknife_AIClist(mf)\n",
    "        VRchisq2dof.append(ensemble_stat(AIC_list.ordered()[0,4][:,0]).mean())\n",
    "        dummy, sigma_rescaled=AIC_list.avgsample(cutoff_ma,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC_list.ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(ensemble_stat(jackknife(AIC_list.avgsample(cutoff_ma,3)[1]).up()).rcov())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jackknife(sigma_rescaled).up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mambo jambo test, lets just take the log ratio from the data and use it as the correct V(R) predictor\n",
    "\n",
    "datarun=[]\n",
    "dataint  = data[xiini:xifin+1]\n",
    "for i in range(len(dataint)):\n",
    "    datarun.append(dataint[i][fileini:filefin+1])\n",
    "\n",
    "sizerun  = size[fileini:filefin+1]\n",
    "betarun  = beta[fileini:filefin+1]\n",
    "\n",
    "if (dini_Gc==0):\n",
    "    diini  = 0\n",
    "    distop = 0\n",
    "else:\n",
    "    diini   = dini_Gc\n",
    "    distop = dini_Gc+dstop_Gc\n",
    "\n",
    "for k in range(len(datarun)):\n",
    "    for j in range(len(datarun[k])):\n",
    "        totaltraj=int(len(data[k][j])/size[j])\n",
    "        Nt=len(data[k][j][0])-1\n",
    "\n",
    "        Gc=np.zeros((totaltraj,Nt))\n",
    "        Vrlistavg=[]\n",
    "        for r in range(Nt):\n",
    "            for i in range(totaltraj):\n",
    "                Gc[[i]]=data[k][j][range(i*Nt,(i+1)*Nt),[r+1]]\n",
    "\n",
    "            data_y   = jackknife(Gc).sample()\n",
    "            Vrlistavg.append(jackknife(np.log(2/data_y[:,0])).up())\n",
    "\n",
    "        np.savetxt('{}{}/VR_ti{}_tistop{}_tmin{}_beta={}.dat'.format(resultspath,xi[k],diini,distop,dmindata_Gc,betarun[j]), np.transpose(Vrlistavg))\n",
    "        np.savetxt('{}{}/worstsel_ti{}_tistop{}_tmin{}_beta={}.dat'.format(resultspath,xi[k],diini,distop,dmindata_Gc,betarun[j]), [0])\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VRchisq2dof = []\n",
    "worstsel=[]\n",
    "\n",
    "for k in range(len(datarun)):\n",
    "    for i in range(len(datarun[0])): \n",
    "        worstsel.append(np.loadtxt('{}{}/worstsel_ti{}_tistop{}_tmin{}_beta={}.dat'.format(resultspath,xi[k],diini,distop,dmindata_Gc,betarun[i])))\n",
    "        Vdat=np.loadtxt('{}{}/VR_ti{}_tistop{}_tmin{}_beta={}.dat'.format(resultspath,xi[k],diini,distop,dmindata_Gc,betarun[i]))\n",
    "        jackkl=len(Vdat)\n",
    "        lt=len(Vdat[i])\n",
    "\n",
    "        data_t     = np.linspace(1, lt, lt)\n",
    "        data_y     = jackknife(Vdat,jackkl).sample()\n",
    "        data_cov   = jackknife(Vdat,jackkl).scov()\n",
    "\n",
    "        m=Modelsmin( data_t, data_y, data_cov, dini_Vr, dstop_Vr, dmindata_Vr, dfin, inipars_Vr, model_Vr, variants_Vr, datatype_Vr, mcalls, mtol, reuse, inv_first)\n",
    "        mf=m.jackk_minimize()\n",
    "        AIC_list=Jackknife_AIClist(mf)\n",
    "        VRchisq2dof.append(ensemble_stat(AIC_list.ordered()[0,4][:,0]).mean())\n",
    "        np.savetxt('{}{}/fits_VR_beta={}.dat'.format(resultspath,xi[k],betarun[i]),np.append(AIC_list.ordered()[0,1:3],[AIC_list.selval()[0:2],AIC_list.avgval()[0:2]]))\n",
    "        np.savetxt('{}{}/sigma_beta={}.dat'.format(resultspath,xi[k],betarun[i]),[AIC_list.avgval()[0][2],AIC_list.avgval()[1][2]])\n",
    "        dataV=np.array([AIC_list.selval()[2],AIC_list.avgval()[2]])\n",
    "        with open('{}{}/corrs_VR_beta={}.dat'.format(resultspath,xi[k],betarun[i]), 'w') as outfile:\n",
    "            outfile.write('# Model selection/average corrs:\\n')\n",
    "            for data_slice in dataV:\n",
    "                np.savetxt(outfile, data_slice)\n",
    "\n",
    "\n",
    "with open('{}/labels.dat'.format(resultsdir), 'w') as outfile:\n",
    "    for k in range(len(datarun)):\n",
    "        for i in range(len(datarun[0])):\n",
    "            outfile.write(\"$\\\\beta$={} $\\\\chi^2/$dof={:.1f}, {:.1f}\\n\".format(betarun[i],worstsel[i],VRchisq2dof[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt=len(logG[0])\n",
    "dfin=lt\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(Gc).mean()\n",
    "data_cov = ensemble_stat(Gc).rcov()\n",
    "\n",
    "\n",
    "datatype=\"exp_WL\"\n",
    "model='exp_np'\n",
    "# Trim to use models that have less params than data points used in the fit\n",
    "inipars_GC=[[0.4,1.]]#,[1.0,0.3,1.0,0.2]]\n",
    "variants_GC=['single']#,'double']\n",
    "\n",
    "m=Modelsmin(data_t, data_y, data_cov, dini, dstop, dmindata, dfin, inipars_GC, model, variants_GC, datatype, mcalls, mtol, 1, 1)\n",
    "mf=m.minimize()\n",
    "AIC_list=AIClist(mf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt=len(Gc[0])\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(Gc).mean()\n",
    "data_cov = ensemble_stat(Gc).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(Gc).rcov()))\n",
    "\n",
    "mcalls=5000\n",
    "mtol=0.001\n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, 4, 16, [-1.93328781, -0.35270411,  0.1       ,  0.1       ], 'nb_exp_np', mcalls, mtol,1)\n",
    "\n",
    "m.minimize()\n",
    "ma=MA_fit(m.minimize())\n",
    "\n",
    "np.log(2/data_y[0])\n",
    "\n",
    "loglimG_geom(0,*ma.pars())\n",
    "prop_err(0.,'loglimG_geom',ma.pars(),ma.errs(),ma.corrs())[0]\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t, exp_np_geom(data_t, *m.minimize().values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt=len(Gc[0])\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(Gc).mean()\n",
    "data_cov = ensemble_stat(Gc).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(Gc).rcov()))\n",
    "\n",
    "mcalls=5000\n",
    "mtol=0.001\n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, 1, 12, [1.,0.5,0.3,.2], 'exp_np', mcalls, mtol,1)\n",
    "\n",
    "m.minimize()\n",
    "ma=MA_fit(m.minimize())\n",
    "\n",
    "np.log(2/data_y[0])\n",
    "\n",
    "loglimG(0,*ma.pars())\n",
    "prop_err(0.,'loglimG',ma.pars(),ma.errs(),ma.corrs())[0]\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t, exp_np(data_t, *m.minimize().values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt=len(Gc[0])\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(Gc).mean()\n",
    "data_cov = ensemble_stat(Gc).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(Gc).rcov()))\n",
    "\n",
    "mcalls=5000\n",
    "mtol=0.001\n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, 1, 12, [2.,0.5,0.2,.2,0.5,0.1], 'exp_np', mcalls, mtol,1)\n",
    "\n",
    "m.minimize()\n",
    "ma=MA_fit(m.minimize())\n",
    "\n",
    "np.log(2/data_y[0])\n",
    "\n",
    "loglimG(0,*ma.pars())\n",
    "prop_err(0.,'loglimG',ma.pars(),ma.errs(),ma.corrs())[0]\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t, exp_np(data_t, *m.minimize().values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt=len(Gc[0])\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(Gc).mean()\n",
    "data_cov = ensemble_stat(Gc).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(Gc).rcov()))\n",
    "\n",
    "mcalls=5000\n",
    "mtol=0.001\n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, 1, 12, [0.125,0.04,.51,0.04,2.56], 'exp_np_norm', mcalls, mtol,1)\n",
    "\n",
    "m.minimize()\n",
    "ma=MA_fit(m.minimize())\n",
    "\n",
    "np.log(2/data_y[0])\n",
    "\n",
    "loglimG_norm(0,*ma.pars())\n",
    "prop_err(0.,'loglimG_norm',ma.pars(),ma.errs(),ma.corrs())[0]\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t, exp_np_norm(data_t, *m.minimize().values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt=len(Gc[0])\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(Gc).mean()\n",
    "data_cov = ensemble_stat(Gc).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(Gc).rcov()))\n",
    "\n",
    "mcalls=5000\n",
    "mtol=0.001\n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, 1, 12, [0.1,0.1,1.,.1,2.], 'exp_np_norm_geom', mcalls, mtol,1)\n",
    "\n",
    "m.minimize()\n",
    "ma=MA_fit(m.minimize())\n",
    "\n",
    "np.log(2/data_y[0])\n",
    "\n",
    "loglimG_norm_geom(0,*ma.pars())\n",
    "prop_err(0.,'loglimG_geom',ma.pars(),ma.errs(),ma.corrs())[0]\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t, exp_np_norm_geom(data_t, *m.minimize().values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logG=np.log(jackknife(Gc).sample())\n",
    "dlogG=np.log(ratio(trim_negative(Gc).trimmed()).val())\n",
    "\n",
    "lt=len(dlogG[0])\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(dlogG).mean()\n",
    "data_cov = ensemble_stat(dlogG).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(dlogG).rcov()))\n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, 1, 12, [1.,1.,1.,1.,1.], 'line_np', mcalls, mtol, 1)\n",
    "\n",
    "m.minimize()\n",
    "ma=MA_fit(m.minimize())\n",
    "data_y[0]\n",
    "line_np(0,*ma.pars())\n",
    "prop_err(0.,'line_np',ma.pars(),ma.errs(),ma.corrs())[0]\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t, line_np(data_t, *m.minimize().values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logG=np.log(trim_negative(Gc).trimmed())\n",
    "\n",
    "lt=len(logG[0])\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(logG).mean()\n",
    "data_cov = ensemble_stat(logG).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(logG).rcov()))\n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, 1, 10, [0.,0.1,0.1,0.1,0.1], 'line_np', mcalls, mtol, 1)\n",
    "\n",
    "m.minimize()\n",
    "ma=MA_fit(m.minimize())\n",
    "np.log(2)-data_y[0]\n",
    "limG(0,*ma.pars())\n",
    "#prop_err(0.,'limG_norm',ma.pars(),ma.errs(),ma.corrs())[0]\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t, line_np(data_t, *m.minimize().values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logG=np.log(trim_negative(Gc).trimmed())\n",
    "\n",
    "lt=len(logG[0])\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(logG).mean()\n",
    "data_cov = ensemble_stat(logG).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(logG).rcov()))\n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, 1, 10, [0.1,0.1,0.1,0.1,0.1], 'line_np_norm', mcalls, mtol, 1)\n",
    "\n",
    "m.minimize()\n",
    "ma=MA_fit(m.minimize())\n",
    "np.log(2)-data_y[0]\n",
    "limG_norm(0,*ma.pars())\n",
    "#prop_err(0.,'limG_norm',ma.pars(),ma.errs(),ma.corrs())[0]\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t, line_np_norm(data_t, *m.minimize().values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logG=np.log(Gc)\n",
    "\n",
    "lt=len(logG[0])\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(logG).mean()\n",
    "data_cov = ensemble_stat(logG).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(logG).rcov()))\n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, 1, 12, [1.,1.,1.,-1.], 'line_np_pole', mcalls, mtol, 1)\n",
    "\n",
    "m.minimize()\n",
    "ma=MA_fit(m.minimize())\n",
    "limGp(0,*ma.pars())\n",
    "prop_err(0.,'limGp',ma.pars(),ma.errs(),ma.corrs())[0]\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t, line_np_pole(data_t, *m.minimize().values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datarun=[]\n",
    "dataint  = data[xiini:xifin+1]\n",
    "for i in range(len(dataint)):\n",
    "    datarun.append(dataint[i][fileini:filefin+1])\n",
    "\n",
    "sizerun  = size[fileini:filefin+1]\n",
    "betarun  = beta[fileini:filefin+1]\n",
    "\n",
    "datatype=\"exp_WL\"\n",
    "dfin=100\n",
    "model='exp_np'\n",
    "reuse=1\n",
    "inipars_GC=[[1.0,0.3]]#,[1.0,0.3,1.0,0.2]]\n",
    "variants_GC=['single']#,'double']\n",
    "jackkl=200\n",
    "\n",
    "result=fitter(datarun[0], size, dini, dstop, dmindata, dfin, datatype_Gc, model_Gc, inipars_Gc, variants_Gc, mcalls, mtol, 1, 1)\n",
    "Vrlistavg, Vrlistsel, worstsel, listfinal =result.jackk_fit(jackkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jackknife exercise test\n",
    "xi=0\n",
    "k=0\n",
    "r=0\n",
    "\n",
    "totaltraj=int(len(data[xi][k])/size[k])\n",
    "Nt=len(data[xi][k][0])-1\n",
    "\n",
    "Gc=np.zeros((totaltraj,Nt))\n",
    "for i in range(totaltraj):\n",
    "    Gc[[i]]=data[xi][k][range(i*Nt,(i+1)*Nt),[r+1]]\n",
    "\n",
    "\n",
    "jackkl=500\n",
    "lt=len(logG[0])\n",
    "dfin=lt\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = jackknife(Gc,jackkl).sample()\n",
    "data_cov = jackknife(Gc,jackkl).scov()\n",
    "\n",
    "\n",
    "datatype=\"exp_WL\"\n",
    "model='exp_np'\n",
    "# Trim to use models that have less params than data points used in the fit\n",
    "inipars_GC=[[1.0,0.4]]#,[1.0,0.3,1.0,0.2]]\n",
    "variants_GC=['single']#,'double']\n",
    "\n",
    "m=Modelsmin(data_t, data_y, data_cov, dini, dstop, dmindata, dfin, inipars_GC, model, variants_GC, datatype, mcalls, mtol, 1, 1)\n",
    "mf=m.jackk_minimize()\n",
    "AIC_list=Jackknife_AIClist(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_R     = []\n",
    "data_V     = []\n",
    "data_V_err = []\n",
    "a=[\"black\",\"crimson\",\"royalblue\",\"seagreen\"]\n",
    "labels=[\"b=2.375\",\"b=2.5\",\"b=2.59\",\"b=2.66\"]\n",
    "plotsR=plt.figure()\n",
    "for k in range(len(valfk)):\n",
    "    Nt=len(valfk[k])\n",
    "    data_R=np.linspace(1, Nt, Nt)\n",
    "    data_V=valfk[k]\n",
    "    data_V_err=evalfk[k]\n",
    "    plt.errorbar(data_R, data_V, data_V_err, fmt=\"ok\", label=labels[k], color=a[k], marker=\"s\")\n",
    "\n",
    "plotsR.show(1)\n",
    "#data_R=[element for sublist in data_R for element in sublist]\n",
    "#data_V=[element for sublist in data_V for element in sublist]\n",
    "#data_V_err=[element for sublist in data_V_err for element in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totaltraj=int(len(data[2])/size[2])\n",
    "Nt=len(data[2][0])-1\n",
    "\n",
    "Gc=np.zeros((totaltraj,Nt))\n",
    "for i in range(totaltraj):\n",
    "    Gc[[i]]=data[2][range(i*Nt,(i+1)*Nt),[1]]\n",
    "    \n",
    "logG=np.log(trim_negative(Gc).trimmed())    \n",
    "\n",
    "lt=len(logG[0])\n",
    "dfin=lt\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(logG).mean()\n",
    "data_cov = ensemble_stat(logG).cov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(logG).cov()))\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype=\"log\"\n",
    "dfin=20\n",
    "model=line_np\n",
    "reuse=1\n",
    "\n",
    "result=fitter(data, size, dini, dstop, dfin, datatype, model, inipars2, variants2, mcalls, mtol, reuse)\n",
    "\n",
    "valtrials, valfk2, evalfk2=result.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_R2     = []\n",
    "data_V2     = []\n",
    "data_V2_err = []\n",
    "a=[\"black\",\"crimson\",\"royalblue\",\"seagreen\"]\n",
    "\n",
    "plotsR=plt.figure(plotsR)\n",
    "for k in range(len(valfk2)):\n",
    "    Nt=len(valfk2[k])\n",
    "    data_R2=np.linspace(1, Nt, Nt)-0.3\n",
    "    data_V2=valfk2[k]\n",
    "    data_V2_err=evalfk2[k]\n",
    "#    for i in range(Nt):\n",
    "#        print(data_R2[i]+0.3,\" \",data_V2[i],\" \",data_V2_err[i])\n",
    "    plt.errorbar(data_R2, data_V2, data_V2_err, fmt=\"ok\", color=a[k])\n",
    "\n",
    "#data_R2=[element for sublist in data_R2 for element in sublist]\n",
    "#data_V2=[element for sublist in data_V2 for element in sublist]\n",
    "#data_V2_err=[element for sublist in data_V2_err for element in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.legend(frameon=False)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=Modelsmin( data_t, data_y, data_cov, dini, dstop, dfin, iniparsexp, model, variantsexp, datatype, mcalls, mtol, 1)\n",
    "mf=m.minimize()\n",
    "AIC_list=AIClist(mf[1])\n",
    "\n",
    "print(mf[0],np.array(AIC_list.avgval0()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_R3     = []\n",
    "data_V3     = []\n",
    "data_V3_err = []\n",
    "a=[\"black\",\"crimson\",\"royalblue\",\"seagreen\"]\n",
    "\n",
    "plotsR=plt.figure(plotsR)\n",
    "for k in range(len(valfk3)):\n",
    "    Nt=len(valfk3[k])\n",
    "    data_R3=np.linspace(1, Nt, Nt)+0.3\n",
    "    data_V3=valfk3[k]\n",
    "    data_V3_err=evalfk3[k]\n",
    "#    for i in range(Nt):\n",
    "#        print(data_R2[i]+0.3,\" \",data_V2[i],\" \",data_V2_err[i])\n",
    "    plt.errorbar(data_R3, data_V3, data_V3_err, fmt=\"ok\", color=a[k], marker=\"^\")\n",
    "\n",
    "#data_R2=[element for sublist in data_R2 for element in sublist]\n",
    "#data_V2=[element for sublist in data_V2 for element in sublist]\n",
    "#data_V2_err=[element for sublist in data_V2_err for element in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.legend(frameon=False)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype=\"exp\"\n",
    "dfin=20\n",
    "model=exp_np\n",
    "reuse=0\n",
    "iniparsexptest=iniparsexp[0:2]\n",
    "variantsexptest=variantsexp[0:2]\n",
    "\n",
    "result=fitter(data, size, dini, dstop, dfin, datatype, model, iniparsexptest, variantsexptest, mcalls, mtol, reuse)\n",
    "\n",
    "valtrials, valfk4, evalfk4=result.fit()\n",
    "\n",
    "valtrials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_R4     = []\n",
    "data_V4     = []\n",
    "data_V4_err = []\n",
    "a=[\"black\",\"crimson\",\"royalblue\",\"seagreen\"]\n",
    "\n",
    "plotsR=plt.figure(plotsR)\n",
    "for k in range(len(valfk4)):\n",
    "    Nt=len(valfk4[k])\n",
    "    data_R4=np.linspace(1, Nt, Nt)+0.3\n",
    "    data_V4=valfk4[k]\n",
    "    data_V4_err=evalfk4[k]\n",
    "#    for i in range(Nt):\n",
    "#        print(data_R2[i]+0.3,\" \",data_V2[i],\" \",data_V2_err[i])\n",
    "    plt.errorbar(data_R4, data_V4, data_V4_err, fmt=\"ok\", color=a[k], marker=\"v\")\n",
    "\n",
    "#data_R2=[element for sublist in data_R2 for element in sublist]\n",
    "#data_V2=[element for sublist in data_V2 for element in sublist]\n",
    "#data_V2_err=[element for sublist in data_V2_err for element in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.legend(frameon=False)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the exercise for exponential fits\n",
    "k=3\n",
    "r=1\n",
    "totaltraj=int(len(data[k])/size[k])\n",
    "Nt=len(data[k][0])-1\n",
    "\n",
    "Gc=np.zeros((totaltraj,Nt))\n",
    "for i in range(totaltraj):\n",
    "    Gc[[i]]=data[k][range(i*Nt,(i+1)*Nt),[r]]\n",
    "    \n",
    "lt=len(Gc[0])\n",
    "dini=0\n",
    "dfin=lt\n",
    "data_t   = np.linspace(1, lt, lt)[dini:dfin]\n",
    "data_y   = ensemble_stat(Gc).mean()[dini:dfin]\n",
    "data_cov = ensemble_stat(Gc).cov()[dini:dfin,dini:dfin]\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(Gc).cov()))[dini:dfin]\n",
    "\n",
    "model=exp_np\n",
    "datatype=\"exp\"\n",
    "\n",
    "m=Minuit_fit( data_t, data_y, data_cov, mcalls, mtol, iniparsexp[2], model,1)\n",
    "\n",
    "ma=MA_fit(m.minimize())\n",
    "print(m.minimize())\n",
    "\n",
    "#plotsE=plt.figure(2)\n",
    "#plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "#plt.plot(data_t, exp_np(data_t, *m.minimize().values), label=\"fit\")\n",
    "#plt.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets repeat a single fit to test it\n",
    "k=0\n",
    "r=1\n",
    "totaltraj=int(len(data[k])/size[k])\n",
    "\n",
    "Nt=len(data[k][0])-1\n",
    "\n",
    "Gc=np.zeros((totaltraj,Nt))\n",
    "for i in range(totaltraj):\n",
    "    Gc[[i]]=data[k][range(i*Nt,(i+1)*Nt),[r]]\n",
    "\n",
    "gdata    = np.log(trim_negative(jackknife(Gc,jackkl).sample()).trimmed())\n",
    "           \n",
    "gdata=jackknife(gdata,jackkl).up()\n",
    "\n",
    "lt=len(gdata[0])\n",
    "dfin=lt\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(gdata).mean()\n",
    "data_cov = ensemble_stat(gdata).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(gdata).rcov()))\n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, 2, 8, [0.5,1.,0.,0.], line_np, mcalls, mtol)\n",
    "\n",
    "m.minimize()\n",
    "m.minimize().fval/m.minimize().ndof\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t, line_np(data_t, *m.minimize().values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacings_iso(beta):\n",
    "    beta=np.asarray(beta).reshape(1, -1)[0,:]\n",
    "    Pi=np.pi\n",
    "    sigma=0.44**2\n",
    "    beta0=22/3; beta1=68/3; b0=0.33982850818945587; b1=-0.047729010997329825; b2=1.66; b3=4.38\n",
    "    scale=4*Pi**2/beta0\n",
    "\n",
    "    alist=np.zeros(len(beta))\n",
    "    for i in range(len(beta)):\n",
    "        f2=2*beta1/beta0**2*np.log(scale*beta[i])-scale*beta[i]+scale*b2/beta[i]+b3\n",
    "        alist[i]=np.sqrt(np.exp(f2)/sigma)\n",
    "\n",
    "    return alist\n",
    "\n",
    "def spacings_xi(xi,beta):\n",
    "    beta=np.asarray(beta).reshape(1, -1)[0,:]\n",
    "    xi=np.asarray(xi).reshape(1, -1)[0,:]\n",
    "    Pi=np.pi\n",
    "    sigma=0.44**2\n",
    "    beta0=22/3; beta1=68/3; b0=0.33982850818945587; b1=-0.047729010997329825; b2=1.613897922881925; b3=7.057569782719919\n",
    "    scale=4*Pi**2/beta0\n",
    "\n",
    "    alist=np.zeros([len(xi),len(beta)])\n",
    "    for j in range(len(xi)):\n",
    "        f1=b0+b1/xi[j]\n",
    "        for i in range(len(beta)):\n",
    "            f2=2*beta1/beta0**2*np.log(scale*beta[i])-scale*beta[i]+scale*b2/beta[i]+b3\n",
    "            alist[j][i]=np.sqrt(f1*np.exp(f2)/sigma)\n",
    "\n",
    "    return alist\n",
    "\n",
    "betas=[2.25,2.3,2.35,2.4,2.45,2.5,2.55,2.6,2.65,2.7,2.75]\n",
    "xi=[2,3,4,5,6,7,8]\n",
    "\n",
    "spacings_iso(betas)\n",
    "spacings_xi(xi,betas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
