{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iminuit version: 2.30.1\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# basic setup of the notebook\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "from numba import njit, prange\n",
    "from numba.experimental import jitclass\n",
    "import pickle\n",
    "\n",
    "from mpmath import *\n",
    "mp.dps = 200;mp.pretty = True\n",
    "import tomllib\n",
    "from pip._vendor import tomli\n",
    "import sys, os\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocess as mp\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import scipy as sp\n",
    "from scipy import *\n",
    "import faulthandler\n",
    "faulthandler.enable()\n",
    "sys.path.append('./code')\n",
    "from fit_drivers import *\n",
    "from minimizer import *\n",
    "from fit_functions import *\n",
    "from output_functions import *\n",
    "from general_stats import *\n",
    "from jpac_colors import *\n",
    "import fit_drivers, minimizer, fit_functions, output_functions, general_stats  \n",
    "\n",
    "import math as mp\n",
    "import timeit\n",
    "import time\n",
    "\n",
    "# everything in iminuit is done through the Minuit object, so we import it\n",
    "from iminuit import Minuit\n",
    "from iminuit import minimize\n",
    "import time\n",
    "from iminuit.util import describe\n",
    "from typing import Annotated\n",
    "\n",
    "# we also need a cost function to fit and import the LeastSquares function\n",
    "from iminuit.cost import LeastSquares\n",
    "\n",
    "# display iminuit version\n",
    "import iminuit\n",
    "print(\"iminuit version:\", iminuit.__version__)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Importing fixed params for analysis\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "with open('ini_files/W_analysis_L32_xi=1_pole.toml', \"rb\") as f:\n",
    "    params = tomli.load(f)\n",
    "\n",
    "with open('ini_files/basic_setup_pole.toml', \"rb\") as f2:\n",
    "    params2 = tomli.load(f2)\n",
    "\n",
    "for i in params:\n",
    "     params['{}'.format(i)].update(params2['{}'.format(i)])\n",
    "\n",
    "\n",
    "who            = params['creator']['who']\n",
    "  \n",
    "  \n",
    "path           = params['paths_to_files']['base_path']\n",
    "mainpath       = '{}{}'.format(path,params['paths_to_files']['mainpath'])\n",
    "resultspath    = '{}{}'.format(path,params['paths_to_files']['resultspath'])\n",
    "resultsdir     = '{}{}'.format(path,params['paths_to_files']['resultsdir'])\n",
    "plotsdir       = '{}{}'.format(path,params['paths_to_files']['plotsdir'])\n",
    "Gcplotsdir     = '{}{}'.format(path,params['paths_to_files']['Gcplotsdir'])\n",
    "sizelabel      = params['paths_to_files']['sizelabel']      \n",
    "  \n",
    "  \n",
    "corrtype       = params['correlators']['corrtype']  \n",
    "xi             = params['correlators']['xi']\n",
    "beta           = params['correlators']['beta']\n",
    "betanorm       = params['correlators']['betanorm']\n",
    "Lextent        = params['correlators']['Lextent']\n",
    "Textent        = params['correlators']['Textent']\n",
    "size           = params['correlators']['size']\n",
    "Ncfgs          = params['correlators']['Ncfgs']\n",
    "\n",
    "als            = params['correlators']['als']\n",
    "  \n",
    "dini_Gc        = params['minimization_parameters']['dini_Gc']\n",
    "dstop_Gc       = params['minimization_parameters']['dstop_Gc']\n",
    "dmindata_Gc    = params['minimization_parameters']['dmindata_Gc']\n",
    "dini_Vr        = params['minimization_parameters']['dini_Vr']\n",
    "dstop_Vr       = params['minimization_parameters']['dstop_Vr']\n",
    "dmindata_Vr    = params['minimization_parameters']['dmindata_Vr']\n",
    "dfin_Gc        = params['minimization_parameters']['dfin_Gc']\n",
    "dfin_Vr        = params['minimization_parameters']['dfin_Vr']\n",
    "reuse          = params['minimization_parameters']['reuse']\n",
    "inv_first      = params['minimization_parameters']['inv_first']\n",
    "mcalls         = params['minimization_parameters']['mcalls']\n",
    "mtol           = params['minimization_parameters']['mtol']\n",
    "inipars_Gc     = params['minimization_parameters']['inipars_GC']\n",
    "variants_Gc    = params['minimization_parameters']['variants_GC']\n",
    "jackkl         = params['minimization_parameters']['jackkl']\n",
    "xiini          = params['minimization_parameters']['xiini']\n",
    "xifin          = params['minimization_parameters']['xifin']   \n",
    "fileini        = params['minimization_parameters']['fileini']                         \n",
    "filefin        = params['minimization_parameters']['filefin']\n",
    "datatype_Gc    = params['minimization_parameters']['datatype_Gc']\n",
    "model_Gc       = params['minimization_parameters']['model_Gc']\n",
    "model_Vr       = params['minimization_parameters']['model_Vr']\n",
    "datatype_Vr    = params['minimization_parameters']['datatype_Vr']\n",
    "inipars_Vr     = params['minimization_parameters']['inipars_Vr']\n",
    "variants_Vr    = params['minimization_parameters']['variants_Vr']\n",
    "multiprocess   = params['minimization_parameters']['multiprocess']\n",
    "cov_freeze     = params['minimization_parameters']['cov_freeze']\n",
    "improve        = params['minimization_parameters']['improve']\n",
    "multistart     = params['minimization_parameters']['multistart']\n",
    "  \n",
    "\n",
    "clean          = params['extra']['clean']\n",
    "cutoff_ma      = params['extra']['cutoff_ma']\n",
    "norm           = params['extra']['norm']\n",
    "no_corrs       = params['extra']['no_corrs']\n",
    "no_valid_check = params['extra']['no_valid_check']\n",
    "\n",
    "\n",
    "gev_m1_tofm=5.068\n",
    "als=np.array(als)/gev_m1_tofm\n",
    "als_orig=np.array(als)*gev_m1_tofm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n",
      "396 396\n",
      "[644]\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#This is the only part that varies between Sebastian's and Wyatt's Lattices, the paths/readings\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create results folders if they do not exist\n",
    "if os.path.exists(resultsdir)==False:\n",
    "    os.mkdir(resultsdir)\n",
    "if os.path.exists(plotsdir)==False:\n",
    "    os.mkdir(plotsdir)\n",
    "if os.path.exists(Gcplotsdir)==False:\n",
    "    os.mkdir(Gcplotsdir)    \n",
    "\n",
    "\n",
    "# Clean results folder?\n",
    "if clean == 1:\n",
    "    os.system('rm -rf {}/*'.format(plotsdir))\n",
    "    os.system('rm -rf {}/*'.format(resultsdir))  \n",
    "    os.system('rm -rf {}/*'.format(Gcplotsdir)) \n",
    "\n",
    "\n",
    "for k in range(len(xi)):\n",
    "    if os.path.exists('{}{}'.format(resultspath,xi[k]))==False:\n",
    "        os.mkdir('{}{}'.format(resultspath,xi[k]))\n",
    "    if os.path.exists('{}/xi={}'.format(Gcplotsdir,xi[k]))==False:\n",
    "        os.mkdir('{}/xi={}'.format(Gcplotsdir,xi[k]))\n",
    "\n",
    "        \n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Read raw data and prepare accordingly\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "         \n",
    "\n",
    "# Data used in the analysis\n",
    "datam=[]\n",
    "for k in range(len(xi)):\n",
    "    dataint=[]\n",
    "    for j in range(len(beta)):\n",
    "        dataint.append(np.genfromtxt('{}{}/L{}_b{}_xi{}_{}.dat'.format(mainpath,xi[k],int(sizelabel),beta[j],xi[k],corrtype)))\n",
    "    datam.append(dataint)\n",
    "    \n",
    "# Collect completed configurations from raw data    \n",
    "data=[]\n",
    "for k in range(len(xi)):\n",
    "    dataint=[]\n",
    "    for j in range(len(datam[k])):\n",
    "        if (len(np.array(collect_configs(datam[k][j],Lextent,Textent).trans_S()))==0):\n",
    "            dataint.append(np.array(collect_configs(datam[k][j],Lextent,Textent).trans_W()))\n",
    "        else:\n",
    "            dataint.append(np.array(collect_configs(datam[k][j],Lextent,Textent).trans_S()))\n",
    "    data.append(dataint)\n",
    "\n",
    "      \n",
    "\n",
    "nconfigs=[]\n",
    "for k in range(len(xi)):\n",
    "    nint=[]\n",
    "    for j in range(len(beta)):\n",
    "        nint.append(int(len(data[k][j])/size[k]))\n",
    "        print(int(len(data[k][j])/size[k]))\n",
    "        nconfigs.append(int(len(data[k][j])/size[k]))  \n",
    "\n",
    "print(min(nconfigs),max(nconfigs))  \n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m     index\u001b[38;5;241m=\u001b[39mjump_configs\u001b[38;5;241m*\u001b[39mi\n\u001b[1;32m     19\u001b[0m     Gc[[i]]\u001b[38;5;241m=\u001b[39mdata[x][k][\u001b[38;5;28mrange\u001b[39m(index\u001b[38;5;241m*\u001b[39mNt,(index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mNt),[r]]\n\u001b[0;32m---> 20\u001b[0m     Gc2[[i]]\u001b[38;5;241m=\u001b[39m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;28mrange\u001b[39m(index\u001b[38;5;241m*\u001b[39mNt,(index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mNt),[r]]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m time \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(Gc[\u001b[38;5;241m0\u001b[39m])):\n\u001b[1;32m     23\u001b[0m     shift\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "x=0\n",
    "k=0\n",
    "r=0\n",
    "pos=0\n",
    "\n",
    "jackkl=100000\n",
    "jump_configs=1\n",
    "\n",
    "mcalls=10000\n",
    "mtol=0.00001\n",
    "\n",
    "totaltraj=int(len(data[x][k])/size[k])\n",
    "Nt=Textent\n",
    "\n",
    "Gc=np.zeros((int(totaltraj/jump_configs),Nt))\n",
    "Gc2=np.zeros((int(totaltraj/jump_configs),Nt))\n",
    "for i in range(int(totaltraj/jump_configs)):\n",
    "    index=jump_configs*i\n",
    "    Gc[[i]]=data[x][k][range(index*Nt,(index+1)*Nt),[r]]\n",
    "    Gc2[[i]]=data[x][k+1][range(index*Nt,(index+1)*Nt),[r]]\n",
    "\n",
    "for time in range(len(Gc[0])):\n",
    "    shift=0.1\n",
    "    data_t = np.ones(len(Gc[:,time]))*time+1\n",
    "    plt.scatter(data_t,Gc[:,time],color=jpac_blue)\n",
    "    plt.scatter(data_t+shift,Gc2[:,time],color=jpac_red)\n",
    "    plt.xlim(0,7.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.33167687e+00, 7.39328891e-01, 4.12173697e-01, 2.30101571e-01,\n",
       "       1.28516128e-01, 7.18040674e-02, 4.01265620e-02, 2.23918613e-02,\n",
       "       1.25067093e-02, 6.98524931e-03, 3.91726002e-03, 2.17525600e-03,\n",
       "       1.20865898e-03, 6.62120324e-04, 3.68739372e-04, 2.20255566e-04])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 4161.80854999, 10843.92592839, 22847.2759508 , 41236.01672957,\n",
       "       58477.43694154, 63620.58007023, 70046.14561113, 78375.9262984 ,\n",
       "       79057.10460337, 79368.64441544, 80773.26432824, 81102.28947974,\n",
       "       81321.95442416, 83068.29754515, 84573.59276072, 84941.47144332])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th colspan=\"2\" style=\"text-align:center\" title=\"Minimizer\"> Migrad </th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align:left\" title=\"Minimum value of function\"> FCN = 4.019 (χ²/ndof = 2.0) </td>\n",
       "        <td style=\"text-align:center\" title=\"Total number of function and (optional) gradient evaluations\"> Nfcn = 5951 </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align:left\" title=\"Estimated distance to minimum and goal\"> EDM = 10.7 (Goal: 2e-08) </td>\n",
       "        <td style=\"text-align:center\" title=\"Total run time of algorithms\">  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align:center;background-color:#c15ef7;color:black\"> INVALID Minimum </td>\n",
       "        <td style=\"text-align:center;background-color:#c15ef7;color:black\"> ABOVE EDM threshold (goal x 10) </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align:center;background-color:#92CCA6;color:black\"> No parameters at limit </td>\n",
       "        <td style=\"text-align:center;background-color:#92CCA6;color:black\"> Below call limit </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align:center;background-color:#FFF79A;color:black\"> Hesse ok </td>\n",
       "        <td style=\"text-align:center;background-color:#FFF79A;color:black\"> Covariance FORCED pos. def. </td>\n",
       "    </tr>\n",
       "</table><table>\n",
       "    <tr>\n",
       "        <td></td>\n",
       "        <th title=\"Variable name\"> Name </th>\n",
       "        <th title=\"Value of parameter\"> Value </th>\n",
       "        <th title=\"Hesse error\"> Hesse Error </th>\n",
       "        <th title=\"Minos lower error\"> Minos Error- </th>\n",
       "        <th title=\"Minos upper error\"> Minos Error+ </th>\n",
       "        <th title=\"Lower limit of the parameter\"> Limit- </th>\n",
       "        <th title=\"Upper limit of the parameter\"> Limit+ </th>\n",
       "        <th title=\"Is the parameter fixed in the fit\"> Fixed </th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> 0 </th>\n",
       "        <td> x0 </td>\n",
       "        <td> 0.0043 </td>\n",
       "        <td> 0.0014 </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> 1 </th>\n",
       "        <td> x1 </td>\n",
       "        <td> 2.3570 </td>\n",
       "        <td> 0.0013 </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> 2 </th>\n",
       "        <td> x2 </td>\n",
       "        <td> -582.00e-3 </td>\n",
       "        <td> 0.14e-3 </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> 3 </th>\n",
       "        <td> x3 </td>\n",
       "        <td> 0.00 </td>\n",
       "        <td> 0.04 </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> 4 </th>\n",
       "        <td> x4 </td>\n",
       "        <td> -0.95 </td>\n",
       "        <td> 0.13 </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> 5 </th>\n",
       "        <td> x5 </td>\n",
       "        <td> -0.042 </td>\n",
       "        <td> 0.008 </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> 6 </th>\n",
       "        <td> x6 </td>\n",
       "        <td> 0.05 </td>\n",
       "        <td> 0.09 </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "        <td>  </td>\n",
       "    </tr>\n",
       "</table><table>\n",
       "    <tr>\n",
       "        <td></td>\n",
       "        <th> x0 </th>\n",
       "        <th> x1 </th>\n",
       "        <th> x2 </th>\n",
       "        <th> x3 </th>\n",
       "        <th> x4 </th>\n",
       "        <th> x5 </th>\n",
       "        <th> x6 </th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> x0 </th>\n",
       "        <td> 1.93e-06 </td>\n",
       "        <td style=\"background-color:rgb(200,200,250);color:black\"> -0.7e-6 <strong>(-0.385)</strong> </td>\n",
       "        <td style=\"background-color:rgb(187,187,250);color:black\"> -0.093e-6 <strong>(-0.487)</strong> </td>\n",
       "        <td style=\"background-color:rgb(126,126,250);color:black\"> -55.9e-6 <strong>(-0.957)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,128,128);color:black\"> 144.0e-6 <strong>(0.816)</strong> </td>\n",
       "        <td style=\"background-color:rgb(135,135,250);color:black\"> -9.5e-6 <strong>(-0.884)</strong> </td>\n",
       "        <td style=\"background-color:rgb(175,175,250);color:black\"> -68.5e-6 <strong>(-0.580)</strong> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> x1 </th>\n",
       "        <td style=\"background-color:rgb(200,200,250);color:black\"> -0.7e-6 <strong>(-0.385)</strong> </td>\n",
       "        <td> 1.81e-06 </td>\n",
       "        <td style=\"background-color:rgb(228,228,250);color:black\"> -0.031e-6 <strong>(-0.166)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,195,195);color:black\"> 20.6e-6 <strong>(0.364)</strong> </td>\n",
       "        <td style=\"background-color:rgb(194,194,250);color:black\"> -73.9e-6 <strong>(-0.433)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,199,199);color:black\"> 3.6e-6 <strong>(0.342)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,188,188);color:black\"> 47.1e-6 <strong>(0.412)</strong> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> x2 </th>\n",
       "        <td style=\"background-color:rgb(187,187,250);color:black\"> -0.093e-6 <strong>(-0.487)</strong> </td>\n",
       "        <td style=\"background-color:rgb(228,228,250);color:black\"> -0.031e-6 <strong>(-0.166)</strong> </td>\n",
       "        <td> 1.88e-08 </td>\n",
       "        <td style=\"background-color:rgb(250,170,170);color:black\"> 3.075e-6 <strong>(0.533)</strong> </td>\n",
       "        <td style=\"background-color:rgb(201,201,250);color:black\"> -6.542e-6 <strong>(-0.375)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,177,177);color:black\"> 0.518e-6 <strong>(0.489)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,220,220);color:black\"> 2.321e-6 <strong>(0.199)</strong> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> x3 </th>\n",
       "        <td style=\"background-color:rgb(126,126,250);color:black\"> -55.9e-6 <strong>(-0.957)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,195,195);color:black\"> 20.6e-6 <strong>(0.364)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,170,170);color:black\"> 3.075e-6 <strong>(0.533)</strong> </td>\n",
       "        <td> 0.00177 </td>\n",
       "        <td style=\"background-color:rgb(136,136,250);color:black\"> -0.0047 <strong>(-0.874)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,105,105);color:black\"> 0.31e-3 <strong>(0.964)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,154,154);color:black\"> 0.0023 <strong>(0.641)</strong> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> x4 </th>\n",
       "        <td style=\"background-color:rgb(250,128,128);color:black\"> 144.0e-6 <strong>(0.816)</strong> </td>\n",
       "        <td style=\"background-color:rgb(194,194,250);color:black\"> -73.9e-6 <strong>(-0.433)</strong> </td>\n",
       "        <td style=\"background-color:rgb(201,201,250);color:black\"> -6.542e-6 <strong>(-0.375)</strong> </td>\n",
       "        <td style=\"background-color:rgb(136,136,250);color:black\"> -0.0047 <strong>(-0.874)</strong> </td>\n",
       "        <td> 0.0161 </td>\n",
       "        <td style=\"background-color:rgb(143,143,250);color:black\"> -0.81e-3 <strong>(-0.823)</strong> </td>\n",
       "        <td style=\"background-color:rgb(197,197,250);color:black\"> -0.004 <strong>(-0.411)</strong> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> x5 </th>\n",
       "        <td style=\"background-color:rgb(135,135,250);color:black\"> -9.5e-6 <strong>(-0.884)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,199,199);color:black\"> 3.6e-6 <strong>(0.342)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,177,177);color:black\"> 0.518e-6 <strong>(0.489)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,105,105);color:black\"> 0.31e-3 <strong>(0.964)</strong> </td>\n",
       "        <td style=\"background-color:rgb(143,143,250);color:black\"> -0.81e-3 <strong>(-0.823)</strong> </td>\n",
       "        <td> 5.98e-05 </td>\n",
       "        <td style=\"background-color:rgb(250,161,161);color:black\"> 0.39e-3 <strong>(0.590)</strong> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th> x6 </th>\n",
       "        <td style=\"background-color:rgb(175,175,250);color:black\"> -68.5e-6 <strong>(-0.580)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,188,188);color:black\"> 47.1e-6 <strong>(0.412)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,220,220);color:black\"> 2.321e-6 <strong>(0.199)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,154,154);color:black\"> 0.0023 <strong>(0.641)</strong> </td>\n",
       "        <td style=\"background-color:rgb(197,197,250);color:black\"> -0.004 <strong>(-0.411)</strong> </td>\n",
       "        <td style=\"background-color:rgb(250,161,161);color:black\"> 0.39e-3 <strong>(0.590)</strong> </td>\n",
       "        <td> 0.00723 </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "┌─────────────────────────────────────────────────────────────────────────┐\n",
       "│                                Migrad                                   │\n",
       "├──────────────────────────────────┬──────────────────────────────────────┤\n",
       "│ FCN = 4.019 (χ²/ndof = 2.0)      │             Nfcn = 5951              │\n",
       "│ EDM = 10.7 (Goal: 2e-08)         │                                      │\n",
       "├──────────────────────────────────┼──────────────────────────────────────┤\n",
       "│         INVALID Minimum          │   ABOVE EDM threshold (goal x 10)    │\n",
       "├──────────────────────────────────┼──────────────────────────────────────┤\n",
       "│      No parameters at limit      │           Below call limit           │\n",
       "├──────────────────────────────────┼──────────────────────────────────────┤\n",
       "│             Hesse ok             │     Covariance FORCED pos. def.      │\n",
       "└──────────────────────────────────┴──────────────────────────────────────┘\n",
       "┌───┬──────┬───────────┬───────────┬────────────┬────────────┬─────────┬─────────┬───────┐\n",
       "│   │ Name │   Value   │ Hesse Err │ Minos Err- │ Minos Err+ │ Limit-  │ Limit+  │ Fixed │\n",
       "├───┼──────┼───────────┼───────────┼────────────┼────────────┼─────────┼─────────┼───────┤\n",
       "│ 0 │ x0   │  0.0043   │  0.0014   │            │            │         │         │       │\n",
       "│ 1 │ x1   │  2.3570   │  0.0013   │            │            │         │         │       │\n",
       "│ 2 │ x2   │-582.00e-3 │  0.14e-3  │            │            │         │         │       │\n",
       "│ 3 │ x3   │   0.00    │   0.04    │            │            │         │         │       │\n",
       "│ 4 │ x4   │   -0.95   │   0.13    │            │            │         │         │       │\n",
       "│ 5 │ x5   │  -0.042   │   0.008   │            │            │         │         │       │\n",
       "│ 6 │ x6   │   0.05    │   0.09    │            │            │         │         │       │\n",
       "└───┴──────┴───────────┴───────────┴────────────┴────────────┴─────────┴─────────┴───────┘\n",
       "┌────┬───────────────────────────────────────────────────────────────────────┐\n",
       "│    │        x0        x1        x2        x3        x4        x5        x6 │\n",
       "├────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│ x0 │  1.93e-06   -0.7e-6 -0.093e-6  -55.9e-6  144.0e-6   -9.5e-6  -68.5e-6 │\n",
       "│ x1 │   -0.7e-6  1.81e-06 -0.031e-6   20.6e-6  -73.9e-6    3.6e-6   47.1e-6 │\n",
       "│ x2 │ -0.093e-6 -0.031e-6  1.88e-08  3.075e-6 -6.542e-6  0.518e-6  2.321e-6 │\n",
       "│ x3 │  -55.9e-6   20.6e-6  3.075e-6   0.00177   -0.0047   0.31e-3    0.0023 │\n",
       "│ x4 │  144.0e-6  -73.9e-6 -6.542e-6   -0.0047    0.0161  -0.81e-3    -0.004 │\n",
       "│ x5 │   -9.5e-6    3.6e-6  0.518e-6   0.31e-3  -0.81e-3  5.98e-05   0.39e-3 │\n",
       "│ x6 │  -68.5e-6   47.1e-6  2.321e-6    0.0023    -0.004   0.39e-3   0.00723 │\n",
       "└────┴───────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 4.29178475e-03,  2.35696294e+00, -5.82002771e-01,  4.66149605e-04,\n",
       "       -9.52395965e-01, -4.17665384e-02,  5.06604917e-02])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<ErrorbarContainer object of 3 artists>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12db04190>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.88, 0.8, '$\\\\chi^2/ndof=2.0$')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.88, 0.7, '$E_0=0.582\\\\pm 0.000$')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.88, 0.65, '$dlog(0)=0.600\\\\pm 0.016$')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '$T$ ')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$G(R,T)$')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=0\n",
    "k=0\n",
    "r=3\n",
    "pos=0\n",
    "\n",
    "jackkl=100000\n",
    "jump_configs=1\n",
    "\n",
    "mcalls=10000\n",
    "mtol=0.00001\n",
    "\n",
    "totaltraj=int(len(data[x][k])/size[k])\n",
    "Nt=Textent\n",
    "\n",
    "Gc=np.zeros((int(totaltraj/jump_configs),Nt))\n",
    "for i in range(int(totaltraj/jump_configs)):\n",
    "    index=jump_configs*i\n",
    "    Gc[[i]]=data[x][k][range(index*Nt,(index+1)*Nt),[r]]\n",
    "    \n",
    "#logG=np.log(ratio(trim_negative(Gc).trimmed()).val())\n",
    "\n",
    "\n",
    "# Get average over all data, we will then replicate for every Jackknife sample to get errors\n",
    "\n",
    "gdata=jackknife(Gc,jackkl).sample()\n",
    "lt=len(Gc[0])\n",
    "dfin=min(lt,100)\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_2t  = np.linspace(1, 2*lt-1, 2*lt-1)\n",
    "if pos==0:\n",
    "    data_y   = ensemble_stat(gdata).mean()\n",
    "else:\n",
    "    data_y   = gdata[pos]\n",
    "data_cov = ensemble_stat(jackknife(gdata,jackkl).up()).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(jackknife(gdata,jackkl).up()).rcov()))\n",
    "\n",
    "data_y\n",
    "np.sort(np.sqrt(np.diag(improved_inverse_covariance(data_cov))))\n",
    "\n",
    "data_covf = np.identity(lt)\n",
    "for i in range(len(np.sqrt(np.diag(data_cov)))):\n",
    "    for j in range(len(np.sqrt(np.diag(data_cov)))):\n",
    "        data_covf[i][j]*=np.sqrt(np.diag(data_cov))[i]*np.sqrt(np.diag(data_cov))[j]\n",
    "\n",
    "tini=1\n",
    "tfin=9\n",
    "\n",
    "funfit='nb_exp_np_pole'\n",
    "inipars=[0.0,1.,1.,0.1,1.0,0.1,0.1]\n",
    "#funfit='nb_exp_np'\n",
    "#inipars=[-0.46355412, -2.793052 ]\n",
    " \n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, tini, tfin, inipars, funfit , mcalls, mtol,0,1,0,0,10,10)\n",
    "\n",
    "fit=m.minimize()\n",
    "fit\n",
    "np.array(fit.values)\n",
    "\n",
    "if (len(inipars)%2==0):\n",
    "    mass  = np.abs(np.array(fit.values)[1])\n",
    "    emass = np.array(fit.errors)[1]\n",
    "else:\n",
    "    mass  = np.abs(np.array(fit.values)[2])\n",
    "    emass = np.array(fit.errors)[2]   \n",
    "\n",
    "\n",
    "dlog=loglimG(0,*np.array(fit.values)[1:])\n",
    "edlog=prop_err(0,'loglimG',np.array(fit.values)[1:],np.array(fit.errors)[1:],np.array(fit.covariance.correlation())[1:,1:])[0]\n",
    "\n",
    "data_t_plot=np.linspace(data_t[0],data_t[-1],1000)\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t_plot, eval(funfit)(data_t_plot, *fit.values), label=\"fit\")\n",
    "\n",
    "#plt.yscale('log')\n",
    "\n",
    "plt.figtext(0.88, 0.8, \n",
    "                '$\\\\chi^2/ndof={:.1f}$'.format(fit.fval/fit.ndof), \n",
    "                horizontalalignment =\"right\",  \n",
    "                verticalalignment =\"center\",  \n",
    "                wrap = True, fontsize = 12,  \n",
    "                color =\"black\")\n",
    "plt.figtext(0.88, 0.7, \n",
    "                '$E_0={:.3f}\\\\pm {:.3f}$'.format(mass,emass), \n",
    "                horizontalalignment =\"right\",  \n",
    "                verticalalignment =\"center\",  \n",
    "                wrap = True, fontsize = 12,  \n",
    "                color =\"black\")\n",
    "plt.figtext(0.88, 0.65, \n",
    "                '$dlog(0)={:.3f}\\\\pm {:.3f}$'.format(dlog,edlog), \n",
    "                horizontalalignment =\"right\",  \n",
    "                verticalalignment =\"center\",  \n",
    "                wrap = True, fontsize = 12,  \n",
    "                color =\"black\")\n",
    "plt.xlabel(\"$T$ \",fontsize=12)\n",
    "plt.ylabel(\"$G(R,T)$\",fontsize=12, rotation=90, loc='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.21117458, 1.28138604, 1.17533155, ..., 1.25877697, 1.24069075,\n",
       "       1.28731942])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(1.2513963643009975)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(1.418929864005)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gc[:,0]\n",
    "np.mean(Gc[:,0])\n",
    "np.max(Gc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.25141655, 1.25138132, 1.25143453, ..., 1.25139266, 1.25140174,\n",
       "       1.25137834])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(1.2514917829298533)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdata=jackknife(Gc,jackkl).sample()[:,0]\n",
    "gdata\n",
    "np.max(gdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.21117458, 1.28138604, 1.17533155, ..., 1.25877697, 1.24069075,\n",
       "       1.28731942])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(1.418929864005098)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jackknife(gdata,jackkl).up()\n",
    "np.max(jackknife(gdata,jackkl).up())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../S_correlators_L32/Gc_plots/xi=1/3_nb_exp_np_pole_exp_AIC_list_ti1_0_tfin16_tmin12_beta=225_R=1_nocorrs=0_g\", \"rb\") as fp:   # Unpickling\n",
    "   b = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00010075])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00010075])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00010071])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00010071])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5142635155172564)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5142635155172567)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00010122])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00010075])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.0001007])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.0001007])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdata1=b.ordered()[0][4][:,1]\n",
    "gdata2=b.ordered()[6][4][:,1]\n",
    "\n",
    "Gdata1=jackknife(gdata1,jackkl).pup()\n",
    "Gdata2=jackknife(gdata2,jackkl).pup()\n",
    "weights=[0.9,0.1]\n",
    "\n",
    "(jackknife(gdata1**2).fmean()-jackknife(gdata1).fmean()**2)*(len(gdata1)-1)\n",
    "jackknife(Gdata1**2).fmean()-jackknife(Gdata1).fmean()**2\n",
    "\n",
    "\n",
    "(jackknife(gdata2**2).fmean()-jackknife(gdata2).fmean()**2)*(len(gdata2)-1)\n",
    "jackknife(Gdata2**2).fmean()-jackknife(Gdata2).fmean()**2\n",
    "\n",
    "\n",
    "gdata=gdata1*weights[0]+gdata2*weights[1]\n",
    "gdatasq=gdata1**2*weights[0]+gdata2**2*weights[1]\n",
    "Gdata=Gdata1*weights[0]+Gdata2*weights[1]\n",
    "Gdatasq=Gdata1**2*weights[0]+Gdata2**2*weights[1]\n",
    "\n",
    "gdata.mean()\n",
    "Gdata.mean()\n",
    "\n",
    "len(gdata)\n",
    "(jackknife(gdatasq).fmean()-jackknife(gdata).fmean()**2)*(len(gdata)-1)\n",
    "jackknife(Gdatasq).fmean()-jackknife(Gdata).fmean()**2\n",
    "(jackknife(gdata**2).fmean()-jackknife(gdata).fmean()**2)*(len(gdata)-1)\n",
    "jackknife(Gdata**2).fmean()-jackknife(Gdata).fmean()**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26457516])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.26457516])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jackknife(gdata1).upcov()+jackknife(gdata1).fmean()**2\n",
    "jackknife(Gdata1**2).fmean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.33397993e-06, 1.12768105e-07],\n",
       "       [1.12768105e-07, 2.31189511e-08]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.64213682],\n",
       "       [0.64213682, 1.        ]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.27380228e-08, -2.61242528e-11],\n",
       "       [-2.61242528e-11,  1.05894645e-08]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.28327604e-07, -9.22688373e-10],\n",
       "       [-9.22688373e-10,  9.59603365e-09]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gc=np.zeros((int(totaltraj/jump_configs),Nt))\n",
    "for i in range(int(totaltraj/jump_configs)):\n",
    "    index=jump_configs*i\n",
    "    Gc[[i]]=data[x][k][range(index*Nt,(index+1)*Nt),[r]]\n",
    "    \n",
    "#logG=np.log(ratio(trim_negative(Gc).trimmed()).val())\n",
    "\n",
    "\n",
    "# Get average over all data, we will then replicate for every Jackknife sample to get errors\n",
    "\n",
    "gdata1=jackknife(jackknife(Gc,jackkl).sample()[:,0]).pup()\n",
    "gdata2=jackknife(jackknife(Gc,jackkl).sample()[:,9]).pup()\n",
    "\n",
    "np.cov(gdata1,gdata2)\n",
    "np.corrcoef(gdata1,gdata2)\n",
    "\n",
    "\n",
    "np.cov(add_gaussian_noise(gdata1,1e-7),add_gaussian_noise(gdata2,1e-8))-np.cov(gdata1,gdata2)\n",
    "np.cov(add_gaussian_noise2(gdata1,1e-7),add_gaussian_noise2(gdata2,1e-8))-np.cov(gdata1,gdata2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00010083])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.10071575])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val=Gdata1.mean()*weights[0]+Gdata2.mean()*weights[1]\n",
    "eval=(jackknife(Gdata1**2).fmean()*weights[0]+jackknife(Gdata2**2).fmean()*weights[1])\n",
    "\n",
    "val2=gdata1.mean()*weights[0]+gdata2.mean()*weights[1]\n",
    "eval2=((jackknife(gdata1).upcov()+jackknife(gdata1).fmean()**2)*weights[0]+(jackknife(gdata2).upcov()+jackknife(gdata2).fmean()**2)*weights[1])\n",
    "\n",
    "\n",
    "eval-val**2\n",
    "eval2-val2**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.37933672e-05, 4.35990770e-08, 3.11586735e-09, 1.01556374e-09,\n",
       "       4.73928161e-10, 3.33576786e-10, 2.49249539e-10, 1.83717921e-10,\n",
       "       8.16209918e-22, 6.04466121e-22])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative eig found== -8.183877357811934e-22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.37933672e-05, 4.35990770e-08, 3.11586735e-09, 1.01556374e-09,\n",
       "       4.73928161e-10, 3.33576854e-10, 2.49249489e-10, 1.83717921e-10,\n",
       "       8.15941334e-22, 1.29402036e-22])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_near_psd(A):   # As explained in N.J. Higham, \"Computing a nearest symmetric positive semidefinite matrix\" (1988): https://doi.org/10.1016/0024-3795(88)90223-6\n",
    "    if (len(np.shape(A))<2):\n",
    "        result=A\n",
    "    else:\n",
    "        C=(A + np.transpose(A))/2\n",
    "        eigval, eigvec = np.linalg.eig(C)\n",
    "        if (np.min(eigval)<0):\n",
    "            print('Negative eig found==',np.min(eigval))\n",
    "        eigval[eigval < 0] = 0\n",
    "        result=np.transpose(eigvec).dot(np.diag(eigval)).dot(eigvec)\n",
    "        #result=(result+np.transpose(result))/2\n",
    "    return result\n",
    "\n",
    "try_matrix=data_cov_R\n",
    "\n",
    "np.linalg.svd(try_matrix)[1]\n",
    "np.linalg.svd(get_near_psd(try_matrix))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.440892098500626e-16)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(5.24173948860076e-16)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1.24867594e+02, 6.54523399e-14])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 8.00848298e-03, -1.58443683e+01])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-1.58443683e+01,  1.52782926e+13])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 8.00848298e-03, -1.58443683e+01])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 8.00848298e-03, -1.58443683e+01])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def improved_inverse_covariance2(A):    # It computes the Moore-Penrose pseudo-inverse. It produces a SVD decomp and inverse, which resets small singular values via a condition related to machine precision. If no small singular values are found, it provides with the actual SVD method inversion\n",
    "    rtol=len(A)*np.finfo(np.float64).eps\n",
    "    svd=sp.linalg.svd(A)\n",
    "    eig_sign=np.round(np.real(sp.linalg.eig(A)[0])/np.abs(np.real(sp.linalg.eig(A)[0])))\n",
    "    singular_value=svd[1][-1]/svd[1][0]\n",
    "    #print(singular_value,rtol)\n",
    "    if (singular_value>rtol):\n",
    "        UT=np.transpose(svd[0])\n",
    "        inv_list=1/svd[1]*eig_sign\n",
    "        inv_list[inv_list < 0]=0\n",
    "        S_inv=np.diag(inv_list)\n",
    "        V=np.transpose(svd[2])\n",
    "        inv_A=np.dot(np.dot(V,S_inv),UT)\n",
    "    else:\n",
    "        inv_A=sp.linalg.pinvh(A)\n",
    "    return inv_A\n",
    "\n",
    "\n",
    "def improved_inverse_covariance_near_psd(A):\n",
    "    lA=len(A)\n",
    "    I=np.diag(np.ones(lA))\n",
    "    if (np.min(sp.linalg.eig(A)[0])>0):\n",
    "        result=sp.linalg.svd(A, lapack_driver='gesvd')\n",
    "        UT=np.transpose(result[0])\n",
    "        S_inv=np.diag(1./result[1])\n",
    "        V=np.transpose(result[2])\n",
    "        UT=np.transpose(V).copy()\n",
    "        inv_A=np.dot(np.dot(V,S_inv),UT)\n",
    "    else:\n",
    "        inv_A=sp.linalg.pinv(A)\n",
    "    return inv_A\n",
    "\n",
    "\n",
    "def improved_inverse_covariance(A):    # It computes the Moore-Penrose pseudo-inverse. It produces a SVD decomp and inverse, which resets small singular values via a condition related to machine precision. If no small singular values are found, it provides with the actual SVD method inversion\n",
    "    inv_A=sp.linalg.pinvh(A)\n",
    "    return inv_A\n",
    "\n",
    "try_matrix=[[1.24867594065e2,0.000000000129494060556078701111],[0.000000000129494060556078701111,6.545234e-14]]\n",
    "#try_matrix=data_cov_R\n",
    "2*np.finfo(np.float64).eps\n",
    "np.linalg.svd(try_matrix)[1][-1]/np.linalg.svd(try_matrix)[1][0]\n",
    "\n",
    "np.linalg.eig(try_matrix)[0]\n",
    "\n",
    "np.allclose(improved_inverse_covariance(try_matrix),np.transpose(improved_inverse_covariance(try_matrix)))\n",
    "np.allclose(improved_inverse_covariance2(try_matrix),np.transpose(improved_inverse_covariance2(try_matrix)))\n",
    "np.allclose(improved_inverse_covariance_no_near_psd(try_matrix),np.transpose(improved_inverse_covariance_no_near_psd(try_matrix)))\n",
    "np.allclose(np.linalg.inv(try_matrix),np.transpose(np.linalg.inv(try_matrix)))\n",
    "\n",
    "improved_inverse_covariance(try_matrix)[0]\n",
    "improved_inverse_covariance(try_matrix)[1]\n",
    "improved_inverse_covariance2(try_matrix)[0]\n",
    "improved_inverse_covariance_no_near_psd(try_matrix)[0]\n",
    "\n",
    "np.allclose(improved_inverse_covariance(try_matrix),improved_inverse_covariance2(try_matrix))\n",
    "np.max(np.abs(improved_inverse_covariance2(try_matrix)-improved_inverse_covariance_no_near_psd(try_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.2005662759242832e-100)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(-5.704278066648301e-72)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(2.6848588206907085e-61)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(-5.854123423105823e-90)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0909481305157181e-17 2.220446049250313e-15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(-4.057230209971613e-92)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0909481305157181e-17 2.220446049250313e-15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(5.664896358398598e-92)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(-1.2635288365754236e-94)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(-4.470566973604055e-93)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(5.839573907996314e-122)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(6.720390456912959e-122)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=0\n",
    "k=1\n",
    "T=1\n",
    "lt=len(Gc[0])\n",
    "totaltraj=int(len(data[x][k])/size[k])\n",
    "G_in_R=np.zeros((int(totaltraj/jump_configs),Nt))\n",
    "for i in range(int(totaltraj/jump_configs)):\n",
    "    for r in range(lt):\n",
    "        index=jump_configs*i\n",
    "        G_in_R[i][r]=data[x][k][range(index*Nt,(index+1)*Nt),[r]][T]\n",
    "\n",
    "data_cov_R=ensemble_stat(G_in_R).rcov()\n",
    "\n",
    "np.linalg.det(np.dot(sp.linalg.inv(try_matrix),try_matrix)-np.diag(np.ones(lt)))\n",
    "np.linalg.det(np.dot(try_matrix,sp.linalg.inv(try_matrix))-np.diag(np.ones(lt)))\n",
    "np.linalg.det(np.dot(np.linalg.inv(try_matrix),try_matrix)-np.diag(np.ones(lt)))\n",
    "np.linalg.det(np.dot(try_matrix,np.linalg.inv(try_matrix))-np.diag(np.ones(lt)))\n",
    "np.linalg.det(np.dot(improved_inverse_covariance2(try_matrix),try_matrix)-np.diag(np.ones(lt)))\n",
    "np.linalg.det(np.dot(try_matrix,improved_inverse_covariance2(try_matrix))-np.diag(np.ones(lt)))\n",
    "np.linalg.det(np.dot(improved_inverse_covariance_no_near_psd(try_matrix),try_matrix)-np.diag(np.ones(lt)))\n",
    "np.linalg.det(np.dot(try_matrix,improved_inverse_covariance_no_near_psd(try_matrix))-np.diag(np.ones(lt)))\n",
    "np.linalg.det(np.dot(improved_inverse_covariance(try_matrix),try_matrix)-np.diag(np.ones(lt)))\n",
    "np.linalg.det(np.dot(try_matrix,improved_inverse_covariance(try_matrix))-np.diag(np.ones(lt)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_check=[[1.e6,0],[0,-1.e-2]]\n",
    "matrix_check=get_near_psd(matrix_check)\n",
    "\n",
    "sp.linalg.eig(matrix_check)[0]\n",
    "#inv1=sp.linalg.inv(matrix_check)\n",
    "result=sp.linalg.svd(matrix_check)\n",
    "UT=np.transpose(result[0])\n",
    "S_inv=np.diag(1./result[1])\n",
    "V=np.transpose(result[2])\n",
    "result[1]\n",
    "inv2=np.dot(np.dot(V,S_inv),UT)\n",
    "sp.linalg.pinv(matrix_check, return_rank=True)[1]\n",
    "inv3=sp.linalg.pinv(matrix_check, return_rank=True)[0]\n",
    "\n",
    "inv1\n",
    "inv2\n",
    "inv3\n",
    "\n",
    "sp.linalg.det(np.dot(matrix_check,inv1)-np.diag(np.ones(2)))\n",
    "sp.linalg.det(np.dot(inv1,matrix_check)-np.diag(np.ones(2)))\n",
    "sp.linalg.det(np.dot(matrix_check,inv2)-np.diag(np.ones(2)))\n",
    "sp.linalg.det(np.dot(inv2,matrix_check)-np.diag(np.ones(2)))\n",
    "sp.linalg.det(np.dot(matrix_check,inv3)-np.diag(np.ones(2)))\n",
    "sp.linalg.det(np.dot(inv3,matrix_check)-np.diag(np.ones(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=0\n",
    "k=7\n",
    "r=8\n",
    "pos=0\n",
    "\n",
    "tini=1\n",
    "tfin=12\n",
    "\n",
    "jackkl=1000\n",
    "jump_configs=1\n",
    "\n",
    "mcalls=10000\n",
    "mtol=0.00001\n",
    "\n",
    "totaltraj=int(len(data[x][k])/size[k])\n",
    "Nt=Textent\n",
    "\n",
    "Gc=np.zeros((int(totaltraj/jump_configs),Nt))\n",
    "for i in range(int(totaltraj/jump_configs)):\n",
    "    index=jump_configs*i\n",
    "    Gc[[i]]=data[x][k][range(index*Nt,(index+1)*Nt),[r]]\n",
    "    \n",
    "#logG=np.log(ratio(trim_negative(Gc).trimmed()).val())\n",
    "\n",
    "\n",
    "# Get average over all data, we will then replicate for every Jackknife sample to get errors\n",
    "\n",
    "gdata=jackknife(Gc,jackkl).sample()\n",
    "lt=len(Gc[0])\n",
    "dfin=min(lt,100)\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_2t  = np.linspace(1, 2*lt-1, 2*lt-1)\n",
    "if pos==0:\n",
    "    data_y   = ensemble_stat(gdata).mean()\n",
    "else:\n",
    "    data_y   = gdata[pos]\n",
    "data_cov = ensemble_stat(jackknife(gdata,jackkl).up()).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(jackknife(gdata,jackkl).up()).rcov()))\n",
    "\n",
    "\n",
    "data_covf = np.identity(lt)\n",
    "for i in range(len(np.sqrt(np.diag(data_cov)))):\n",
    "    for j in range(len(np.sqrt(np.diag(data_cov)))):\n",
    "        data_covf[i][j]*=np.sqrt(np.diag(data_cov))[i]*np.sqrt(np.diag(data_cov))[j]\n",
    "\n",
    "\n",
    "funfit='nb_exp_np_pole'\n",
    "inipars=[0.,2.,1.,0.1,1.0,0.1,1.0]\n",
    "#funfit='nb_exp_np'\n",
    "#inipars=[-0.46355412, -2.793052 ]\n",
    " \n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, tini, tfin, inipars, funfit , mcalls, mtol,0,1,0,0,10,1000)\n",
    "\n",
    "m.minimize()\n",
    "\n",
    "fit=m.minimize()\n",
    "\n",
    "E_val=np.array(fit.values)[2]\n",
    "E_err=np.array(fit.errors)[2]\n",
    "\n",
    "dlog=loglimG(0,*np.array(fit.values)[1:])\n",
    "edlog=prop_err(0,'loglimG',np.array(fit.values)[1:],np.array(fit.errors)[1:],np.array(fit.covariance.correlation())[1:,1:])[0]\n",
    "chi2= m.minimize().fval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ini_jackk_pars=np.array(fit.values)\n",
    "\n",
    "dlog_jackk = []\n",
    "E_jackk    = []\n",
    "chi2_jackk = []\n",
    "for jackk in range(min(totaltraj,jackkl)):\n",
    "    pos=jackk\n",
    "    data_y=gdata[pos]\n",
    "    m=RepeatSingleFit(data_t, data_y, data_cov, tini, tfin, ini_jackk_pars, funfit , mcalls, mtol,0,1,0,0,10,0)\n",
    "    if (m.minimize().valid==False):\n",
    "        print('Trying fix',jackk)\n",
    "        ntries=50\n",
    "        for k in range(ntries):\n",
    "            s = np.random.normal(0, 0.01, len(ini_jackk_pars))\n",
    "            inipars_list=(1+s)*ini_jackk_pars\n",
    "            m2=RepeatSingleFit(data_t, data_y, data_cov, tini, tfin, inipars_list, funfit , mcalls, mtol,0,1,0,0,10,0)\n",
    "            if (m2.minimize().valid):\n",
    "                m=m2\n",
    "                break\n",
    "\n",
    "    if (m.minimize().valid==False):\n",
    "        print('Not valid',jackk)\n",
    "\n",
    "    fit=m.minimize()\n",
    "    dlog_jackk.append(loglimG(0,*np.array(fit.values)[1:]))\n",
    "    E_jackk.append(np.array(fit.values)[2])\n",
    "    chi2_jackk.append(fit.fval)\n",
    "\n",
    "\n",
    "print(dlog,edlog)\n",
    "print(ensemble_stat(dlog_jackk).mean(),np.sqrt(ensemble_stat(jackknife(dlog_jackk).up()).rcov()))\n",
    "print(E_val,E_err)\n",
    "print(ensemble_stat(E_jackk).mean(),np.sqrt(ensemble_stat(jackknife(E_jackk).up()).rcov()))\n",
    "chi2_f_jackk=np.mean(chi2_jackk)-((tfin-tini+1)-len(inipars))/(len(chi2_jackk)-1)\n",
    "print(chi2,chi2_f_jackk,np.abs(chi2_f_jackk-chi2)/chi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocess=10\n",
    "filefin=0\n",
    "multistart=100\n",
    "\n",
    "mcalls=10000\n",
    "mtol=0.00001\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Select data files to be fitted\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "datarun=[]\n",
    "dataint  = data[xiini:xifin+1]\n",
    "for i in range(len(dataint)):\n",
    "    datarun.append(dataint[i][fileini:filefin+1])\n",
    "\n",
    "sizerun  = size[fileini:filefin+1]\n",
    "betarun  = beta[fileini:filefin+1]\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#Prepare options for fitting\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "if (dini_Gc==0):\n",
    "    diini  = 0\n",
    "    distop = 0\n",
    "else:\n",
    "    diini   = dini_Gc\n",
    "    distop = dini_Gc+dstop_Gc\n",
    "    \n",
    "x=0\n",
    "k=0\n",
    "r=5\n",
    "\n",
    "totaltraj=int(len(data[x][k])/size[k])\n",
    "Nt=Textent\n",
    "\n",
    "Gc=np.zeros((totaltraj,Nt))\n",
    "for i in range(totaltraj):\n",
    "    Gc[[i]]=data[x][k][range(i*Nt,(i+1)*Nt),[r]]\n",
    "    \n",
    "logG=np.log(ratio(trim_negative(Gc).trimmed()).val())\n",
    "\n",
    "\n",
    "# Get average over all data, we will then replicate for every Jackknife sample to get errors\n",
    "jackkl=10000\n",
    "\n",
    "#datatype_Gc='exp'\n",
    "\n",
    "\n",
    "if (datatype_Gc==\"dlog\"):\n",
    "    gdata=np.log(ratio(trim_negative(jackknife(Gc,jackkl).sample()).trimmed()).val())\n",
    "elif (datatype_Gc==\"log\" or datatype_Gc==\"log_pole\"):\n",
    "    gdata=np.log(trim_negative(jackknife(Gc,jackkl).sample()).trimmed())\n",
    "    #gdata=np.log(trim_negative(Gc).trimmed())\n",
    "elif (datatype_Gc==\"exp\" or datatype_Gc==\"exp_WL\" or datatype_Gc==\"exp_line\"):\n",
    "    gdata=jackknife(Gc,jackkl).sample()\n",
    "\n",
    "gdata=jackknife(gdata,jackkl).up()\n",
    "\n",
    "\n",
    "lt=len(gdata[0])\n",
    "dfin=min(lt,100)\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = jackknife(gdata,jackkl).sample()\n",
    "data_cov = jackknife(gdata,jackkl).scov()\n",
    "\n",
    "\n",
    "model_Gc='nb_exp_np_pole'\n",
    "inipars_Gc  = [[0.0,2.0,1.0],[0.0,2.0,1.0,0.1,1.0],[0.0,2.0,1.0,0.1,1.0,0.1,1.0]]                                                                                        # Input pars to fit with\n",
    "variants_Gc = ['single','double','triple']  \n",
    "#dmindata_Gc=5\n",
    "\n",
    "m=Modelsmin(data_t, data_y, data_cov, dini_Gc, dstop_Gc, dmindata_Gc, dfin_Gc, inipars_Gc, model_Gc, variants_Gc, datatype_Gc, mcalls, mtol, reuse, inv_first, multiprocess,cov_freeze,improve,multistart,no_corrs,no_valid_check)\n",
    "mf=m.jackk_minimize()\n",
    "AIC_list=Jackknife_AIClist(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC_list.ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC_list.avgval0(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=1\n",
    "\n",
    "betarun  = beta[0:11]\n",
    "xirun    = xi\n",
    "diini    = 1\n",
    "variants_Gc=[1,2]\n",
    "\n",
    "Vdat=[]\n",
    "for i in range(len(betarun)):\n",
    "    print('{}{}/{}_{}_{}_VR_rescaled_ti{}_{}_tfin{}_tmin{}_cut{}_beta={}_nocorrs={}_{}.dat'.format(resultspath,xi[0],len(variants_Gc),model_Gc,datatype_Gc,diini,dstop_Gc,dfin_Gc,dmindata_Gc,cutoff_ma,betarun[i],no_corrs,corrtype))\n",
    "    Vdat_int=np.loadtxt('{}{}/{}_{}_{}_VR_rescaled_ti{}_{}_tfin{}_tmin{}_cut{}_beta={}_nocorrs={}_{}.dat'.format(resultspath,xi[0],len(variants_Gc),model_Gc,datatype_Gc,diini,dstop_Gc,dfin_Gc,dmindata_Gc,cutoff_ma,betarun[i],no_corrs,corrtype))\n",
    "    Vdat.append(Vdat_int)\n",
    "\n",
    "lt       = len(Vdat[0][0])\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_tf  = np.linspace(1, lt, 100*lt)\n",
    "data_y   = ensemble_stat(Vdat[k]).mean()\n",
    "data_cov = ensemble_stat(Vdat[k]).rcov()     # Do not use these non-diagonal elements, they come from a rescaled sample, they are not correct\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(Vdat[k]).rcov()))\n",
    "\n",
    "data_y\n",
    "data_err\n",
    "\n",
    "pos=0\n",
    "\n",
    "jackkl=100000\n",
    "jump_configs=1\n",
    "\n",
    "mcalls=10000\n",
    "mtol=0.00001\n",
    "\n",
    "\n",
    "rini=1\n",
    "rfin=12\n",
    "\n",
    "funfit='nb_VR_line'\n",
    "inipars=[0.0,2.,1.]\n",
    " \n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, rini, rfin, inipars, funfit , mcalls, mtol,0,1,0,0,10,10)\n",
    "\n",
    "fit=m.minimize()\n",
    "fit\n",
    "np.array(fit.values)\n",
    "\n",
    "\n",
    "sigma  = np.abs(np.array(fit.values)[2])/als[0][k]**2/0.44**2/gev_m1_tofm**2\n",
    "esigma = np.array(fit.errors)[2]/als[0][k]**2/0.44**2/gev_m1_tofm**2\n",
    "\n",
    "\n",
    "data_t_plot=np.linspace(data_t[0],data_t[-1],1000)\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t_plot, eval(funfit)(data_t_plot, *fit.values), label=\"fit\")\n",
    "\n",
    "#plt.yscale('log')\n",
    "\n",
    "plt.figtext(0.35, 0.8, \n",
    "                '$\\\\chi^2/ndof={:.1f}$'.format(fit.fval/fit.ndof), \n",
    "                horizontalalignment =\"right\",  \n",
    "                verticalalignment =\"center\",  \n",
    "                wrap = True, fontsize = 12,  \n",
    "                color =\"black\")\n",
    "plt.figtext(0.35, 0.7, \n",
    "                '$\\\\sigma={:.2f}\\\\pm {:.2f}$'.format(sigma,esigma), \n",
    "                horizontalalignment =\"right\",  \n",
    "                verticalalignment =\"center\",  \n",
    "                wrap = True, fontsize = 12,  \n",
    "                color =\"black\")\n",
    "plt.xlabel(\"$R$ \",fontsize=12)\n",
    "plt.ylabel(\"$V(R)$\",fontsize=12, rotation=90, loc='center')\n",
    "plt.ylim(0,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../S_correlators_L32/Gc_plots/xi=4/2_nb_exp_np_pole_exp_AIC_list_ti1_0_tfin16_tmin12_beta=225_R=1_nocorrs=0_g\", \"rb\") as fp:   # Unpickling\n",
    "   b = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing autocorrelations, based on page 94 from Gattringer and Lang's and page 184 of Degrand and Detar\n",
    "\n",
    "def auto_func(t,a,b):\n",
    "    return a*np.exp(-t/b)\n",
    "\n",
    "def autocorr(list,dt):\n",
    "    mean=np.mean(list)\n",
    "    mean1=0\n",
    "    mean2=0\n",
    "    Ncfgs=len(list)\n",
    "    corr1=0\n",
    "    corr2=0\n",
    "    for i in range(Ncfgs-dt):\n",
    "        corr1+=(list[i]*list[i+dt])/(Ncfgs-dt)\n",
    "        corr2+=(list[i]-mean)*(list[i+dt]-mean)/(Ncfgs-dt)\n",
    "        mean1+=list[i]/(Ncfgs-dt)\n",
    "        mean2+=list[i+dt]/(Ncfgs-dt)\n",
    "    \n",
    "    corr1-=mean1*mean2\n",
    "    return corr2\n",
    "\n",
    "xi_range=1\n",
    "r_range=10\n",
    "r_ini=1\n",
    "tval=10\n",
    "t_ini=1\n",
    "ergodic_T=100\n",
    "\n",
    "for beta_label in range(len(beta)):\n",
    "\n",
    "    fig = plt.figure(figsize=(16,9))\n",
    "    plt.legend(fontsize=12,frameon=False,loc=0)\n",
    "\n",
    "    for x in range(xi_range):\n",
    "        corr_ergodic_final=[]\n",
    "\n",
    "        jump_configs=1\n",
    "        #print(len(data[x][beta_label]))\n",
    "        totaltraj=int(len(data[x][beta_label])/size[beta_label])\n",
    "        Nt=Textent\n",
    "        Gc=np.zeros((int(totaltraj/jump_configs),Nt))\n",
    "\n",
    "        for r in range(r_ini,r_ini+r_range):\n",
    "            for i in range(int(totaltraj/jump_configs)):\n",
    "                index=jump_configs*i\n",
    "                Gc[[i]]=data[x][beta_label][range(index*Nt,(index+1)*Nt),[r]]\n",
    "\n",
    "            data_ergodic   = np.linspace(0, ergodic_T, ergodic_T+1)\n",
    "            corr_ergodic=[]\n",
    "            for i in data_ergodic:\n",
    "                inter=0\n",
    "                for k in range(t_ini,t_ini+tval):\n",
    "                     inter+=autocorr(Gc[:,k],int(i))/autocorr(Gc[:,k],0)/tval\n",
    "\n",
    "                corr_ergodic.append(inter)\n",
    "\n",
    "            corr_ergodic_final.append(corr_ergodic)\n",
    "\n",
    "        final_autocor=np.mean(corr_ergodic_final,axis=0)\n",
    "        fit_autocor=sp.optimize.curve_fit(auto_func,data_ergodic,final_autocor)\n",
    "        time_autoco=fit_autocor[0][1]\n",
    "\n",
    "        plt.plot(data_ergodic, final_autocor, label='$\\\\xi={},\\\\tau={:10.2f}$'.format(x+1,time_autoco),color=jpac_color_around[x])\n",
    "        plt.legend(fontsize=12,frameon=False,loc=1)\n",
    "        #plt.plot(data_ergodic, auto_func(data_ergodic,fit_autocor[0][0],fit_autocor[0][1]), label=\"fit\",color=\"blue\")\n",
    "\n",
    "    plt.figtext(0.4, 0.8, \n",
    "                '$L={},\\, \\\\beta={}$'.format(sizelabel,beta[beta_label]/betanorm), \n",
    "                horizontalalignment =\"center\",  \n",
    "                verticalalignment =\"center\",  \n",
    "                wrap = True, fontsize = 20,  \n",
    "                color =\"black\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi_range=2\n",
    "r_range=1\n",
    "r_ini=15\n",
    "tval=1\n",
    "t_ini=1\n",
    "ergodic_T=100\n",
    "\n",
    "for beta_label in range(1,2+0*len(beta)):\n",
    "\n",
    "    fig = plt.figure(figsize=(16,9))\n",
    "    plt.legend(fontsize=12,frameon=False,loc=0)\n",
    "\n",
    "    for x in range(xi_range):\n",
    "        jump_configs=1\n",
    "        #print(len(data[x][beta_label]))\n",
    "        totaltraj=int(len(data[x][beta_label])/size[beta_label])\n",
    "        Nt=Textent\n",
    "        Gc=np.zeros((totaltraj,Nt))\n",
    "        Gc_avg=np.zeros(totaltraj)\n",
    "\n",
    "        for i in range(totaltraj):\n",
    "            for r in range(r_ini,r_ini+r_range):\n",
    "                index=jump_configs*i\n",
    "                Gc[[i]]+=data[x][beta_label][range(index*Nt,(index+1)*Nt),[r]]/r_range\n",
    "\n",
    "            for k in range(t_ini,t_ini+tval):\n",
    "                Gc_avg[[i]]+=Gc[i,k]/tval\n",
    "                \n",
    "\n",
    "        data_ergodic   = np.linspace(0, ergodic_T, ergodic_T+1)\n",
    "        corr_ergodic=[]\n",
    "        corr_ergodic_final=[]\n",
    "        for i in data_ergodic:\n",
    "            inter=autocorr(Gc_avg,int(i))/autocorr(Gc_avg,0)\n",
    "            corr_ergodic.append(inter)\n",
    "        corr_ergodic_final.append(corr_ergodic)\n",
    "\n",
    "        final_autocor=np.mean(corr_ergodic_final,axis=0)\n",
    "        fit_autocor=sp.optimize.curve_fit(auto_func,data_ergodic,final_autocor)\n",
    "        time_autoco=fit_autocor[0][1]\n",
    "\n",
    "        plt.plot(data_ergodic, final_autocor, label='$\\\\xi={},\\\\tau={:10.2f},Ncfgs={}$'.format(x+1,time_autoco,totaltraj),color=jpac_color_around[x])\n",
    "        plt.legend(fontsize=12,frameon=False,loc=1)\n",
    "        #plt.plot(data_ergodic, auto_func(data_ergodic,fit_autocor[0][0],fit_autocor[0][1]), label=\"fit\",color=\"blue\")\n",
    "\n",
    "    plt.figtext(0.4, 0.8, \n",
    "                '$L={},\\, \\\\beta={}$'.format(sizelabel,beta[beta_label]/betanorm), \n",
    "                horizontalalignment =\"center\",  \n",
    "                verticalalignment =\"center\",  \n",
    "                wrap = True, fontsize = 20,  \n",
    "                color =\"black\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_s=20\n",
    "repeat=100\n",
    "data_to_repeat=np.genfromtxt('../tests/Arkaitz-2.75.dat')\n",
    "data_test=np.zeros(repeat*len_s)\n",
    "\n",
    "for k in range(repeat):\n",
    "    for i in range(len_s):\n",
    "        data_test[[i+k*len_s]]=data_to_repeat[i+k][1]\n",
    "\n",
    "data_test   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test=np.genfromtxt('../tests/Arkaitz-2.75.dat')[:20\n",
    "\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "plt.legend(fontsize=12,frameon=False,loc=0)\n",
    "\n",
    "ergodic_T=80\n",
    "data_ergodic   = np.linspace(0, ergodic_T, ergodic_T+1)\n",
    "corr_ergodic=[]\n",
    "corr_ergodic_final=[]\n",
    "for i in data_ergodic:\n",
    "    inter=autocorr(data_test[:],int(i))/autocorr(data_test[:],0)\n",
    "    corr_ergodic.append(inter)\n",
    "\n",
    "corr_ergodic_final.append(corr_ergodic)\n",
    "\n",
    "final_autocor=corr_ergodic_final[0]\n",
    "fit_autocor=sp.optimize.curve_fit(auto_func,data_ergodic,final_autocor)\n",
    "time_autoco=fit_autocor[0][1]\n",
    "plt.scatter(data_ergodic, final_autocor, label='$\\\\beta=2.75,\\\\tau={:10.2f}$'.format(time_autoco),color=jpac_color_around[x])\n",
    "plt.legend(fontsize=12,frameon=False,loc=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if Jackknife is correct, we will test central values and errors\n",
    "\n",
    "x=0\n",
    "k=0\n",
    "r=0\n",
    "\n",
    "totaltraj=int(len(data[x][k])/size[k])\n",
    "Nt=Textent\n",
    "\n",
    "Gc=np.zeros((totaltraj,Nt))\n",
    "for i in range(totaltraj):\n",
    "    Gc[[i]]=data[x][k][range(i*Nt,(i+1)*Nt),[r]]\n",
    "    \n",
    "data_y   = ensemble_stat(Gc).mean()\n",
    "\n",
    "data_y\n",
    "\n",
    "np.mean(jackknife(Gc).sample(),axis=0) \n",
    "jackknife(jackknife(Gc).sample()).up() \n",
    "\n",
    "# These two are identical to one another\n",
    "ensemble_stat(Gc).rcov()[0]\n",
    "jackknife(Gc).fcov()[0]\n",
    "jackknife(jackknife(Gc).sample()).upcov()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing minimizer's precision/accuracy\n",
    "factor=10\n",
    "ntrials=100\n",
    "mcalls=5000\n",
    "mtol=0.0001\n",
    "hack=0\n",
    "\n",
    "\n",
    "data_incov=improved_inverse_covariance(data_cov)\n",
    "def least_squares_scipy(par):  # we must accept a variable number of model parameters\n",
    "    ym = exp_np(data_t, *par)\n",
    "    return np.dot(np.dot((data_y - ym), data_incov),(data_y - ym))\n",
    "\n",
    "count1=0\n",
    "count2=0\n",
    "count3=0\n",
    "count4=0\n",
    "count5=0\n",
    "\n",
    "m1list=[]\n",
    "m1chilist=[]\n",
    "m2list=[]\n",
    "m2chilist=[]\n",
    "m3list=[]\n",
    "m3chilist=[]\n",
    "m4list=[]\n",
    "m4chilist=[]\n",
    "m5list=[]\n",
    "m5chilist=[]\n",
    "m6list=[]\n",
    "\n",
    "\n",
    "for i in range(ntrials):\n",
    "    inipars=np.array([0.0756601070458546,1.8388443700832076,0.2397704868012228,0.081132649591307,0.3404256622175537])\n",
    "    einipars=factor*inipars\n",
    "    s = np.random.normal(0, 1, len(inipars))\n",
    "    inipars=inipars+s*einipars\n",
    "    least_squares_np = EvenBetterLeastSquares(eval('nb_exp_np_pole'), data_t, data_y, data_incov)\n",
    "    m=Minuit(least_squares_np,*inipars)   # pass starting values as a sequence\n",
    "    m.strategy=1\n",
    "    m.tol=mtol\n",
    "    result1=m.migrad(mcalls)\n",
    "    m2=Minuit(least_squares_np,*inipars)   # pass starting values as a sequence\n",
    "    m2.strategy=2\n",
    "    m2.tol=mtol\n",
    "    result2=m2.scipy('COBYLA',mcalls).simplex(mcalls).scipy('CG',mcalls).migrad(mcalls).migrad(mcalls).migrad(mcalls)\n",
    "    m3=Minuit(least_squares_np,*inipars)   # pass starting values as a sequence\n",
    "    m3.strategy=2\n",
    "    m3.tol=mtol\n",
    "    result3=m3.scipy('CG',mcalls).scipy('L-BFGS-B',mcalls).migrad(mcalls).migrad(mcalls)\n",
    "    m4=Minuit(least_squares_np,*inipars)   # pass starting values as a sequence\n",
    "    m4.strategy=2\n",
    "    m4.tol=mtol\n",
    "    result4=m4.simplex(mcalls).simplex(mcalls).scipy('CG',mcalls).scipy('L-BFGS-B',mcalls).migrad(mcalls).migrad(mcalls).migrad(mcalls)\n",
    "\n",
    "\n",
    "    np.set_printoptions(precision=16)\n",
    "    \n",
    "\n",
    "    if result1.valid:\n",
    "        count1+=1\n",
    "    if result1.valid or hack==1:\n",
    "        m1list.append(np.abs(np.array(result1.values)))\n",
    "        m1chilist.append(result1.fval/result1.ndof)\n",
    "\n",
    "    if result2.valid:\n",
    "        count2+=1\n",
    "    if result2.valid or hack==1:\n",
    "        m2list.append(np.abs(np.array(result2.values)))\n",
    "        m2chilist.append(result2.fval/result2.ndof)\n",
    "\n",
    "    if result3.valid:\n",
    "        count3+=1\n",
    "    if result3.valid or hack==1:\n",
    "        m3list.append(np.abs(np.array(result3.values)))\n",
    "        m3chilist.append(result3.fval/result3.ndof)\n",
    "\n",
    "    if result4.valid:\n",
    "        count4+=1\n",
    "    if result4.valid or hack==1:\n",
    "        m4list.append(np.abs(np.array(result4.values)))\n",
    "        m4chilist.append(result4.fval/result4.ndof)\n",
    "\n",
    "\n",
    "    bounds=[]\n",
    "    for i in inipars:   \n",
    "        bounds.append((0,factor*abs(i)))\n",
    "\n",
    "    #res1=sp.optimize.basinhopping(least_squares_scipy,inipars,niter=10)\n",
    "    #m5list.append(np.abs(res1.x))\n",
    "    #m5chilist.append(res1.fun/result4.ndof)\n",
    "    #inipars5=np.array(res1.x)\n",
    "    m5=Minuit(least_squares_np,*inipars)\n",
    "    m5.tol=mtol\n",
    "    m5.strategy=2\n",
    "    res1=m5.scipy('Nelder-Mead',mcalls).scipy('CG',mcalls).scipy('Nelder-Mead',mcalls).scipy('L-BFGS-B',mcalls).migrad(mcalls).migrad(mcalls).migrad(mcalls)\n",
    "\n",
    "    if res1.valid:\n",
    "        count5+=1\n",
    "    if res1.valid or hack==1:\n",
    "        m5list.append(np.abs(np.array(res1.values)))\n",
    "        m5chilist.append(res1.fval/res1.ndof)\n",
    "\n",
    "\n",
    "m1list=np.array(m1list)\n",
    "m1chilist=np.array(m1chilist)\n",
    "m2list=np.array(m2list)\n",
    "m2chilist=np.array(m2chilist)\n",
    "m3list=np.array(m3list)\n",
    "m3chilist=np.array(m3chilist)\n",
    "m4list=np.array(m4list)\n",
    "m4chilist=np.array(m4chilist)\n",
    "m5list=np.array(m5list)\n",
    "m5chilist=np.array(m5chilist)\n",
    "\n",
    "\n",
    "#np.mean(m1list,axis=0)\n",
    "#np.mean(m2list,axis=0)\n",
    "#np.mean(m3list,axis=0)\n",
    "#np.mean(m4list,axis=0)\n",
    "#np.mean(m5list,axis=0)\n",
    "\n",
    "count1\n",
    "count2\n",
    "count3\n",
    "count4\n",
    "count5\n",
    "\n",
    "np.mean(m1chilist,axis=0)\n",
    "np.mean(m2chilist,axis=0)\n",
    "np.mean(m3chilist,axis=0)\n",
    "np.mean(m4chilist,axis=0)\n",
    "np.mean(m5chilist,axis=0)\n",
    "\n",
    "np.sqrt(np.var(m1list,axis=0))\n",
    "np.sqrt(np.var(m2list,axis=0))\n",
    "np.sqrt(np.var(m3list,axis=0))\n",
    "np.sqrt(np.var(m4list,axis=0))\n",
    "np.sqrt(np.var(m5list,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-start procedure for \"global minimization\"\n",
    "# This works by providing the maximum amount of points you want to start sampling with. It produces a \n",
    "\n",
    "x=0\n",
    "k=10\n",
    "r=11\n",
    "\n",
    "jackkl=20000\n",
    "jump_configs=1\n",
    "\n",
    "mcalls=5000\n",
    "mtol=0.0001\n",
    "factor=1\n",
    "nsamples=1000\n",
    "strategy=2\n",
    "\n",
    "totaltraj=int(len(data[x][k])/size[k])\n",
    "Nt=Textent\n",
    "\n",
    "Gc=np.zeros((int(totaltraj/jump_configs),Nt))\n",
    "for i in range(int(totaltraj/jump_configs)):\n",
    "    index=jump_configs*i\n",
    "    Gc[[i]]=data[x][k][range(index*Nt,(index+1)*Nt),[r]]\n",
    "    \n",
    "#logG=np.log(ratio(trim_negative(Gc).trimmed()).val())\n",
    "\n",
    "\n",
    "# Get average over all data, we will then replicate for every Jackknife sample to get errors\n",
    "\n",
    "gdata=jackknife(Gc,jackkl).sample()\n",
    "gdata=jackknife(gdata,jackkl).up()\n",
    "lt=len(Gc[0])\n",
    "dfin=min(lt,100)\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_2t  = np.linspace(1, 2*lt-1, 2*lt-1)\n",
    "data_y   = ensemble_stat(gdata).mean()\n",
    "data_cov = ensemble_stat(gdata).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(gdata).rcov()))\n",
    "data_incov=improved_inverse_covariance(data_cov)\n",
    "\n",
    "data_covf = np.identity(lt)\n",
    "for i in range(len(np.sqrt(np.diag(data_cov)))):\n",
    "    for j in range(len(np.sqrt(np.diag(data_cov)))):\n",
    "        data_covf[i][j]*=np.sqrt(np.diag(data_cov))[i]*np.sqrt(np.diag(data_cov))[j]\n",
    "\n",
    "\n",
    "\n",
    "pars_best=[-0.0756601021475849,1.838844370954277,0.2397704868229662,0.0811326516777515,0.3404256638585156]\n",
    "fit_best=1.6972963589305958\n",
    "\n",
    "inipars=np.array([0.0,2.0,1.0,0.1,1.0])\n",
    "einipars=inipars.copy()\n",
    "for j in range(len(einipars)):\n",
    "    einipars[j]=max(0.01,einipars[j])\n",
    "einipars*=factor\n",
    "\n",
    "least_squares_np = EvenBetterLeastSquares(eval('nb_exp_np_pole'), data_t, data_y, data_incov)\n",
    "\n",
    "inipars_list=[]\n",
    "for i in range(nsamples):\n",
    "    s = np.random.normal(0, 1, len(inipars))\n",
    "    inipars_list.append(inipars+s*einipars)\n",
    "\n",
    "fit_results=[]\n",
    "minimized=0\n",
    "par_results=[]\n",
    "for i in range(len(inipars_list)):\n",
    "    m=Minuit(least_squares_np,*inipars_list[i])\n",
    "    m.tol=mtol\n",
    "    m.strategy=strategy\n",
    "    result_fit=m.simplex(mcalls).scipy('L-BFGS-B',mcalls).migrad(mcalls).migrad(mcalls)\n",
    "    #result_fit=m.simplex(mcalls).scipy('CG',mcalls).simplex(mcalls).scipy('L-BFGS-B',mcalls).migrad(mcalls).migrad(mcalls)\n",
    "    if (result_fit.valid):\n",
    "        minimized+=1\n",
    "        par_results.append(np.array(result_fit.values))\n",
    "\n",
    "    fit_results.append(result_fit.fval/result_fit.ndof)\n",
    "\n",
    "correct=0\n",
    "for i in range(nsamples):\n",
    "    if (np.abs(fit_results[i]-1)<100):\n",
    "        correct+=1\n",
    "\n",
    "minimized\n",
    "correct\n",
    "\n",
    "np.mean(np.sqrt(np.var(par_results,axis=0)))   # Mean of variation on parameter results over fits\n",
    "\n",
    "np.min(fit_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./'\n",
    "list_data_tpa=[];list_data_effm_f=[];list_data_effm_err_f=[];list_data_tp=[];list_data_effmp=[];list_data_effm_errp=[];list_data_tf=[];list_fitall=[];list_efitall=[];list_data_tpf=[];list_fit=[];list_efit=[]\n",
    "data_tpa, data_effm_f, data_effm_err_f, data_tp, data_effmp, data_effm_errp, data_tf, fitall, efitall, data_tpf, fit, efit=plotGc(data_t, data_y, data_cov, AIC_list, datatype_Gc, model_Gc, mcalls, mtol, reuse, inv_first, xi[0], path,0,0.05).prepare()  \n",
    "list_data_tpa.append(data_tpa);list_data_effm_f.append(data_effm_f);list_data_effm_err_f.append(data_effm_err_f);list_data_tp.append(data_tp);list_data_effmp.append(data_effmp);list_data_effm_errp.append(data_effm_errp);list_data_tf.append(data_tf);list_fitall.append(fitall);list_efitall.append(efitall);list_data_tpf.append(data_tpf);list_fit.append(fit);list_efit.append(efit)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "plt.fill_between(data_tf, fitall+efitall, fitall-efitall,color=jpac_blue,alpha=0.1)\n",
    "plt.fill_between(data_tpf, fit+efit, fit-efit,color=jpac_blue,alpha=0.7)\n",
    "if (len(data_tp)>=1):\n",
    "    plt.errorbar(data_tpa, data_effm_f, data_effm_err_f, fmt=\"ok\", alpha=0.3)\n",
    "    plt.errorbar(data_tp, data_effmp, data_effm_errp, fmt=\"ok\")\n",
    "plt.xlabel(\"$t/a_t$\",fontsize=24)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.legend(fontsize=16,frameon=False)\n",
    "plt.show(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compact_eff_m(list_data_tpa, list_data_effm_f, list_data_effm_err_f, list_data_tp, list_data_effmp, list_data_effm_errp, list_data_tf, list_fitall, list_efitall, list_data_tpf, list_fit, list_efit, path, beta, y_lim):   \n",
    "    fig = plt.figure(figsize=(16,9))\n",
    "    for i in range(len(list_data_tpa)):\n",
    "        alphamult=1\n",
    "        data_tf=list_data_tf[i];data_tpf=list_data_tpf[i];fitall=list_fitall[i];efitall=list_efitall[i];fit=list_fit[i];efit=list_efit[i];data_tpa=list_data_tpa[i];\n",
    "        data_tp=list_data_tp[i];data_effm_f=list_data_effm_f[i];data_effmp=list_data_effmp[i];data_effm_err_f=list_data_effm_err_f[i];data_effm_errp=list_data_effm_errp[i]\n",
    "        if (fitall[-1]>y_lim):\n",
    "            alphamult=0\n",
    "        plt.fill_between(data_tf, fitall+efitall, fitall-efitall,color=jpac_color_around[i],alpha=alphamult*0.1)\n",
    "        plt.fill_between(data_tpf, fit+efit, fit-efit,color=jpac_color_around[i],alpha=alphamult*0.7)\n",
    "        if (len(data_tp)>=1):\n",
    "            plt.errorbar(data_tpa, data_effm_f, data_effm_err_f,color=jpac_color_around[i], fmt=\"ok\", alpha=alphamult*0.3)\n",
    "            plt.errorbar(data_tp, data_effmp, data_effm_errp,color=jpac_color_around[i], fmt=\"ok\",alpha=alphamult*1)\n",
    "    plt.xlabel(\"$t/a_t$\",fontsize=24)\n",
    "    plt.ylabel(\"$\\\\beta={}$\".format(beta),fontsize=24, rotation=0, loc='top')\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.ylim(None,y_lim)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.legend(fontsize=16,frameon=False)\n",
    "    #plt.show()\n",
    "    plt.savefig('{}_compact.pdf'.format(path), format=\"pdf\", bbox_inches='tight', pad_inches=0.2)\n",
    "    plt.close(fig)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compact_eff_m(list_data_tpa,list_data_effm_f,list_data_effm_err_f,list_data_tp,list_data_effmp,list_data_effm_errp,list_data_tf,list_fitall,list_efitall,list_data_tpf,list_fit,list_efit,'/',2.25,1.)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileini=filefin=2\n",
    "datarun=[]\n",
    "dataint  = data[xiini:xifin+1]\n",
    "xirun    = xi[xiini:xifin+1]\n",
    "for i in range(len(dataint)):\n",
    "    datarun.append(dataint[i][fileini:filefin+1])\n",
    "\n",
    "\n",
    "sizerun  = size[fileini:filefin+1]\n",
    "betarun  = beta[fileini:filefin+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multistart=10\n",
    "jackkl=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gcplotsdircompact='{}_compact'.format(Gcplotsdir)\n",
    "AIC_list_final=[]\n",
    "for k in range(len(datarun)):\n",
    "    print('Attempting fits to xi={}'.format(xirun[k]))\n",
    "    path=['{}/xi={}'.format(Gcplotsdir,xirun[k]),'{}/xi={}'.format(Gcplotsdircompact,xirun[k])]\n",
    "    result=fitter(datarun[k], sizerun, dini_Gc, dstop_Gc, dmindata_Gc, dfin_Gc, datatype_Gc, model_Gc, inipars_Gc, variants_Gc, mcalls, mtol, reuse, inv_first, multiprocess, cutoff_ma, xirun[k], betarun, path, corrtype, norm, cov_freeze, improve, multistart, no_corrs, no_valid_check)\n",
    "    Vrlistavg, Vrlistavg_rescaled, Vrlistsel, worstsel, listfinal , datayf=result.jackk_fit(jackkl)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC_list_final.append(listfinal)\n",
    "#Store the V(R) data Jackknife results\n",
    "Vrf=[]\n",
    "for i in range(len(datarun[k])):\n",
    "    Vrf.append(jackknife(Vrlistavg[i]).up())\n",
    "    np.savetxt('{}{}/{}_{}_{}_VR_ti{}_{}_tfin{}_tmin{}_cut{}_beta={}_nocorrs={}_{}.dat'.format(resultspath,xirun[k],len(variants_Gc),model_Gc,datatype_Gc,dini_Gc,dstop_Gc,dfin_Gc,dmindata_Gc,cutoff_ma,betarun[i],no_corrs,corrtype), jackknife(Vrlistavg[i]).up())\n",
    "    np.savetxt('{}{}/{}_{}_{}_VR_rescaled_ti{}_{}_tfin{}_tmin{}_cut{}_beta={}_nocorrs={}_{}.dat'.format(resultspath,xirun[k],len(variants_Gc),model_Gc,datatype_Gc,dini_Gc,dstop_Gc,dfin_Gc,dmindata_Gc,cutoff_ma,betarun[i],no_corrs,corrtype), jackknife(Vrlistavg_rescaled[i]).up())\n",
    "    np.savetxt('{}{}/{}_{}_{}_worstsel_ti{}_{}_tfin{}_tmin{}_cut{}_beta={}_nocorrs={}_{}.dat'.format(resultspath,xirun[k],len(variants_Gc),model_Gc,datatype_Gc,dini_Gc,dstop_Gc,dfin_Gc,dmindata_Gc,cutoff_ma,betarun[i],no_corrs,corrtype), [worstsel[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cov[5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cov_rescaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagn=6\n",
    "jackknife(Vdat,jackkl).scov()[0][diagn][diagn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jackknife(jackknife(Vdat_rescaled,jackkl).sample()).upcov()[diagn][diagn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multistart = 10\n",
    "improve    = 0\n",
    "\n",
    "datarun=[]\n",
    "dataint  = data[xiini:xifin+1]\n",
    "xirun    = xi[xiini:xifin+1]\n",
    "for i in range(len(dataint)):\n",
    "    datarun.append(dataint[i][fileini:filefin+1])\n",
    "\n",
    "sizerun  = size[fileini:filefin+1]\n",
    "betarun  = beta\n",
    "\n",
    "VRchisq2dof = []\n",
    "worstsel=[]\n",
    "\n",
    "variants_Gc=['single','double','triple']\n",
    "diini=1\n",
    "distop=0\n",
    "model_Gc='nb_exp_np_pole'\n",
    "\n",
    "dini_Vr=1 \n",
    "dstop_Vr=1 \n",
    "dmindata_Vr=8\n",
    "dfin_Vr=10\n",
    "\n",
    "for k in range(1+0*len(datarun)):\n",
    "    for i in range(2,3+0*len(betarun)): \n",
    "        print (\"xi={}, beta={}\".format(xirun[k],betarun[i]))\n",
    "        worstsel.append(np.loadtxt('{}{}/{}_{}_{}_worstsel_ti{}_{}_tfin{}_tmin{}_cut{}_beta={}_nocorrs={}_{}.dat'.format(resultspath,xirun[k],len(variants_Gc),model_Gc,datatype_Gc,diini,dstop_Gc,dfin_Gc,dmindata_Gc,cutoff_ma,betarun[i],no_corrs,corrtype)))\n",
    "        Vdat=np.loadtxt('{}{}/{}_{}_{}_VR_ti{}_{}_tfin{}_tmin{}_cut{}_beta={}_nocorrs={}_{}.dat'.format(resultspath,xirun[k],len(variants_Gc),model_Gc,datatype_Gc,diini,dstop_Gc,dfin_Gc,dmindata_Gc,cutoff_ma,betarun[i],no_corrs,corrtype))\n",
    "        Vdat_rescaled=np.loadtxt('{}{}/{}_{}_{}_VR_rescaled_ti{}_{}_tfin{}_tmin{}_cut{}_beta={}_nocorrs={}_{}.dat'.format(resultspath,xirun[k],len(variants_Gc),model_Gc,datatype_Gc,diini,dstop_Gc,dfin_Gc,dmindata_Gc,cutoff_ma,betarun[i],no_corrs,corrtype))\n",
    "        jackkl=len(Vdat)\n",
    "        lt=len(Vdat[i])\n",
    "\n",
    "        data_t     = np.linspace(1, lt, lt)\n",
    "        data_y     = jackknife(Vdat,jackkl).sample()\n",
    "        data_cov   = jackknife(Vdat,jackkl).scov()\n",
    "        data_cov_rescaled = jackknife(jackknife(Vdat_rescaled,jackkl).sample()).upcov()\n",
    "\n",
    "        m=Modelsmin( data_t, data_y, data_cov, dini_Vr, dstop_Vr, dmindata_Vr, dfin_Vr, inipars_Vr, model_Vr, variants_Vr, datatype_Vr, mcalls, mtol, reuse, inv_first, multiprocess, cov_freeze, improve, multistart, no_corrs, no_valid_check, data_cov_rescaled)\n",
    "        mf=m.jackk_minimize()\n",
    "        AIC_list=Jackknife_AIClist(mf)\n",
    "        VRchisq2dof.append(ensemble_stat(AIC_list.ordered()[0,4][:,0]).mean())\n",
    "        dummy, sigma_rescaled=AIC_list.avgsample(cutoff_ma,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC_list.ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(ensemble_stat(jackknife(AIC_list.avgsample(cutoff_ma,3)[1]).up()).rcov())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jackknife(sigma_rescaled).up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mambo jambo test, lets just take the log ratio from the data and use it as the correct V(R) predictor\n",
    "\n",
    "datarun=[]\n",
    "dataint  = data[xiini:xifin+1]\n",
    "for i in range(len(dataint)):\n",
    "    datarun.append(dataint[i][fileini:filefin+1])\n",
    "\n",
    "sizerun  = size[fileini:filefin+1]\n",
    "betarun  = beta[fileini:filefin+1]\n",
    "\n",
    "if (dini_Gc==0):\n",
    "    diini  = 0\n",
    "    distop = 0\n",
    "else:\n",
    "    diini   = dini_Gc\n",
    "    distop = dini_Gc+dstop_Gc\n",
    "\n",
    "for k in range(len(datarun)):\n",
    "    for j in range(len(datarun[k])):\n",
    "        totaltraj=int(len(data[k][j])/size[j])\n",
    "        Nt=len(data[k][j][0])-1\n",
    "\n",
    "        Gc=np.zeros((totaltraj,Nt))\n",
    "        Vrlistavg=[]\n",
    "        for r in range(Nt):\n",
    "            for i in range(totaltraj):\n",
    "                Gc[[i]]=data[k][j][range(i*Nt,(i+1)*Nt),[r+1]]\n",
    "\n",
    "            data_y   = jackknife(Gc).sample()\n",
    "            Vrlistavg.append(jackknife(np.log(2/data_y[:,0])).up())\n",
    "\n",
    "        np.savetxt('{}{}/VR_ti{}_tistop{}_tmin{}_beta={}.dat'.format(resultspath,xi[k],diini,distop,dmindata_Gc,betarun[j]), np.transpose(Vrlistavg))\n",
    "        np.savetxt('{}{}/worstsel_ti{}_tistop{}_tmin{}_beta={}.dat'.format(resultspath,xi[k],diini,distop,dmindata_Gc,betarun[j]), [0])\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VRchisq2dof = []\n",
    "worstsel=[]\n",
    "\n",
    "for k in range(len(datarun)):\n",
    "    for i in range(len(datarun[0])): \n",
    "        worstsel.append(np.loadtxt('{}{}/worstsel_ti{}_tistop{}_tmin{}_beta={}.dat'.format(resultspath,xi[k],diini,distop,dmindata_Gc,betarun[i])))\n",
    "        Vdat=np.loadtxt('{}{}/VR_ti{}_tistop{}_tmin{}_beta={}.dat'.format(resultspath,xi[k],diini,distop,dmindata_Gc,betarun[i]))\n",
    "        jackkl=len(Vdat)\n",
    "        lt=len(Vdat[i])\n",
    "\n",
    "        data_t     = np.linspace(1, lt, lt)\n",
    "        data_y     = jackknife(Vdat,jackkl).sample()\n",
    "        data_cov   = jackknife(Vdat,jackkl).scov()\n",
    "\n",
    "        m=Modelsmin( data_t, data_y, data_cov, dini_Vr, dstop_Vr, dmindata_Vr, dfin, inipars_Vr, model_Vr, variants_Vr, datatype_Vr, mcalls, mtol, reuse, inv_first)\n",
    "        mf=m.jackk_minimize()\n",
    "        AIC_list=Jackknife_AIClist(mf)\n",
    "        VRchisq2dof.append(ensemble_stat(AIC_list.ordered()[0,4][:,0]).mean())\n",
    "        np.savetxt('{}{}/fits_VR_beta={}.dat'.format(resultspath,xi[k],betarun[i]),np.append(AIC_list.ordered()[0,1:3],[AIC_list.selval()[0:2],AIC_list.avgval()[0:2]]))\n",
    "        np.savetxt('{}{}/sigma_beta={}.dat'.format(resultspath,xi[k],betarun[i]),[AIC_list.avgval()[0][2],AIC_list.avgval()[1][2]])\n",
    "        dataV=np.array([AIC_list.selval()[2],AIC_list.avgval()[2]])\n",
    "        with open('{}{}/corrs_VR_beta={}.dat'.format(resultspath,xi[k],betarun[i]), 'w') as outfile:\n",
    "            outfile.write('# Model selection/average corrs:\\n')\n",
    "            for data_slice in dataV:\n",
    "                np.savetxt(outfile, data_slice)\n",
    "\n",
    "\n",
    "with open('{}/labels.dat'.format(resultsdir), 'w') as outfile:\n",
    "    for k in range(len(datarun)):\n",
    "        for i in range(len(datarun[0])):\n",
    "            outfile.write(\"$\\\\beta$={} $\\\\chi^2/$dof={:.1f}, {:.1f}\\n\".format(betarun[i],worstsel[i],VRchisq2dof[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt=len(logG[0])\n",
    "dfin=lt\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(Gc).mean()\n",
    "data_cov = ensemble_stat(Gc).rcov()\n",
    "\n",
    "\n",
    "datatype=\"exp_WL\"\n",
    "model='exp_np'\n",
    "# Trim to use models that have less params than data points used in the fit\n",
    "inipars_GC=[[0.4,1.]]#,[1.0,0.3,1.0,0.2]]\n",
    "variants_GC=['single']#,'double']\n",
    "\n",
    "m=Modelsmin(data_t, data_y, data_cov, dini, dstop, dmindata, dfin, inipars_GC, model, variants_GC, datatype, mcalls, mtol, 1, 1)\n",
    "mf=m.minimize()\n",
    "AIC_list=AIClist(mf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt=len(Gc[0])\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(Gc).mean()\n",
    "data_cov = ensemble_stat(Gc).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(Gc).rcov()))\n",
    "\n",
    "mcalls=5000\n",
    "mtol=0.001\n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, 4, 16, [-1.93328781, -0.35270411,  0.1       ,  0.1       ], 'nb_exp_np', mcalls, mtol,1)\n",
    "\n",
    "m.minimize()\n",
    "ma=MA_fit(m.minimize())\n",
    "\n",
    "np.log(2/data_y[0])\n",
    "\n",
    "loglimG_geom(0,*ma.pars())\n",
    "prop_err(0.,'loglimG_geom',ma.pars(),ma.errs(),ma.corrs())[0]\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t, exp_np_geom(data_t, *m.minimize().values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt=len(Gc[0])\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(Gc).mean()\n",
    "data_cov = ensemble_stat(Gc).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(Gc).rcov()))\n",
    "\n",
    "mcalls=5000\n",
    "mtol=0.001\n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, 1, 12, [1.,0.5,0.3,.2], 'exp_np', mcalls, mtol,1)\n",
    "\n",
    "m.minimize()\n",
    "ma=MA_fit(m.minimize())\n",
    "\n",
    "np.log(2/data_y[0])\n",
    "\n",
    "loglimG(0,*ma.pars())\n",
    "prop_err(0.,'loglimG',ma.pars(),ma.errs(),ma.corrs())[0]\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t, exp_np(data_t, *m.minimize().values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt=len(Gc[0])\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(Gc).mean()\n",
    "data_cov = ensemble_stat(Gc).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(Gc).rcov()))\n",
    "\n",
    "mcalls=5000\n",
    "mtol=0.001\n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, 1, 12, [2.,0.5,0.2,.2,0.5,0.1], 'exp_np', mcalls, mtol,1)\n",
    "\n",
    "m.minimize()\n",
    "ma=MA_fit(m.minimize())\n",
    "\n",
    "np.log(2/data_y[0])\n",
    "\n",
    "loglimG(0,*ma.pars())\n",
    "prop_err(0.,'loglimG',ma.pars(),ma.errs(),ma.corrs())[0]\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t, exp_np(data_t, *m.minimize().values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt=len(Gc[0])\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(Gc).mean()\n",
    "data_cov = ensemble_stat(Gc).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(Gc).rcov()))\n",
    "\n",
    "mcalls=5000\n",
    "mtol=0.001\n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, 1, 12, [0.125,0.04,.51,0.04,2.56], 'exp_np_norm', mcalls, mtol,1)\n",
    "\n",
    "m.minimize()\n",
    "ma=MA_fit(m.minimize())\n",
    "\n",
    "np.log(2/data_y[0])\n",
    "\n",
    "loglimG_norm(0,*ma.pars())\n",
    "prop_err(0.,'loglimG_norm',ma.pars(),ma.errs(),ma.corrs())[0]\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t, exp_np_norm(data_t, *m.minimize().values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt=len(Gc[0])\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(Gc).mean()\n",
    "data_cov = ensemble_stat(Gc).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(Gc).rcov()))\n",
    "\n",
    "mcalls=5000\n",
    "mtol=0.001\n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, 1, 12, [0.1,0.1,1.,.1,2.], 'exp_np_norm_geom', mcalls, mtol,1)\n",
    "\n",
    "m.minimize()\n",
    "ma=MA_fit(m.minimize())\n",
    "\n",
    "np.log(2/data_y[0])\n",
    "\n",
    "loglimG_norm_geom(0,*ma.pars())\n",
    "prop_err(0.,'loglimG_geom',ma.pars(),ma.errs(),ma.corrs())[0]\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t, exp_np_norm_geom(data_t, *m.minimize().values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logG=np.log(jackknife(Gc).sample())\n",
    "dlogG=np.log(ratio(trim_negative(Gc).trimmed()).val())\n",
    "\n",
    "lt=len(dlogG[0])\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(dlogG).mean()\n",
    "data_cov = ensemble_stat(dlogG).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(dlogG).rcov()))\n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, 1, 12, [1.,1.,1.,1.,1.], 'line_np', mcalls, mtol, 1)\n",
    "\n",
    "m.minimize()\n",
    "ma=MA_fit(m.minimize())\n",
    "data_y[0]\n",
    "line_np(0,*ma.pars())\n",
    "prop_err(0.,'line_np',ma.pars(),ma.errs(),ma.corrs())[0]\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t, line_np(data_t, *m.minimize().values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logG=np.log(trim_negative(Gc).trimmed())\n",
    "\n",
    "lt=len(logG[0])\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(logG).mean()\n",
    "data_cov = ensemble_stat(logG).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(logG).rcov()))\n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, 1, 10, [0.,0.1,0.1,0.1,0.1], 'line_np', mcalls, mtol, 1)\n",
    "\n",
    "m.minimize()\n",
    "ma=MA_fit(m.minimize())\n",
    "np.log(2)-data_y[0]\n",
    "limG(0,*ma.pars())\n",
    "#prop_err(0.,'limG_norm',ma.pars(),ma.errs(),ma.corrs())[0]\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t, line_np(data_t, *m.minimize().values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logG=np.log(trim_negative(Gc).trimmed())\n",
    "\n",
    "lt=len(logG[0])\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(logG).mean()\n",
    "data_cov = ensemble_stat(logG).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(logG).rcov()))\n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, 1, 10, [0.1,0.1,0.1,0.1,0.1], 'line_np_norm', mcalls, mtol, 1)\n",
    "\n",
    "m.minimize()\n",
    "ma=MA_fit(m.minimize())\n",
    "np.log(2)-data_y[0]\n",
    "limG_norm(0,*ma.pars())\n",
    "#prop_err(0.,'limG_norm',ma.pars(),ma.errs(),ma.corrs())[0]\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t, line_np_norm(data_t, *m.minimize().values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logG=np.log(Gc)\n",
    "\n",
    "lt=len(logG[0])\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(logG).mean()\n",
    "data_cov = ensemble_stat(logG).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(logG).rcov()))\n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, 1, 12, [1.,1.,1.,-1.], 'line_np_pole', mcalls, mtol, 1)\n",
    "\n",
    "m.minimize()\n",
    "ma=MA_fit(m.minimize())\n",
    "limGp(0,*ma.pars())\n",
    "prop_err(0.,'limGp',ma.pars(),ma.errs(),ma.corrs())[0]\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t, line_np_pole(data_t, *m.minimize().values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datarun=[]\n",
    "dataint  = data[xiini:xifin+1]\n",
    "for i in range(len(dataint)):\n",
    "    datarun.append(dataint[i][fileini:filefin+1])\n",
    "\n",
    "sizerun  = size[fileini:filefin+1]\n",
    "betarun  = beta[fileini:filefin+1]\n",
    "\n",
    "datatype=\"exp_WL\"\n",
    "dfin=100\n",
    "model='exp_np'\n",
    "reuse=1\n",
    "inipars_GC=[[1.0,0.3]]#,[1.0,0.3,1.0,0.2]]\n",
    "variants_GC=['single']#,'double']\n",
    "jackkl=200\n",
    "\n",
    "result=fitter(datarun[0], size, dini, dstop, dmindata, dfin, datatype_Gc, model_Gc, inipars_Gc, variants_Gc, mcalls, mtol, 1, 1)\n",
    "Vrlistavg, Vrlistsel, worstsel, listfinal =result.jackk_fit(jackkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jackknife exercise test\n",
    "xi=0\n",
    "k=0\n",
    "r=0\n",
    "\n",
    "totaltraj=int(len(data[xi][k])/size[k])\n",
    "Nt=len(data[xi][k][0])-1\n",
    "\n",
    "Gc=np.zeros((totaltraj,Nt))\n",
    "for i in range(totaltraj):\n",
    "    Gc[[i]]=data[xi][k][range(i*Nt,(i+1)*Nt),[r+1]]\n",
    "\n",
    "\n",
    "jackkl=500\n",
    "lt=len(logG[0])\n",
    "dfin=lt\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = jackknife(Gc,jackkl).sample()\n",
    "data_cov = jackknife(Gc,jackkl).scov()\n",
    "\n",
    "\n",
    "datatype=\"exp_WL\"\n",
    "model='exp_np'\n",
    "# Trim to use models that have less params than data points used in the fit\n",
    "inipars_GC=[[1.0,0.4]]#,[1.0,0.3,1.0,0.2]]\n",
    "variants_GC=['single']#,'double']\n",
    "\n",
    "m=Modelsmin(data_t, data_y, data_cov, dini, dstop, dmindata, dfin, inipars_GC, model, variants_GC, datatype, mcalls, mtol, 1, 1)\n",
    "mf=m.jackk_minimize()\n",
    "AIC_list=Jackknife_AIClist(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_R     = []\n",
    "data_V     = []\n",
    "data_V_err = []\n",
    "a=[\"black\",\"crimson\",\"royalblue\",\"seagreen\"]\n",
    "labels=[\"b=2.375\",\"b=2.5\",\"b=2.59\",\"b=2.66\"]\n",
    "plotsR=plt.figure()\n",
    "for k in range(len(valfk)):\n",
    "    Nt=len(valfk[k])\n",
    "    data_R=np.linspace(1, Nt, Nt)\n",
    "    data_V=valfk[k]\n",
    "    data_V_err=evalfk[k]\n",
    "    plt.errorbar(data_R, data_V, data_V_err, fmt=\"ok\", label=labels[k], color=a[k], marker=\"s\")\n",
    "\n",
    "plotsR.show(1)\n",
    "#data_R=[element for sublist in data_R for element in sublist]\n",
    "#data_V=[element for sublist in data_V for element in sublist]\n",
    "#data_V_err=[element for sublist in data_V_err for element in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totaltraj=int(len(data[2])/size[2])\n",
    "Nt=len(data[2][0])-1\n",
    "\n",
    "Gc=np.zeros((totaltraj,Nt))\n",
    "for i in range(totaltraj):\n",
    "    Gc[[i]]=data[2][range(i*Nt,(i+1)*Nt),[1]]\n",
    "    \n",
    "logG=np.log(trim_negative(Gc).trimmed())    \n",
    "\n",
    "lt=len(logG[0])\n",
    "dfin=lt\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(logG).mean()\n",
    "data_cov = ensemble_stat(logG).cov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(logG).cov()))\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype=\"log\"\n",
    "dfin=20\n",
    "model=line_np\n",
    "reuse=1\n",
    "\n",
    "result=fitter(data, size, dini, dstop, dfin, datatype, model, inipars2, variants2, mcalls, mtol, reuse)\n",
    "\n",
    "valtrials, valfk2, evalfk2=result.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_R2     = []\n",
    "data_V2     = []\n",
    "data_V2_err = []\n",
    "a=[\"black\",\"crimson\",\"royalblue\",\"seagreen\"]\n",
    "\n",
    "plotsR=plt.figure(plotsR)\n",
    "for k in range(len(valfk2)):\n",
    "    Nt=len(valfk2[k])\n",
    "    data_R2=np.linspace(1, Nt, Nt)-0.3\n",
    "    data_V2=valfk2[k]\n",
    "    data_V2_err=evalfk2[k]\n",
    "#    for i in range(Nt):\n",
    "#        print(data_R2[i]+0.3,\" \",data_V2[i],\" \",data_V2_err[i])\n",
    "    plt.errorbar(data_R2, data_V2, data_V2_err, fmt=\"ok\", color=a[k])\n",
    "\n",
    "#data_R2=[element for sublist in data_R2 for element in sublist]\n",
    "#data_V2=[element for sublist in data_V2 for element in sublist]\n",
    "#data_V2_err=[element for sublist in data_V2_err for element in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.legend(frameon=False)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=Modelsmin( data_t, data_y, data_cov, dini, dstop, dfin, iniparsexp, model, variantsexp, datatype, mcalls, mtol, 1)\n",
    "mf=m.minimize()\n",
    "AIC_list=AIClist(mf[1])\n",
    "\n",
    "print(mf[0],np.array(AIC_list.avgval0()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_R3     = []\n",
    "data_V3     = []\n",
    "data_V3_err = []\n",
    "a=[\"black\",\"crimson\",\"royalblue\",\"seagreen\"]\n",
    "\n",
    "plotsR=plt.figure(plotsR)\n",
    "for k in range(len(valfk3)):\n",
    "    Nt=len(valfk3[k])\n",
    "    data_R3=np.linspace(1, Nt, Nt)+0.3\n",
    "    data_V3=valfk3[k]\n",
    "    data_V3_err=evalfk3[k]\n",
    "#    for i in range(Nt):\n",
    "#        print(data_R2[i]+0.3,\" \",data_V2[i],\" \",data_V2_err[i])\n",
    "    plt.errorbar(data_R3, data_V3, data_V3_err, fmt=\"ok\", color=a[k], marker=\"^\")\n",
    "\n",
    "#data_R2=[element for sublist in data_R2 for element in sublist]\n",
    "#data_V2=[element for sublist in data_V2 for element in sublist]\n",
    "#data_V2_err=[element for sublist in data_V2_err for element in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.legend(frameon=False)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype=\"exp\"\n",
    "dfin=20\n",
    "model=exp_np\n",
    "reuse=0\n",
    "iniparsexptest=iniparsexp[0:2]\n",
    "variantsexptest=variantsexp[0:2]\n",
    "\n",
    "result=fitter(data, size, dini, dstop, dfin, datatype, model, iniparsexptest, variantsexptest, mcalls, mtol, reuse)\n",
    "\n",
    "valtrials, valfk4, evalfk4=result.fit()\n",
    "\n",
    "valtrials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_R4     = []\n",
    "data_V4     = []\n",
    "data_V4_err = []\n",
    "a=[\"black\",\"crimson\",\"royalblue\",\"seagreen\"]\n",
    "\n",
    "plotsR=plt.figure(plotsR)\n",
    "for k in range(len(valfk4)):\n",
    "    Nt=len(valfk4[k])\n",
    "    data_R4=np.linspace(1, Nt, Nt)+0.3\n",
    "    data_V4=valfk4[k]\n",
    "    data_V4_err=evalfk4[k]\n",
    "#    for i in range(Nt):\n",
    "#        print(data_R2[i]+0.3,\" \",data_V2[i],\" \",data_V2_err[i])\n",
    "    plt.errorbar(data_R4, data_V4, data_V4_err, fmt=\"ok\", color=a[k], marker=\"v\")\n",
    "\n",
    "#data_R2=[element for sublist in data_R2 for element in sublist]\n",
    "#data_V2=[element for sublist in data_V2 for element in sublist]\n",
    "#data_V2_err=[element for sublist in data_V2_err for element in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.legend(frameon=False)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the exercise for exponential fits\n",
    "k=3\n",
    "r=1\n",
    "totaltraj=int(len(data[k])/size[k])\n",
    "Nt=len(data[k][0])-1\n",
    "\n",
    "Gc=np.zeros((totaltraj,Nt))\n",
    "for i in range(totaltraj):\n",
    "    Gc[[i]]=data[k][range(i*Nt,(i+1)*Nt),[r]]\n",
    "    \n",
    "lt=len(Gc[0])\n",
    "dini=0\n",
    "dfin=lt\n",
    "data_t   = np.linspace(1, lt, lt)[dini:dfin]\n",
    "data_y   = ensemble_stat(Gc).mean()[dini:dfin]\n",
    "data_cov = ensemble_stat(Gc).cov()[dini:dfin,dini:dfin]\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(Gc).cov()))[dini:dfin]\n",
    "\n",
    "model=exp_np\n",
    "datatype=\"exp\"\n",
    "\n",
    "m=Minuit_fit( data_t, data_y, data_cov, mcalls, mtol, iniparsexp[2], model,1)\n",
    "\n",
    "ma=MA_fit(m.minimize())\n",
    "print(m.minimize())\n",
    "\n",
    "#plotsE=plt.figure(2)\n",
    "#plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "#plt.plot(data_t, exp_np(data_t, *m.minimize().values), label=\"fit\")\n",
    "#plt.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets repeat a single fit to test it\n",
    "k=0\n",
    "r=1\n",
    "totaltraj=int(len(data[k])/size[k])\n",
    "\n",
    "Nt=len(data[k][0])-1\n",
    "\n",
    "Gc=np.zeros((totaltraj,Nt))\n",
    "for i in range(totaltraj):\n",
    "    Gc[[i]]=data[k][range(i*Nt,(i+1)*Nt),[r]]\n",
    "\n",
    "gdata    = np.log(trim_negative(jackknife(Gc,jackkl).sample()).trimmed())\n",
    "           \n",
    "gdata=jackknife(gdata,jackkl).up()\n",
    "\n",
    "lt=len(gdata[0])\n",
    "dfin=lt\n",
    "data_t   = np.linspace(1, lt, lt)\n",
    "data_y   = ensemble_stat(gdata).mean()\n",
    "data_cov = ensemble_stat(gdata).rcov()\n",
    "data_err = np.sqrt(np.diagonal(ensemble_stat(gdata).rcov()))\n",
    "\n",
    "m=RepeatSingleFit(data_t, data_y, data_cov, 2, 8, [0.5,1.,0.,0.], line_np, mcalls, mtol)\n",
    "\n",
    "m.minimize()\n",
    "m.minimize().fval/m.minimize().ndof\n",
    "\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t, line_np(data_t, *m.minimize().values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacings_iso(beta):\n",
    "    beta=np.asarray(beta).reshape(1, -1)[0,:]\n",
    "    Pi=np.pi\n",
    "    sigma=0.44**2\n",
    "    beta0=22/3; beta1=68/3; b0=0.33982850818945587; b1=-0.047729010997329825; b2=1.66; b3=4.38\n",
    "    scale=4*Pi**2/beta0\n",
    "\n",
    "    alist=np.zeros(len(beta))\n",
    "    for i in range(len(beta)):\n",
    "        f2=2*beta1/beta0**2*np.log(scale*beta[i])-scale*beta[i]+scale*b2/beta[i]+b3\n",
    "        alist[i]=np.sqrt(np.exp(f2)/sigma)\n",
    "\n",
    "    return alist\n",
    "\n",
    "def spacings_xi(xi,beta):\n",
    "    beta=np.asarray(beta).reshape(1, -1)[0,:]\n",
    "    xi=np.asarray(xi).reshape(1, -1)[0,:]\n",
    "    Pi=np.pi\n",
    "    sigma=0.44**2\n",
    "    beta0=22/3; beta1=68/3; b0=0.33982850818945587; b1=-0.047729010997329825; b2=1.613897922881925; b3=7.057569782719919\n",
    "    scale=4*Pi**2/beta0\n",
    "\n",
    "    alist=np.zeros([len(xi),len(beta)])\n",
    "    for j in range(len(xi)):\n",
    "        f1=b0+b1/xi[j]\n",
    "        for i in range(len(beta)):\n",
    "            f2=2*beta1/beta0**2*np.log(scale*beta[i])-scale*beta[i]+scale*b2/beta[i]+b3\n",
    "            alist[j][i]=np.sqrt(f1*np.exp(f2)/sigma)\n",
    "\n",
    "    return alist\n",
    "\n",
    "betas=[2.25,2.3,2.35,2.4,2.45,2.5,2.55,2.6,2.65,2.7,2.75]\n",
    "xi=[2,3,4,5,6,7,8]\n",
    "\n",
    "spacings_iso(betas)\n",
    "spacings_xi(xi,betas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
