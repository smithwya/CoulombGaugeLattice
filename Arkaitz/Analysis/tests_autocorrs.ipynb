{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iminuit version: 2.28.0\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# basic setup of the notebook\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "from numba import njit, prange\n",
    "from numba.experimental import jitclass\n",
    "import pickle\n",
    "\n",
    "from mpmath import *\n",
    "mp.dps = 200;mp.pretty = True\n",
    "import tomllib\n",
    "from pip._vendor import tomli\n",
    "import sys, os\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocess as mp\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import scipy as sp\n",
    "from scipy import *\n",
    "import faulthandler\n",
    "faulthandler.enable()\n",
    "sys.path.append('./code')\n",
    "from fit_drivers import *\n",
    "from minimizer import *\n",
    "from fit_functions import *\n",
    "from output_functions import *\n",
    "from general_stats import *\n",
    "from jpac_colors import *\n",
    "import fit_drivers, minimizer, fit_functions, output_functions, general_stats  \n",
    "\n",
    "import math as mp\n",
    "import timeit\n",
    "import time\n",
    "\n",
    "# everything in iminuit is done through the Minuit object, so we import it\n",
    "from iminuit import Minuit\n",
    "from iminuit import minimize\n",
    "import time\n",
    "from iminuit.util import describe\n",
    "from typing import Annotated\n",
    "\n",
    "# we also need a cost function to fit and import the LeastSquares function\n",
    "from iminuit.cost import LeastSquares\n",
    "\n",
    "# display iminuit version\n",
    "import iminuit\n",
    "print(\"iminuit version:\", iminuit.__version__)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Importing fixed params for analysis\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "with open('ini_files/S_analysis_L16_pole.toml', \"rb\") as f:\n",
    "    params = tomli.load(f)\n",
    "\n",
    "with open('ini_files/basic_setup_pole.toml', \"rb\") as f2:\n",
    "    params2 = tomli.load(f2)\n",
    "\n",
    "for i in params:\n",
    "     params['{}'.format(i)].update(params2['{}'.format(i)])\n",
    "\n",
    "\n",
    "who            = params['creator']['who']\n",
    "  \n",
    "  \n",
    "path           = params['paths_to_files']['base_path']\n",
    "mainpath       = '{}{}'.format(path,params['paths_to_files']['mainpath'])\n",
    "resultspath    = '{}{}'.format(path,params['paths_to_files']['resultspath'])\n",
    "resultsdir     = '{}{}'.format(path,params['paths_to_files']['resultsdir'])\n",
    "plotsdir       = '{}{}'.format(path,params['paths_to_files']['plotsdir'])\n",
    "Gcplotsdir     = '{}{}'.format(path,params['paths_to_files']['Gcplotsdir'])\n",
    "sizelabel      = params['paths_to_files']['sizelabel']      \n",
    "  \n",
    "  \n",
    "corrtype       = params['correlators']['corrtype']  \n",
    "xi             = params['correlators']['xi']\n",
    "beta           = params['correlators']['beta']\n",
    "betanorm       = params['correlators']['betanorm']\n",
    "Lextent        = params['correlators']['Lextent']\n",
    "Textent        = params['correlators']['Textent']\n",
    "size           = params['correlators']['size']\n",
    "Ncfgs          = params['correlators']['Ncfgs']\n",
    "\n",
    "als            = params['correlators']['als']\n",
    "  \n",
    "dini_Gc        = params['minimization_parameters']['dini_Gc']\n",
    "dstop_Gc       = params['minimization_parameters']['dstop_Gc']\n",
    "dmindata_Gc    = params['minimization_parameters']['dmindata_Gc']\n",
    "dini_Vr        = params['minimization_parameters']['dini_Vr']\n",
    "dstop_Vr       = params['minimization_parameters']['dstop_Vr']\n",
    "dmindata_Vr    = params['minimization_parameters']['dmindata_Vr']\n",
    "dfin_Gc        = params['minimization_parameters']['dfin_Gc']\n",
    "dfin_Vr        = params['minimization_parameters']['dfin_Vr']\n",
    "reuse          = params['minimization_parameters']['reuse']\n",
    "inv_first      = params['minimization_parameters']['inv_first']\n",
    "mcalls         = params['minimization_parameters']['mcalls']\n",
    "mtol           = params['minimization_parameters']['mtol']\n",
    "inipars_Gc     = params['minimization_parameters']['inipars_GC']\n",
    "variants_Gc    = params['minimization_parameters']['variants_GC']\n",
    "jackkl         = params['minimization_parameters']['jackkl']\n",
    "xiini          = params['minimization_parameters']['xiini']\n",
    "xifin          = params['minimization_parameters']['xifin']   \n",
    "fileini        = params['minimization_parameters']['fileini']                         \n",
    "filefin        = params['minimization_parameters']['filefin']\n",
    "datatype_Gc    = params['minimization_parameters']['datatype_Gc']\n",
    "model_Gc       = params['minimization_parameters']['model_Gc']\n",
    "model_Vr       = params['minimization_parameters']['model_Vr']\n",
    "datatype_Vr    = params['minimization_parameters']['datatype_Vr']\n",
    "inipars_Vr     = params['minimization_parameters']['inipars_Vr']\n",
    "variants_Vr    = params['minimization_parameters']['variants_Vr']\n",
    "multiprocess   = params['minimization_parameters']['multiprocess']\n",
    "cov_freeze     = params['minimization_parameters']['cov_freeze']\n",
    "improve        = params['minimization_parameters']['improve']\n",
    "multistart     = params['minimization_parameters']['multistart']\n",
    "  \n",
    "\n",
    "clean          = params['extra']['clean']\n",
    "cutoff_ma      = params['extra']['cutoff_ma']\n",
    "norm           = params['extra']['norm']\n",
    "no_corrs       = params['extra']['no_corrs']\n",
    "no_valid_check = params['extra']['no_valid_check']\n",
    "\n",
    "\n",
    "gev_m1_tofm=5.068\n",
    "als=np.array(als)/gev_m1_tofm\n",
    "als_orig=np.array(als)*gev_m1_tofm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "1985\n",
      "1992\n",
      "1927\n",
      "2000\n",
      "2000\n",
      "1995\n",
      "1994\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "1985\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "1917\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "1946\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "1917 2000\n",
      "[225, 230, 235, 240, 245, 250, 255, 260]\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#This is the only part that varies between Sebastian's and Wyatt's Lattices, the paths/readings\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create results folders if they do not exist\n",
    "if os.path.exists(resultsdir)==False:\n",
    "    os.mkdir(resultsdir)\n",
    "if os.path.exists(plotsdir)==False:\n",
    "    os.mkdir(plotsdir)\n",
    "if os.path.exists(Gcplotsdir)==False:\n",
    "    os.mkdir(Gcplotsdir)    \n",
    "\n",
    "\n",
    "# Clean results folder?\n",
    "if clean == 1:\n",
    "    os.system('rm -rf {}/*'.format(plotsdir))\n",
    "    os.system('rm -rf {}/*'.format(resultsdir))  \n",
    "    os.system('rm -rf {}/*'.format(Gcplotsdir)) \n",
    "\n",
    "\n",
    "for k in range(len(xi)):\n",
    "    if os.path.exists('{}{}'.format(resultspath,xi[k]))==False:\n",
    "        os.mkdir('{}{}'.format(resultspath,xi[k]))\n",
    "    if os.path.exists('{}/xi={}'.format(Gcplotsdir,xi[k]))==False:\n",
    "        os.mkdir('{}/xi={}'.format(Gcplotsdir,xi[k]))\n",
    "\n",
    "        \n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Read raw data and prepare accordingly\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "         \n",
    "\n",
    "# Data used in the analysis\n",
    "datam=[]\n",
    "for k in range(len(xi)):\n",
    "    dataint=[]\n",
    "    for j in range(len(beta)):\n",
    "        dataint.append(np.genfromtxt('{}{}/L{}_b{}_xi{}_{}.dat'.format(mainpath,xi[k],int(sizelabel),beta[j],xi[k],corrtype)))\n",
    "    datam.append(dataint)\n",
    "    \n",
    "# Collect completed configurations from raw data    \n",
    "data=[]\n",
    "for k in range(len(xi)):\n",
    "    dataint=[]\n",
    "    for j in range(len(datam[k])):\n",
    "        if (len(np.array(collect_configs(datam[k][j],Lextent,Textent).trans_S()))==0):\n",
    "            dataint.append(np.array(collect_configs(datam[k][j],Lextent,Textent).trans_W()))\n",
    "        else:\n",
    "            dataint.append(np.array(collect_configs(datam[k][j],Lextent,Textent).trans_S()))\n",
    "    data.append(dataint)\n",
    "\n",
    "      \n",
    "\n",
    "nconfigs=[]\n",
    "for k in range(len(xi)):\n",
    "    nint=[]\n",
    "    for j in range(len(beta)):\n",
    "        nint.append(int(len(data[k][j])/size[k]))\n",
    "        print(int(len(data[k][j])/size[k]))\n",
    "        nconfigs.append(int(len(data[k][j])/size[k]))  \n",
    "\n",
    "print(min(nconfigs),max(nconfigs))  \n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing autocorrelations, based on page 94 from Gattringer and Lang's and page 184 of Degrand and Detar\n",
    "\n",
    "def auto_func(t,a,b):\n",
    "    return a*np.exp(-t/b)\n",
    "\n",
    "def autocorr(list,dt):\n",
    "    mean=np.mean(list)\n",
    "    mean1=0\n",
    "    mean2=0\n",
    "    Ncfgs=len(list)\n",
    "    corr1=0\n",
    "    corr2=0\n",
    "    for i in range(Ncfgs-dt):\n",
    "        corr1+=(list[i]*list[i+dt])/(Ncfgs-dt)\n",
    "        corr2+=(list[i]-mean)*(list[i+dt]-mean)/(Ncfgs-dt)\n",
    "        mean1+=list[i]/(Ncfgs-dt)\n",
    "        mean2+=list[i+dt]/(Ncfgs-dt)\n",
    "    \n",
    "    corr1-=mean1*mean2\n",
    "    return corr2\n",
    "\n",
    "xi_range=1\n",
    "r_range=10\n",
    "r_ini=1\n",
    "tval=10\n",
    "t_ini=1\n",
    "ergodic_T=100\n",
    "\n",
    "for beta_label in range(len(beta)):\n",
    "\n",
    "    fig = plt.figure(figsize=(16,9))\n",
    "    plt.legend(fontsize=12,frameon=False,loc=0)\n",
    "\n",
    "    for x in range(xi_range):\n",
    "        corr_ergodic_final=[]\n",
    "\n",
    "        jump_configs=1\n",
    "        #print(len(data[x][beta_label]))\n",
    "        totaltraj=int(len(data[x][beta_label])/size[beta_label])\n",
    "        Nt=Textent\n",
    "        Gc=np.zeros((int(totaltraj/jump_configs),Nt))\n",
    "\n",
    "        for r in range(r_ini,r_ini+r_range):\n",
    "            for i in range(int(totaltraj/jump_configs)):\n",
    "                index=jump_configs*i\n",
    "                Gc[[i]]=data[x][beta_label][range(index*Nt,(index+1)*Nt),[r]]\n",
    "\n",
    "            data_ergodic   = np.linspace(0, ergodic_T, ergodic_T+1)\n",
    "            corr_ergodic=[]\n",
    "            for i in data_ergodic:\n",
    "                inter=0\n",
    "                for k in range(t_ini,t_ini+tval):\n",
    "                     inter+=autocorr(Gc[:,k],int(i))/autocorr(Gc[:,k],0)/tval\n",
    "\n",
    "                corr_ergodic.append(inter)\n",
    "\n",
    "            corr_ergodic_final.append(corr_ergodic)\n",
    "\n",
    "        final_autocor=np.mean(corr_ergodic_final,axis=0)\n",
    "        fit_autocor=sp.optimize.curve_fit(auto_func,data_ergodic,final_autocor)\n",
    "        time_autoco=fit_autocor[0][1]\n",
    "\n",
    "        plt.plot(data_ergodic, final_autocor, label='$\\\\xi={},\\\\tau={:10.2f}$'.format(x+1,time_autoco),color=jpac_color_around[x])\n",
    "        plt.legend(fontsize=12,frameon=False,loc=1)\n",
    "        #plt.plot(data_ergodic, auto_func(data_ergodic,fit_autocor[0][0],fit_autocor[0][1]), label=\"fit\",color=\"blue\")\n",
    "\n",
    "    plt.figtext(0.4, 0.8, \n",
    "                '$L={},\\, \\\\beta={}$'.format(sizelabel,beta[beta_label]/betanorm), \n",
    "                horizontalalignment =\"center\",  \n",
    "                verticalalignment =\"center\",  \n",
    "                wrap = True, fontsize = 20,  \n",
    "                color =\"black\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi_range=2\n",
    "r_range=1\n",
    "r_ini=15\n",
    "tval=1\n",
    "t_ini=1\n",
    "ergodic_T=100\n",
    "\n",
    "for beta_label in range(1,2+0*len(beta)):\n",
    "\n",
    "    fig = plt.figure(figsize=(16,9))\n",
    "    plt.legend(fontsize=12,frameon=False,loc=0)\n",
    "\n",
    "    for x in range(xi_range):\n",
    "        jump_configs=1\n",
    "        #print(len(data[x][beta_label]))\n",
    "        totaltraj=int(len(data[x][beta_label])/size[beta_label])\n",
    "        Nt=Textent\n",
    "        Gc=np.zeros((totaltraj,Nt))\n",
    "        Gc_avg=np.zeros(totaltraj)\n",
    "\n",
    "        for i in range(totaltraj):\n",
    "            for r in range(r_ini,r_ini+r_range):\n",
    "                index=jump_configs*i\n",
    "                Gc[[i]]+=data[x][beta_label][range(index*Nt,(index+1)*Nt),[r]]/r_range\n",
    "\n",
    "            for k in range(t_ini,t_ini+tval):\n",
    "                Gc_avg[[i]]+=Gc[i,k]/tval\n",
    "                \n",
    "\n",
    "        data_ergodic   = np.linspace(0, ergodic_T, ergodic_T+1)\n",
    "        corr_ergodic=[]\n",
    "        corr_ergodic_final=[]\n",
    "        for i in data_ergodic:\n",
    "            inter=autocorr(Gc_avg,int(i))/autocorr(Gc_avg,0)\n",
    "            corr_ergodic.append(inter)\n",
    "        corr_ergodic_final.append(corr_ergodic)\n",
    "\n",
    "        final_autocor=np.mean(corr_ergodic_final,axis=0)\n",
    "        fit_autocor=sp.optimize.curve_fit(auto_func,data_ergodic,final_autocor)\n",
    "        time_autoco=fit_autocor[0][1]\n",
    "\n",
    "        plt.plot(data_ergodic, final_autocor, label='$\\\\xi={},\\\\tau={:10.2f},Ncfgs={}$'.format(x+1,time_autoco,totaltraj),color=jpac_color_around[x])\n",
    "        plt.legend(fontsize=12,frameon=False,loc=1)\n",
    "        #plt.plot(data_ergodic, auto_func(data_ergodic,fit_autocor[0][0],fit_autocor[0][1]), label=\"fit\",color=\"blue\")\n",
    "\n",
    "    plt.figtext(0.4, 0.8, \n",
    "                '$L={},\\, \\\\beta={}$'.format(sizelabel,beta[beta_label]/betanorm), \n",
    "                horizontalalignment =\"center\",  \n",
    "                verticalalignment =\"center\",  \n",
    "                wrap = True, fontsize = 20,  \n",
    "                color =\"black\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_s=20\n",
    "repeat=100\n",
    "data_to_repeat=np.genfromtxt('../tests/Arkaitz-2.75.dat')\n",
    "data_test=np.zeros(repeat*len_s)\n",
    "\n",
    "for k in range(repeat):\n",
    "    for i in range(len_s):\n",
    "        data_test[[i+k*len_s]]=data_to_repeat[i+k][1]\n",
    "\n",
    "data_test   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test=np.genfromtxt('../tests/Arkaitz-2.75.dat')[:20\n",
    "\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "plt.legend(fontsize=12,frameon=False,loc=0)\n",
    "\n",
    "ergodic_T=80\n",
    "data_ergodic   = np.linspace(0, ergodic_T, ergodic_T+1)\n",
    "corr_ergodic=[]\n",
    "corr_ergodic_final=[]\n",
    "for i in data_ergodic:\n",
    "    inter=autocorr(data_test[:],int(i))/autocorr(data_test[:],0)\n",
    "    corr_ergodic.append(inter)\n",
    "\n",
    "corr_ergodic_final.append(corr_ergodic)\n",
    "\n",
    "final_autocor=corr_ergodic_final[0]\n",
    "fit_autocor=sp.optimize.curve_fit(auto_func,data_ergodic,final_autocor)\n",
    "time_autoco=fit_autocor[0][1]\n",
    "plt.scatter(data_ergodic, final_autocor, label='$\\\\beta=2.75,\\\\tau={:10.2f}$'.format(time_autoco),color=jpac_color_around[x])\n",
    "plt.legend(fontsize=12,frameon=False,loc=1)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
